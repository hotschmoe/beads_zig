{"id":"bd-10o","title":"Implement sync command","description":"## Goal\nImplement `bz sync` command for JSONL import/export operations.\n\n## Technical Approach\nCreate `src/cli/sync.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Exporter = @import(\"../sync/export.zig\").Exporter;\nconst Importer = @import(\"../sync/import.zig\").Importer;\nconst Output = @import(\"../output/mod.zig\").Output;\n\npub const SyncArgs = struct {\n    flush_only: bool = false,\n    import_only: bool = false,\n    force: bool = false,\n    dry_run: bool = false,\n};\n\npub fn run(args: SyncArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    const jsonl_path = \".beads/issues.jsonl\";\n    \n    if (args.flush_only) {\n        // Export only\n        try runExport(&db, jsonl_path, args.force, &output, allocator);\n    } else if (args.import_only) {\n        // Import only\n        try runImport(&db, jsonl_path, args.force, args.dry_run, &output, allocator);\n    } else {\n        // Bidirectional sync: import first (if newer), then export\n        try runBidirectional(&db, jsonl_path, args.force, &output, allocator);\n    }\n}\n\nfn runExport(db: *Database, path: []const u8, force: bool, output: *Output, allocator: std.mem.Allocator) !void {\n    var issue_store = IssueStore.init(db, allocator);\n    var dirty_tracker = DirtyTracker.init(db, allocator);\n    var exporter = Exporter.init(&issue_store, &dirty_tracker, allocator);\n    \n    const result = exporter.export(.{\n        .output_path = path,\n        .force = force,\n        .backup = true,\n    }) catch |err| switch (err) {\n        error.WouldOverwriteData => {\n            try output.err(\"Refusing to overwrite non-empty JSONL with empty database\", .{});\n            try output.print(\"Use --force to override this safety check.\\n\", .{});\n            return err;\n        },\n        else => return err,\n    };\n    \n    if (output.mode == .json) {\n        try output.printJson(.{\n            .action = \"export\",\n            .issues_exported = result.issues_exported,\n            .path = result.path,\n        });\n    } else {\n        try output.success(\"Exported {d} issue(s) to {s}\", .{ result.issues_exported, path });\n    }\n}\n\nfn runImport(db: *Database, path: []const u8, force: bool, dry_run: bool, output: *Output, allocator: std.mem.Allocator) !void {\n    var issue_store = IssueStore.init(db, allocator);\n    var importer = Importer.init(&issue_store, allocator);\n    \n    const result = importer.import(.{\n        .input_path = path,\n        .force = force,\n        .dry_run = dry_run,\n    }) catch |err| switch (err) {\n        error.MergeConflictDetected => {\n            try output.err(\"JSONL file contains merge conflict markers\", .{});\n            try output.print(\"Resolve conflicts in {s} before importing.\\n\", .{path});\n            return err;\n        },\n        error.JsonlParseError => {\n            try output.err(\"Failed to parse JSONL file\", .{});\n            return err;\n        },\n        else => return err,\n    };\n    \n    if (output.mode == .json) {\n        try output.printJson(.{\n            .action = \"import\",\n            .issues_created = result.issues_created,\n            .issues_updated = result.issues_updated,\n            .issues_skipped = result.issues_skipped,\n            .conflicts = result.conflicts,\n            .dry_run = dry_run,\n        });\n    } else {\n        if (dry_run) {\n            try output.print(\"[dry-run] Would \", .{});\n        }\n        try output.success(\"Imported: {d} created, {d} updated, {d} skipped\", .{\n            result.issues_created,\n            result.issues_updated,\n            result.issues_skipped,\n        });\n        \n        if (result.conflicts.len > 0) {\n            try output.warn(\"{d} conflict(s) detected:\", .{result.conflicts.len});\n            for (result.conflicts) |conflict| {\n                try output.print(\"  {s}: {s}\\n\", .{ conflict.issue_id, @tagName(conflict.reason) });\n            }\n        }\n    }\n}\n\nfn runBidirectional(db: *Database, path: []const u8, force: bool, output: *Output, allocator: std.mem.Allocator) !void {\n    // Check if JSONL is newer than last sync\n    const jsonl_mtime = getFileMtime(path) catch null;\n    const last_sync = try getLastSyncTime(db);\n    \n    if (jsonl_mtime != null and (last_sync == null or jsonl_mtime.? > last_sync.?)) {\n        try output.print(\"JSONL file is newer than last sync, importing first...\\n\", .{});\n        try runImport(db, path, force, false, output, allocator);\n    }\n    \n    // Export dirty issues\n    var dirty_tracker = DirtyTracker.init(db, allocator);\n    if (try dirty_tracker.hasDirtyIssues()) {\n        try output.print(\"Exporting dirty issues...\\n\", .{});\n        try runExport(db, path, force, output, allocator);\n    } else {\n        try output.print(\"No dirty issues to export.\\n\", .{});\n    }\n    \n    // Update last sync time\n    try updateLastSyncTime(db);\n}\n\nfn getFileMtime(path: []const u8) !?i64 {\n    const file = try std.fs.cwd().openFile(path, .{});\n    defer file.close();\n    const stat = try file.stat();\n    return @intCast(stat.mtime);\n}\n\nfn getLastSyncTime(db: *Database) !?i64 {\n    var stmt = try db.prepare(\"SELECT value FROM config WHERE key = 'last_sync_time'\");\n    defer stmt.deinit();\n    if (try stmt.step()) {\n        const val = stmt.columnText(0) orelse return null;\n        return std.fmt.parseInt(i64, val, 10) catch null;\n    }\n    return null;\n}\n\nfn updateLastSyncTime(db: *Database) !void {\n    const now = std.time.timestamp();\n    var stmt = try db.prepare(\"INSERT OR REPLACE INTO config (key, value) VALUES ('last_sync_time', ?1)\");\n    defer stmt.deinit();\n    var buf: [20]u8 = undefined;\n    const time_str = std.fmt.bufPrint(&buf, \"{d}\", .{now}) catch unreachable;\n    try stmt.bindText(1, time_str);\n    _ = try stmt.step();\n}\n```\n\n## Validation\n1. Test sync --flush-only exports to JSONL\n2. Test sync --import-only imports from JSONL\n3. Test bidirectional sync (import if newer, then export)\n4. Test merge conflict detection\n5. Test empty DB safety check\n6. Test --force bypasses safety checks\n7. Test --dry-run doesn't modify database\n8. Test conflict reporting\n9. Test --json output\n10. `zig build test` passes\n11. Manual test in sandbox/\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-227 (JSONL export)\n- bd-2o0 (JSONL import)\n- bd-3rn (dirty tracking)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-30T05:21:33.323709366Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:21:33.323709366Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-116","title":"Implement changelog command","description":"## Goal\nImplement `bz changelog` command to generate a changelog from closed issues.\n\n## Technical Approach\nCreate `src/cli/changelog.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst IssueStore = @import(\"../storage/issues.zig\").IssueStore;\nconst EventStore = @import(\"../storage/events.zig\").EventStore;\nconst Output = @import(\"../output/mod.zig\").Output;\nconst timestamp = @import(\"../models/timestamp.zig\");\n\npub const ChangelogArgs = struct {\n    since: ?[]const u8 = null,      // Start date (ISO or relative)\n    until: ?[]const u8 = null,      // End date (default: now)\n    format: enum { markdown, text, json } = .markdown,\n    group_by: enum { type, priority, none } = .type,\n};\n\npub fn run(args: ChangelogArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var issue_store = IssueStore.init(&db, allocator);\n    \n    // Parse date range\n    const since_ts = if (args.since) |s| try parseDate(s) else null;\n    const until_ts = if (args.until) |u| try parseDate(u) else std.time.timestamp();\n    \n    // Query closed issues in date range\n    var sql = std.ArrayList(u8).init(allocator);\n    defer sql.deinit();\n    \n    try sql.appendSlice(\n        \\\\SELECT * FROM issues\n        \\\\WHERE status = 'closed'\n    );\n    \n    if (since_ts != null) {\n        try sql.appendSlice(\" AND closed_at >= ?1\");\n    }\n    if (until_ts != null) {\n        try sql.appendSlice(\" AND closed_at <= ?2\");\n    }\n    \n    try sql.appendSlice(\" ORDER BY issue_type, priority, closed_at DESC\");\n    \n    var stmt = try db.prepare(sql.items);\n    defer stmt.deinit();\n    \n    if (since_ts) |ts| try stmt.bindInt(1, ts);\n    try stmt.bindInt(2, until_ts);\n    \n    var issues = std.ArrayList(Issue).init(allocator);\n    defer issues.deinit();\n    \n    while (try stmt.step()) {\n        try issues.append(try issue_store.rowToIssue(&stmt));\n    }\n    \n    if (global.json or args.format == .json) {\n        try output.printJson(.{\n            .since = if (since_ts) |ts| try timestamp.formatRfc3339Alloc(allocator, ts) else null,\n            .until = try timestamp.formatRfc3339Alloc(allocator, until_ts),\n            .count = issues.items.len,\n            .issues = issues.items,\n        });\n        return;\n    }\n    \n    // Generate formatted changelog\n    if (args.format == .markdown) {\n        try generateMarkdown(&output, issues.items, args.group_by, since_ts, until_ts, allocator);\n    } else {\n        try generateText(&output, issues.items, args.group_by, since_ts, until_ts, allocator);\n    }\n}\n\nfn generateMarkdown(output: *Output, issues: []const Issue, group_by: anytype, since: ?i64, until: i64, allocator: std.mem.Allocator) !void {\n    // Header\n    try output.print(\"# Changelog\\n\\n\", .{});\n    \n    if (since) |s| {\n        try output.print(\"Changes from {s} to {s}\\n\\n\", .{\n            try timestamp.formatRfc3339Alloc(allocator, s),\n            try timestamp.formatRfc3339Alloc(allocator, until),\n        });\n    } else {\n        try output.print(\"All changes up to {s}\\n\\n\", .{\n            try timestamp.formatRfc3339Alloc(allocator, until),\n        });\n    }\n    \n    if (issues.len == 0) {\n        try output.print(\"No changes in this period.\\n\", .{});\n        return;\n    }\n    \n    switch (group_by) {\n        .type => {\n            // Group by issue type\n            const types = [_]struct { t: IssueType, label: []const u8 }{\n                .{ .t = .feature, .label = \"Features\" },\n                .{ .t = .bug, .label = \"Bug Fixes\" },\n                .{ .t = .chore, .label = \"Chores\" },\n                .{ .t = .docs, .label = \"Documentation\" },\n                .{ .t = .task, .label = \"Tasks\" },\n            };\n            \n            for (types) |group| {\n                var group_issues = std.ArrayList(Issue).init(allocator);\n                defer group_issues.deinit();\n                \n                for (issues) |issue| {\n                    if (std.meta.eql(issue.issue_type, group.t)) {\n                        try group_issues.append(issue);\n                    }\n                }\n                \n                if (group_issues.items.len > 0) {\n                    try output.print(\"## {s}\\n\\n\", .{group.label});\n                    for (group_issues.items) |issue| {\n                        try output.print(\"- {s} ({s})\\n\", .{ issue.title, issue.id });\n                        if (issue.description) |desc| {\n                            // First line of description as detail\n                            const first_line = if (std.mem.indexOf(u8, desc, \"\\n\")) |idx|\n                                desc[0..idx]\n                            else\n                                desc;\n                            if (first_line.len > 0) {\n                                try output.print(\"  - {s}\\n\", .{first_line});\n                            }\n                        }\n                    }\n                    try output.print(\"\\n\", .{});\n                }\n            }\n        },\n        .priority => {\n            // Group by priority\n            var i: u3 = 0;\n            while (i <= 4) : (i += 1) {\n                var group_issues = std.ArrayList(Issue).init(allocator);\n                defer group_issues.deinit();\n                \n                for (issues) |issue| {\n                    if (issue.priority.value == i) {\n                        try group_issues.append(issue);\n                    }\n                }\n                \n                if (group_issues.items.len > 0) {\n                    const priority = Priority{ .value = i };\n                    try output.print(\"## {s}\\n\\n\", .{priority.toString()});\n                    for (group_issues.items) |issue| {\n                        try output.print(\"- [{s}] {s} ({s})\\n\", .{\n                            issue.issue_type.toString(),\n                            issue.title,\n                            issue.id,\n                        });\n                    }\n                    try output.print(\"\\n\", .{});\n                }\n            }\n        },\n        .none => {\n            // Flat list\n            for (issues) |issue| {\n                try output.print(\"- [{s}] {s} ({s})\\n\", .{\n                    issue.issue_type.toString(),\n                    issue.title,\n                    issue.id,\n                });\n            }\n        },\n    }\n    \n    try output.print(\"---\\n*{d} issue(s) closed*\\n\", .{issues.len});\n}\n\nfn generateText(output: *Output, issues: []const Issue, group_by: anytype, since: ?i64, until: i64, allocator: std.mem.Allocator) !void {\n    // Plain text version\n    try output.print(\"CHANGELOG\\n\", .{});\n    try output.print(\"=========\\n\\n\", .{});\n    \n    for (issues) |issue| {\n        try output.print(\"[{s}] {s}: {s}\\n\", .{\n            issue.issue_type.toString(),\n            issue.id,\n            issue.title,\n        });\n    }\n    \n    try output.print(\"\\n{d} issue(s) closed\\n\", .{issues.len});\n}\n\nfn parseDate(s: []const u8) !i64 {\n    const now = std.time.timestamp();\n    \n    // Try relative format\n    if (s.len >= 2) {\n        const num_str = s[0 .. s.len - 1];\n        const unit = s[s.len - 1];\n        \n        if (std.fmt.parseInt(i64, num_str, 10)) |num| {\n            const seconds: i64 = switch (unit) {\n                'd' => num * 24 * 60 * 60,\n                'w' => num * 7 * 24 * 60 * 60,\n                'm' => num * 30 * 24 * 60 * 60,\n                else => return error.InvalidDateFormat,\n            };\n            return now - seconds;  // \"7d\" means 7 days ago\n        } else |_| {}\n    }\n    \n    return timestamp.parseRfc3339(s);\n}\n```\n\nUpdate main.zig to dispatch to changelog command.\n\n## Validation\n1. Test changelog with --since date\n2. Test changelog with relative dates (7d, 2w, 1m)\n3. Test changelog groups by type\n4. Test changelog groups by priority\n5. Test changelog flat list (--group-by none)\n6. Test markdown format output\n7. Test text format output\n8. Test --json output\n9. Test empty changelog (no closed issues)\n10. `zig build test` passes\n11. Manual test in sandbox/\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-283 (RFC3339 timestamp utilities)\n- bd-abv (issue CRUD operations)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-30T05:38:57.631335082Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:38:57.631335082Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-12h","title":"Implement config command","description":"## Goal\nImplement `bz config` command for managing configuration settings.\n\n## Technical Approach\nCreate `src/cli/config.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Output = @import(\"../output/mod.zig\").Output;\n\npub const ConfigArgs = union(enum) {\n    list: void,\n    get: struct { key: []const u8 },\n    set: struct { key: []const u8, value: []const u8 },\n};\n\npub fn run(args: ConfigArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    switch (args) {\n        .list => try runList(global, allocator),\n        .get => |g| try runGet(g.key, global, allocator),\n        .set => |s| try runSet(s.key, s.value, global, allocator),\n    }\n}\n\nfn runList(global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    const sql = \"SELECT key, value FROM config ORDER BY key\";\n    var stmt = try db.prepare(sql);\n    defer stmt.deinit();\n    \n    var configs = std.ArrayList(ConfigEntry).init(allocator);\n    defer configs.deinit();\n    \n    while (try stmt.step()) {\n        try configs.append(.{\n            .key = try allocator.dupe(u8, stmt.columnText(0).?),\n            .value = try allocator.dupe(u8, stmt.columnText(1).?),\n        });\n    }\n    \n    if (global.json) {\n        try output.printJson(configs.items);\n    } else {\n        if (configs.items.len == 0) {\n            try output.print(\"No configuration values set.\\n\", .{});\n            return;\n        }\n        \n        for (configs.items) |entry| {\n            try output.print(\"{s} = {s}\\n\", .{ entry.key, entry.value });\n        }\n    }\n}\n\nfn runGet(key: []const u8, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    const value = try getConfigValue(&db, key);\n    \n    if (global.json) {\n        try output.printJson(.{ .key = key, .value = value });\n    } else {\n        if (value) |v| {\n            try output.print(\"{s}\\n\", .{v});\n        } else {\n            try output.print(\"(not set)\\n\", .{});\n        }\n    }\n}\n\nfn runSet(key: []const u8, value: []const u8, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    // Validate known keys\n    const valid_keys = [_][]const u8{\n        \"issue_prefix\",\n        \"default_priority\",\n        \"default_issue_type\",\n        \"auto_flush\",\n        \"auto_import\",\n        \"actor\",\n    };\n    \n    var is_valid = false;\n    for (valid_keys) |vk| {\n        if (std.mem.eql(u8, key, vk)) {\n            is_valid = true;\n            break;\n        }\n    }\n    \n    if (!is_valid) {\n        try output.warn(\"Unknown config key '{s}'. Setting anyway.\", .{key});\n    }\n    \n    const sql = \"INSERT OR REPLACE INTO config (key, value) VALUES (?1, ?2)\";\n    var stmt = try db.prepare(sql);\n    defer stmt.deinit();\n    try stmt.bindText(1, key);\n    try stmt.bindText(2, value);\n    _ = try stmt.step();\n    \n    if (global.json) {\n        try output.printJson(.{ .key = key, .value = value, .set = true });\n    } else {\n        try output.success(\"Set {s} = {s}\", .{ key, value });\n    }\n}\n\nconst ConfigEntry = struct {\n    key: []const u8,\n    value: []const u8,\n};\n```\n\n## Validation\n1. Test config --list shows all config\n2. Test config --get retrieves value\n3. Test config --get for non-existent key\n4. Test config --set sets value\n5. Test config --set warns for unknown keys\n6. Test --json output\n7. `zig build test` passes\n8. Manual test in sandbox/\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-30T05:23:25.420897012Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:23:25.420897012Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-15t","title":"Implement Base36 encoding/decoding","description":"## Goal\nImplement Base36 encoding and decoding for issue ID hash generation.\n\n## Technical Approach\nCreate `src/id/base36.zig`:\n\n```zig\nconst std = @import(\"std\");\n\n/// Character set for Base36: 0-9, a-z (lowercase)\nconst CHARSET = \"0123456789abcdefghijklmnopqrstuvwxyz\";\n\n/// Encode a u64 value to Base36 string\n/// Returns slice of buffer containing result\npub fn encode(value: u64, buffer: []u8) []const u8 {\n    if (value == 0) {\n        buffer[0] = '0';\n        return buffer[0..1];\n    }\n    \n    var v = value;\n    var i: usize = buffer.len;\n    while (v > 0) {\n        i -= 1;\n        buffer[i] = CHARSET[@intCast(v % 36)];\n        v /= 36;\n    }\n    return buffer[i..];\n}\n\n/// Encode to heap-allocated string\npub fn encodeAlloc(allocator: std.mem.Allocator, value: u64) ![]u8 {\n    var buf: [13]u8 = undefined;  // Max for u64 in base36\n    const result = encode(value, &buf);\n    return allocator.dupe(u8, result);\n}\n\n/// Decode Base36 string to u64\n/// Returns error for invalid characters or overflow\npub fn decode(s: []const u8) !u64 {\n    if (s.len == 0) return error.EmptyInput;\n    \n    var result: u64 = 0;\n    for (s) |c| {\n        const digit: u64 = switch (c) {\n            '0'...'9' => c - '0',\n            'a'...'z' => c - 'a' + 10,\n            'A'...'Z' => c - 'A' + 10,  // Accept uppercase\n            else => return error.InvalidCharacter,\n        };\n        result = std.math.mul(u64, result, 36) catch return error.Overflow;\n        result = std.math.add(u64, result, digit) catch return error.Overflow;\n    }\n    return result;\n}\n\n/// Calculate encoded length for a value\npub fn encodedLength(value: u64) usize {\n    if (value == 0) return 1;\n    var v = value;\n    var len: usize = 0;\n    while (v > 0) {\n        len += 1;\n        v /= 36;\n    }\n    return len;\n}\n\ntest \"encode decode roundtrip\" {\n    const allocator = std.testing.allocator;\n    const values = [_]u64{ 0, 1, 35, 36, 100, 1000, std.math.maxInt(u64) };\n    for (values) |v| {\n        const encoded = try encodeAlloc(allocator, v);\n        defer allocator.free(encoded);\n        const decoded = try decode(encoded);\n        try std.testing.expectEqual(v, decoded);\n    }\n}\n```\n\nKey details:\n- Lowercase output (matches beads_rust)\n- Accept both cases on input (case-insensitive decode)\n- Handle edge cases (0, max u64)\n- Efficient stack-based encoding with buffer\n\nUpdate `src/id/mod.zig` to export base36 functions.\n\n## Validation\n1. Test encode/decode roundtrip for various values\n2. Test encode produces lowercase\n3. Test decode accepts both cases\n4. Test decode error on invalid chars\n5. Test overflow handling\n6. Test edge cases (0, max u64)\n7. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:02:46.347576562Z","created_by":"hotschmoe","updated_at":"2026-01-30T07:02:30.726759118Z","closed_at":"2026-01-30T07:02:30.726736014Z","close_reason":"Completed successfully","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-177","title":"Implement dep commands","description":"## Goal\nImplement `bz dep` subcommands for dependency management.\n\n## Technical Approach\nCreate `src/cli/dep.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Dependency = @import(\"../models/dependency.zig\").Dependency;\nconst DependencyType = @import(\"../models/dependency.zig\").DependencyType;\nconst DependencyStore = @import(\"../storage/dependencies.zig\").DependencyStore;\nconst EventStore = @import(\"../storage/events.zig\").EventStore;\nconst Output = @import(\"../output/mod.zig\").Output;\n\npub const DepArgs = union(enum) {\n    add: AddArgs,\n    remove: RemoveArgs,\n    list: ListArgs,\n    tree: TreeArgs,\n    cycles: void,\n};\n\npub const AddArgs = struct {\n    child_id: []const u8,     // Issue being blocked\n    parent_id: []const u8,    // Issue doing the blocking\n    dep_type: ?[]const u8 = null,\n};\n\npub const RemoveArgs = struct {\n    child_id: []const u8,\n    parent_id: []const u8,\n};\n\npub const ListArgs = struct {\n    id: []const u8,\n};\n\npub const TreeArgs = struct {\n    id: []const u8,\n    depth: ?u32 = null,\n};\n\npub fn run(args: DepArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    switch (args) {\n        .add => |a| try runAdd(a, global, allocator),\n        .remove => |r| try runRemove(r, global, allocator),\n        .list => |l| try runList(l, global, allocator),\n        .tree => |t| try runTree(t, global, allocator),\n        .cycles => try runCycles(global, allocator),\n    }\n}\n\nfn runAdd(args: AddArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var dep_store = DependencyStore.init(&db, allocator);\n    var issue_store = IssueStore.init(&db, allocator);\n    var event_store = EventStore.init(&db, allocator);\n    \n    // Validate both issues exist\n    _ = try issue_store.get(args.child_id) orelse {\n        try output.err(\"Issue '{s}' not found\", .{args.child_id});\n        return error.IssueNotFound;\n    };\n    _ = try issue_store.get(args.parent_id) orelse {\n        try output.err(\"Issue '{s}' not found\", .{args.parent_id});\n        return error.IssueNotFound;\n    };\n    \n    const dep_type = if (args.dep_type) |t|\n        DependencyType.fromString(t)\n    else\n        .blocks;\n    \n    const actor = global.actor orelse try getActor();\n    const now = std.time.timestamp();\n    \n    // Add dependency (checks for cycles internally)\n    dep_store.add(.{\n        .issue_id = args.child_id,\n        .depends_on_id = args.parent_id,\n        .dep_type = dep_type,\n        .created_at = now,\n        .created_by = actor,\n        .metadata = null,\n        .thread_id = null,\n    }) catch |err| switch (err) {\n        error.CycleDetected => {\n            try output.err(\"Cannot add dependency: would create a cycle\", .{});\n            return err;\n        },\n        error.SelfDependency => {\n            try output.err(\"Cannot add dependency: issue cannot depend on itself\", .{});\n            return err;\n        },\n        else => return err,\n    };\n    \n    // Log event\n    try event_store.log(.{\n        .id = 0,\n        .issue_id = args.child_id,\n        .event_type = .dependency_added,\n        .actor = actor,\n        .old_value = null,\n        .new_value = args.parent_id,\n        .created_at = now,\n    });\n    \n    if (!global.no_auto_flush) {\n        try autoFlush(&db, allocator);\n    }\n    \n    if (global.json) {\n        try output.printJson(.{\n            .child = args.child_id,\n            .parent = args.parent_id,\n            .type = dep_type.toString(),\n        });\n    } else {\n        try output.success(\"{s} now depends on {s}\", .{ args.child_id, args.parent_id });\n    }\n}\n\nfn runRemove(args: RemoveArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var dep_store = DependencyStore.init(&db, allocator);\n    var event_store = EventStore.init(&db, allocator);\n    \n    const actor = global.actor orelse try getActor();\n    const now = std.time.timestamp();\n    \n    try dep_store.remove(args.child_id, args.parent_id);\n    \n    try event_store.log(.{\n        .id = 0,\n        .issue_id = args.child_id,\n        .event_type = .dependency_removed,\n        .actor = actor,\n        .old_value = args.parent_id,\n        .new_value = null,\n        .created_at = now,\n    });\n    \n    if (!global.no_auto_flush) {\n        try autoFlush(&db, allocator);\n    }\n    \n    if (global.json) {\n        try output.printJson(.{ .removed = true });\n    } else {\n        try output.success(\"Removed dependency: {s} -> {s}\", .{ args.child_id, args.parent_id });\n    }\n}\n\nfn runList(args: ListArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var dep_store = DependencyStore.init(&db, allocator);\n    \n    const depends_on = try dep_store.getDependencies(args.id);\n    const dependents = try dep_store.getDependents(args.id);\n    \n    if (global.json) {\n        try output.printJson(.{\n            .id = args.id,\n            .depends_on = depends_on,\n            .dependents = dependents,\n        });\n    } else {\n        try output.printBold(\"Dependencies for {s}\\n\", .{args.id});\n        \n        if (depends_on.len > 0) {\n            try output.print(\"\\nDepends on ({d}):\\n\", .{depends_on.len});\n            for (depends_on) |dep| {\n                try output.print(\"  -> {s} ({s})\\n\", .{ dep.depends_on_id, dep.dep_type.toString() });\n            }\n        } else {\n            try output.print(\"\\nNo dependencies.\\n\", .{});\n        }\n        \n        if (dependents.len > 0) {\n            try output.print(\"\\nBlocking ({d}):\\n\", .{dependents.len});\n            for (dependents) |dep| {\n                try output.print(\"  <- {s} ({s})\\n\", .{ dep.issue_id, dep.dep_type.toString() });\n            }\n        } else {\n            try output.print(\"\\nNot blocking any issues.\\n\", .{});\n        }\n    }\n}\n\nfn runTree(args: TreeArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var dep_store = DependencyStore.init(&db, allocator);\n    var issue_store = IssueStore.init(&db, allocator);\n    \n    const issue = try issue_store.get(args.id) orelse {\n        try output.err(\"Issue '{s}' not found\", .{args.id});\n        return error.IssueNotFound;\n    };\n    \n    if (global.json) {\n        const tree = try buildDepTree(&dep_store, args.id, args.depth orelse 10, allocator);\n        try output.printJson(tree);\n    } else {\n        try output.print(\"{s}  {s}\\n\", .{ issue.id, issue.title });\n        try printDepTree(&output, &dep_store, &issue_store, args.id, 0, args.depth orelse 5, allocator);\n    }\n}\n\nfn printDepTree(output: *Output, dep_store: *DependencyStore, issue_store: *IssueStore, id: []const u8, depth: u32, max_depth: u32, allocator: std.mem.Allocator) !void {\n    if (depth >= max_depth) return;\n    \n    const deps = try dep_store.getDependencies(id);\n    for (deps, 0..) |dep, i| {\n        const is_last = i == deps.len - 1;\n        const prefix = if (is_last) \"  `-- \" else \"  |-- \";\n        \n        const blocker = try issue_store.get(dep.depends_on_id);\n        if (blocker) |b| {\n            try output.print(\"{s: >[1]}{s}{s}  {s}\\n\", .{\n                \"\",\n                depth * 4,\n                prefix,\n                b.id,\n                b.title,\n            });\n            try printDepTree(output, dep_store, issue_store, b.id, depth + 1, max_depth, allocator);\n        }\n    }\n}\n\nfn runCycles(global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var dep_store = DependencyStore.init(&db, allocator);\n    \n    const cycles = try dep_store.detectCycles();\n    \n    if (global.json) {\n        try output.printJson(.{ .cycles = cycles });\n    } else {\n        if (cycles == null or cycles.?.len == 0) {\n            try output.success(\"No dependency cycles detected.\", .{});\n        } else {\n            try output.err(\"Found {d} dependency cycle(s):\\n\", .{cycles.?.len});\n            for (cycles.?) |cycle| {\n                try output.print(\"  \", .{});\n                for (cycle, 0..) |id, i| {\n                    if (i > 0) try output.print(\" -> \", .{});\n                    try output.print(\"{s}\", .{id});\n                }\n                try output.print(\" -> {s} (cycle)\\n\", .{cycle[0]});\n            }\n        }\n    }\n}\n```\n\n## Validation\n1. Test dep add creates dependency\n2. Test dep add rejects cycles\n3. Test dep add rejects self-dependency\n4. Test dep remove removes dependency\n5. Test dep list shows both directions\n6. Test dep tree shows hierarchy\n7. Test dep cycles detects cycles\n8. Test event logging\n9. Test --json output for all subcommands\n10. `zig build test` passes\n11. Manual test in sandbox/\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-2fo (Dependency struct)\n- bd-22m (dependency operations)\n- bd-2hv (event operations)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-30T05:18:16.233274269Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:18:16.233274269Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-19r","title":"Implement Issue struct","description":"## Goal\nImplement the core Issue struct with all fields matching SPEC.md and beads_rust compatibility.\n\n## Technical Approach\nCreate `src/models/issue.zig`:\n\n```zig\nconst Status = @import(\"status.zig\").Status;\nconst Priority = @import(\"priority.zig\").Priority;\nconst IssueType = @import(\"issue_type.zig\").IssueType;\nconst Dependency = @import(\"dependency.zig\").Dependency;\nconst Comment = @import(\"comment.zig\").Comment;\n\npub const Issue = struct {\n    // Identity\n    id: []const u8,                    // \"bd-abc123\" format\n    content_hash: ?[]const u8,         // SHA256 for deduplication\n\n    // Content\n    title: []const u8,                 // Required, 1-500 characters\n    description: ?[]const u8,\n    design: ?[]const u8,\n    acceptance_criteria: ?[]const u8,\n    notes: ?[]const u8,\n\n    // Classification\n    status: Status,\n    priority: Priority,\n    issue_type: IssueType,\n\n    // Assignment\n    assignee: ?[]const u8,\n    owner: ?[]const u8,\n\n    // Timestamps (Unix epoch seconds)\n    created_at: i64,\n    created_by: ?[]const u8,\n    updated_at: i64,\n    closed_at: ?i64,\n    close_reason: ?[]const u8,\n\n    // Scheduling\n    due_at: ?i64,\n    defer_until: ?i64,\n    estimated_minutes: ?i32,\n\n    // External references\n    external_ref: ?[]const u8,         // Link to external tracker\n    source_system: ?[]const u8,        // Where imported from\n\n    // Flags\n    pinned: bool,                      // High-priority display\n    is_template: bool,                 // Template for new issues\n\n    // Embedded relations (populated on read, not stored in issues table)\n    labels: []const []const u8,\n    dependencies: []const Dependency,\n    comments: []const Comment,\n\n    // Validation\n    pub fn validate(self: Issue) !void {\n        if (self.title.len == 0) return error.EmptyTitle;\n        if (self.title.len > 500) return error.TitleTooLong;\n        if (self.id.len == 0) return error.EmptyId;\n    }\n\n    // JSON serialization matching beads_rust JSONL format\n    pub fn jsonStringify(self: Issue, options: std.json.StringifyOptions, writer: anytype) !void {\n        // Serialize with RFC3339 timestamps\n        // Include all fields, null for missing optional fields\n    }\n\n    pub fn jsonParse(allocator: std.mem.Allocator, source: anytype, options: std.json.ParseOptions) !Issue {\n        // Parse RFC3339 timestamps to Unix epoch\n    }\n\n    // Equality check (compares all fields except embedded relations)\n    pub fn eql(a: Issue, b: Issue) bool { ... }\n\n    // Clone with allocator (deep copy)\n    pub fn clone(self: Issue, allocator: std.mem.Allocator) !Issue { ... }\n\n    // Free allocated memory\n    pub fn deinit(self: *Issue, allocator: std.mem.Allocator) void { ... }\n};\n```\n\nKey implementation details:\n- All string fields are slices - lifetime management is caller's responsibility\n- JSON timestamps must be RFC3339 format (e.g., \"2024-01-29T15:30:00Z\")\n- labels, dependencies, comments are embedded for convenience but not part of issues table\n- Validation enforces title constraints\n- clone() performs deep copy for when ownership transfer is needed\n\nUpdate `src/models/mod.zig` to export Issue.\n\n## Validation\n1. Test Issue creation with all fields\n2. Test validation (empty title, title > 500 chars)\n3. Test JSON roundtrip with all field types\n4. Test RFC3339 timestamp parsing/serialization\n5. Test with null optional fields\n6. Test clone and deinit don't leak memory\n7. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-8ev (Status enum)\n- bd-3t8 (Priority struct)\n- bd-4y7 (IssueType enum)\n- bd-2fo (Dependency struct)\n- bd-nwm (Comment struct)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:01:46.913858746Z","created_by":"hotschmoe","updated_at":"2026-01-30T06:48:02.279282622Z","closed_at":"2026-01-30T06:48:02.279258957Z","close_reason":"Completed successfully","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-1bf","title":"Implement history and audit commands","description":"## Goal\nImplement `bz history <id>` and `bz audit` commands for viewing event logs.\n\n## Technical Approach\nCreate `src/cli/history.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Event = @import(\"../models/event.zig\").Event;\nconst EventStore = @import(\"../storage/events.zig\").EventStore;\nconst Output = @import(\"../output/mod.zig\").Output;\n\npub const HistoryArgs = struct {\n    id: []const u8,\n    limit: ?u32 = null,\n};\n\npub fn run(args: HistoryArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var event_store = EventStore.init(&db, allocator);\n    \n    // Verify issue exists\n    var issue_store = IssueStore.init(&db, allocator);\n    _ = try issue_store.get(args.id) orelse {\n        try output.err(\"Issue '{s}' not found\", .{args.id});\n        return error.IssueNotFound;\n    };\n    \n    const events = try event_store.getHistory(args.id);\n    \n    if (global.json) {\n        try output.printJson(events);\n    } else {\n        if (events.len == 0) {\n            try output.print(\"No history for {s}\\n\", .{args.id});\n            return;\n        }\n        \n        try output.printBold(\"History for {s} ({d} events)\\n\\n\", .{ args.id, events.len });\n        \n        for (events) |event| {\n            try output.printDim(\"{s}  \", .{formatTimestamp(event.created_at)});\n            try output.print(\"{s}  \", .{event.actor});\n            try output.printEventType(event.event_type);\n            \n            // Show value changes\n            if (event.old_value != null or event.new_value != null) {\n                try output.print(\": \", .{});\n                if (event.old_value) |old| {\n                    try output.printDim(\"{s}\", .{truncate(old, 30)});\n                }\n                try output.print(\" -> \", .{});\n                if (event.new_value) |new| {\n                    try output.print(\"{s}\", .{truncate(new, 30)});\n                }\n            }\n            try output.print(\"\\n\", .{});\n        }\n    }\n}\n```\n\nCreate `src/cli/audit.zig`:\n\n```zig\npub const AuditArgs = struct {\n    actor: ?[]const u8 = null,\n    event_type: ?[]const u8 = null,\n    since: ?[]const u8 = null,\n    until: ?[]const u8 = null,\n    limit: ?u32 = null,\n};\n\npub fn run(args: AuditArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var event_store = EventStore.init(&db, allocator);\n    \n    const filters = EventStore.AuditFilters{\n        .actor = args.actor,\n        .event_type = if (args.event_type) |t| EventType.fromString(t) else null,\n        .since = if (args.since) |s| try parseDate(s) else null,\n        .until = if (args.until) |u| try parseDate(u) else null,\n        .limit = args.limit orelse 100,\n    };\n    \n    const events = try event_store.getAuditLog(filters);\n    \n    if (global.json) {\n        try output.printJson(events);\n    } else {\n        if (events.len == 0) {\n            try output.print(\"No events found.\\n\", .{});\n            return;\n        }\n        \n        try output.printBold(\"Audit Log ({d} events)\\n\\n\", .{events.len});\n        \n        for (events) |event| {\n            try output.printDim(\"{s}  \", .{formatTimestamp(event.created_at)});\n            try output.print(\"{s: <12}  \", .{event.issue_id});\n            try output.print(\"{s: <15}  \", .{event.actor});\n            try output.printEventType(event.event_type);\n            try output.print(\"\\n\", .{});\n        }\n    }\n}\n```\n\n## Validation\n1. Test history shows events for issue\n2. Test history chronological order\n3. Test audit shows all events\n4. Test audit --actor filter\n5. Test audit --since/--until date filters\n6. Test audit --event-type filter\n7. Test audit --limit\n8. Test --json output for both\n9. `zig build test` passes\n10. Manual test in sandbox/\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-sbg (Event struct)\n- bd-2hv (event operations)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-30T05:20:56.622700676Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:20:56.622700676Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-1c7","title":"Implement comment operations","description":"## Goal\nImplement database operations for issue comments.\n\n## Technical Approach\nCreate `src/storage/comments.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Database = @import(\"sqlite.zig\").Database;\nconst Comment = @import(\"../models/comment.zig\").Comment;\n\npub const CommentStore = struct {\n    db: *Database,\n    allocator: std.mem.Allocator,\n\n    pub fn init(db: *Database, allocator: std.mem.Allocator) CommentStore {\n        return .{ .db = db, .allocator = allocator };\n    }\n\n    /// Add a comment to an issue\n    pub fn add(self: *CommentStore, comment: Comment) !i64 {\n        try comment.validate();\n        \n        const sql = \n            \\\\INSERT INTO comments (issue_id, author, body, created_at)\n            \\\\VALUES (?1, ?2, ?3, ?4)\n        ;\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindText(1, comment.issue_id);\n        try stmt.bindText(2, comment.author);\n        try stmt.bindText(3, comment.body);\n        try stmt.bindInt(4, comment.created_at);\n        _ = try stmt.step();\n        \n        const id = self.db.lastInsertRowId();\n        \n        // Mark issue as dirty\n        try self.markIssueDirty(comment.issue_id);\n        \n        return id;\n    }\n\n    /// Get all comments for an issue\n    pub fn getComments(self: *CommentStore, issue_id: []const u8) ![]Comment {\n        const sql = \n            \\\\SELECT id, issue_id, author, body, created_at\n            \\\\FROM comments\n            \\\\WHERE issue_id = ?1\n            \\\\ORDER BY created_at ASC\n        ;\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindText(1, issue_id);\n        \n        var comments = std.ArrayList(Comment).init(self.allocator);\n        errdefer comments.deinit();\n        \n        while (try stmt.step()) {\n            try comments.append(.{\n                .id = stmt.columnInt(0),\n                .issue_id = try self.allocator.dupe(u8, stmt.columnText(1).?),\n                .author = try self.allocator.dupe(u8, stmt.columnText(2).?),\n                .body = try self.allocator.dupe(u8, stmt.columnText(3).?),\n                .created_at = stmt.columnInt(4),\n            });\n        }\n        \n        return comments.toOwnedSlice();\n    }\n\n    /// Get comment by ID\n    pub fn get(self: *CommentStore, id: i64) !?Comment {\n        const sql = \"SELECT id, issue_id, author, body, created_at FROM comments WHERE id = ?1\";\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindInt(1, id);\n        \n        if (try stmt.step()) {\n            return .{\n                .id = stmt.columnInt(0),\n                .issue_id = try self.allocator.dupe(u8, stmt.columnText(1).?),\n                .author = try self.allocator.dupe(u8, stmt.columnText(2).?),\n                .body = try self.allocator.dupe(u8, stmt.columnText(3).?),\n                .created_at = stmt.columnInt(4),\n            };\n        }\n        return null;\n    }\n\n    /// Count comments for an issue\n    pub fn countComments(self: *CommentStore, issue_id: []const u8) !u32 {\n        const sql = \"SELECT COUNT(*) FROM comments WHERE issue_id = ?1\";\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindText(1, issue_id);\n        _ = try stmt.step();\n        return @intCast(stmt.columnInt(0));\n    }\n\n    fn markIssueDirty(self: *CommentStore, issue_id: []const u8) !void {\n        const sql = \"INSERT OR REPLACE INTO dirty_issues (issue_id, marked_at) VALUES (?1, ?2)\";\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindText(1, issue_id);\n        try stmt.bindInt(2, std.time.timestamp());\n        _ = try stmt.step();\n    }\n};\n```\n\nUpdate `src/storage/mod.zig` to export CommentStore.\n\n## Validation\n1. Test add comment\n2. Test add returns generated ID\n3. Test getComments returns chronological order\n4. Test get by ID\n5. Test countComments\n6. Test validation rejects empty body/author\n7. Test dirty marking\n8. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-2o2 (database schema)\n- bd-nwm (Comment struct)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:06:20.131134225Z","created_by":"hotschmoe","updated_at":"2026-01-30T19:40:42.001181918Z","closed_at":"2026-01-30T19:40:42.001155347Z","close_reason":"Comment operations implemented in IssueStore: addComment(), comments stored in Issue struct","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-1f5","title":"Implement main CLI dispatcher","description":"## Goal\nImplement the main CLI entry point that dispatches to subcommands.\n\n## Technical Approach\nUpdate `src/main.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst args = @import(\"cli/args.zig\");\nconst init = @import(\"cli/init.zig\");\nconst create = @import(\"cli/create.zig\");\nconst show = @import(\"cli/show.zig\");\nconst list = @import(\"cli/list.zig\");\nconst update = @import(\"cli/update.zig\");\nconst close = @import(\"cli/close.zig\");\nconst reopen = @import(\"cli/reopen.zig\");\nconst delete = @import(\"cli/delete.zig\");\nconst ready = @import(\"cli/ready.zig\");\nconst blocked = @import(\"cli/blocked.zig\");\nconst search = @import(\"cli/search.zig\");\nconst dep = @import(\"cli/dep.zig\");\nconst label = @import(\"cli/label.zig\");\nconst comments = @import(\"cli/comments.zig\");\nconst history = @import(\"cli/history.zig\");\nconst audit = @import(\"cli/audit.zig\");\nconst sync = @import(\"cli/sync.zig\");\nconst config = @import(\"cli/config.zig\");\nconst info = @import(\"cli/info.zig\");\nconst stats = @import(\"cli/stats.zig\");\nconst doctor = @import(\"cli/doctor.zig\");\nconst version = @import(\"cli/version.zig\");\nconst schema_cmd = @import(\"cli/schema.zig\");\nconst completions = @import(\"cli/completions.zig\");\nconst Output = @import(\"output/mod.zig\").Output;\n\npub fn main() !void {\n    var gpa = std.heap.GeneralPurposeAllocator(.{}){};\n    defer _ = gpa.deinit();\n    const allocator = gpa.allocator();\n    \n    const argv = try std.process.argsAlloc(allocator);\n    defer std.process.argsFree(allocator, argv);\n    \n    // Skip program name\n    const cli_args = if (argv.len > 1) argv[1..] else &[_][]const u8{};\n    \n    var parser = args.ArgParser.init(allocator, cli_args);\n    const result = parser.parse() catch |err| {\n        var output = Output.init(allocator, .{});\n        try output.err(\"Failed to parse arguments: {s}\", .{@errorName(err)});\n        return err;\n    };\n    \n    // Auto-import if enabled and reading (not mutating)\n    if (!result.global.no_auto_import) {\n        maybeAutoImport(allocator, result.global) catch {};\n    }\n    \n    // Dispatch to command\n    const cmd_result = switch (result.command) {\n        .init => |a| init.run(a, result.global, allocator),\n        .create => |a| create.run(a, result.global, allocator),\n        .q => |a| create.runQuick(a, result.global, allocator),\n        .show => |a| show.run(a, result.global, allocator),\n        .list => |a| list.run(a, result.global, allocator),\n        .update => |a| update.run(a, result.global, allocator),\n        .close => |a| close.run(a, result.global, allocator),\n        .reopen => |a| reopen.run(a, result.global, allocator),\n        .delete => |a| delete.run(a, result.global, allocator),\n        .ready => |a| ready.run(a, result.global, allocator),\n        .blocked => |a| blocked.run(a, result.global, allocator),\n        .search => |a| search.run(a, result.global, allocator),\n        .dep => |a| dep.run(a, result.global, allocator),\n        .label => |a| label.run(a, result.global, allocator),\n        .comments => |a| comments.run(a, result.global, allocator),\n        .history => |a| history.run(a, result.global, allocator),\n        .audit => |a| audit.run(a, result.global, allocator),\n        .sync => |a| sync.run(a, result.global, allocator),\n        .config => |a| config.run(a, result.global, allocator),\n        .info => info.run(result.global, allocator),\n        .stats => stats.run(result.global, allocator),\n        .doctor => doctor.run(result.global, allocator),\n        .version => version.run(result.global, allocator),\n        .schema => schema_cmd.run(result.global, allocator),\n        .completions => |a| completions.run(a, result.global, allocator),\n        .help => |topic| showHelp(topic, allocator),\n    };\n    \n    cmd_result catch |err| {\n        var output = Output.init(allocator, result.global);\n        \n        // Handle specific errors with helpful messages\n        switch (err) {\n            error.NotInitialized => {\n                try output.err(\"Not a beads workspace. Run 'bz init' first.\", .{});\n            },\n            error.IssueNotFound => {}, // Already handled with suggestions\n            error.CycleDetected => {}, // Already handled\n            else => {\n                try output.err(\"{s}\", .{@errorName(err)});\n            },\n        }\n        \n        std.process.exit(1);\n    };\n}\n\nfn showHelp(topic: ?[]const u8, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, .{});\n    \n    if (topic) |t| {\n        // Show help for specific command\n        try output.print(\"Help for '{s}' command...\\n\", .{t});\n        // ... command-specific help\n    } else {\n        // General help\n        try output.print(\n            \\\\bz - beads_zig issue tracker\n            \\\\\n            \\\\USAGE:\n            \\\\    bz <command> [options] [arguments]\n            \\\\\n            \\\\COMMANDS:\n            \\\\    init          Initialize workspace\n            \\\\    create        Create new issue\n            \\\\    q             Quick capture\n            \\\\    show          Display issue details\n            \\\\    update        Update issue\n            \\\\    close         Close issue\n            \\\\    reopen        Reopen issue\n            \\\\    delete        Delete issue (tombstone)\n            \\\\    list          List issues\n            \\\\    ready         Show actionable issues\n            \\\\    blocked       Show blocked issues\n            \\\\    search        Full-text search\n            \\\\    dep           Manage dependencies\n            \\\\    label         Manage labels\n            \\\\    comments      Manage comments\n            \\\\    history       Issue history\n            \\\\    audit         Audit log\n            \\\\    sync          JSONL sync\n            \\\\    config        Configuration\n            \\\\    info          Workspace info\n            \\\\    stats         Statistics\n            \\\\    doctor        Diagnostics\n            \\\\    version       Show version\n            \\\\    schema        Show schema\n            \\\\    completions   Shell completions\n            \\\\\n            \\\\GLOBAL OPTIONS:\n            \\\\    --json            JSON output\n            \\\\    -q, --quiet       Quiet mode\n            \\\\    -v                Verbose (use twice for debug)\n            \\\\    --no-color        Disable colors\n            \\\\    --db <PATH>       Override database path\n            \\\\    --actor <NAME>    Override actor name\n            \\\\\n            \\\\Run 'bz <command> --help' for command-specific help.\n            \\\\\n        , .{});\n    }\n}\n\nfn maybeAutoImport(allocator: std.mem.Allocator, global: anytype) !void {\n    // Check if JSONL is newer than DB and import if so\n    const db_path = \".beads/beads.db\";\n    const jsonl_path = \".beads/issues.jsonl\";\n    \n    const db_mtime = getFileMtime(db_path) catch return;\n    const jsonl_mtime = getFileMtime(jsonl_path) catch return;\n    \n    if (jsonl_mtime > db_mtime) {\n        // Auto-import\n        var db = try openDatabase(allocator, global);\n        defer db.close();\n        \n        var issue_store = IssueStore.init(&db, allocator);\n        var importer = Importer.init(&issue_store, allocator);\n        \n        _ = importer.import(.{\n            .input_path = jsonl_path,\n            .force = false,\n            .dry_run = false,\n        }) catch {};\n    }\n}\n```\n\n## Validation\n1. Test `bz` with no args shows help\n2. Test `bz help` shows help\n3. Test `bz <unknown>` shows error\n4. Test all commands dispatch correctly\n5. Test global flags are parsed\n6. Test error handling with helpful messages\n7. Test auto-import on read commands\n8. Test exit codes (0 success, 1 error)\n9. `zig build` produces working binary\n10. Manual test all commands in sandbox/\n\n## Dependencies\n- All CLI command implementations\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-30T05:26:56.374715816Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:26:56.374715816Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-1lc","title":"Implement WAL compaction","description":"## Goal\nImplement compaction to merge WAL into main JSONL file.\n\n## Technical Approach\nCreate `src/storage/compact.zig`:\n\n```zig\n/// Compact WAL into main file.\n/// 1. Acquire BeadsLock\n/// 2. Load beads.jsonl into memory\n/// 3. Replay beads.wal operations\n/// 4. Write merged state to beads.jsonl.tmp\n/// 5. fsync for durability\n/// 6. Atomic rename over beads.jsonl\n/// 7. Truncate beads.wal\n/// 8. Release lock\npub fn compact() !void;\n\n/// Trigger compaction if WAL exceeds threshold.\n/// Threshold: 100 operations OR 100KB file size.\npub fn maybeCompact() !void;\n\n/// Get current WAL stats for monitoring.\npub fn walStats() !WalStats;\n\npub const WalStats = struct {\n    entry_count: usize,\n    file_size: u64,\n    needs_compaction: bool,\n};\n```\n\nKey requirements:\n- Lock hold time ~10-50ms for typical repos\n- Atomic main file replacement (no partial states visible)\n- Preserve unknown fields for forward compatibility\n\n## Validation\n1. Test compact merges WAL correctly\n2. Test maybeCompact triggers at threshold\n3. Test atomic rename prevents corruption\n4. Test compaction under concurrent reads","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-30T19:42:47.869861287Z","created_by":"hotschmoe","updated_at":"2026-01-30T19:43:59.771597658Z","source_repo":".","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1lc","depends_on_id":"bd-1sd","type":"blocks","created_at":"2026-01-30T19:43:59.771559575Z","created_by":"hotschmoe","metadata":"{}","thread_id":""},{"issue_id":"bd-1lc","depends_on_id":"bd-fw7","type":"blocks","created_at":"2026-01-30T19:43:36.027710617Z","created_by":"hotschmoe","metadata":"{}","thread_id":""}]}
{"id":"bd-1ld","title":"Implement CLI argument parser","description":"## Goal\nImplement command-line argument parsing with support for global flags and subcommands.\n\n## Technical Approach\nCreate `src/cli/args.zig`:\n\n```zig\nconst std = @import(\"std\");\n\n/// Global CLI options that apply to all commands\npub const GlobalOptions = struct {\n    json: bool = false,           // --json: Machine-readable output\n    quiet: bool = false,          // -q, --quiet: Suppress non-essential output\n    verbose: u8 = 0,              // -v, -vv: Verbosity level\n    no_color: bool = false,       // --no-color: Disable ANSI colors\n    db_path: ?[]const u8 = null,  // --db: Override database path\n    actor: ?[]const u8 = null,    // --actor: Override actor name\n    lock_timeout: u32 = 5000,     // --lock-timeout: SQLite busy timeout\n    no_auto_flush: bool = false,  // --no-auto-flush: Skip auto export\n    no_auto_import: bool = false, // --no-auto-import: Skip freshness check\n};\n\n/// All available subcommands\npub const Command = union(enum) {\n    // Workspace\n    init: InitArgs,\n    info: void,\n    stats: void,\n    doctor: void,\n    config: ConfigArgs,\n    \n    // Issue CRUD\n    create: CreateArgs,\n    q: QuickArgs,\n    show: ShowArgs,\n    update: UpdateArgs,\n    close: CloseArgs,\n    reopen: ReopenArgs,\n    delete: DeleteArgs,\n    \n    // Query\n    list: ListArgs,\n    ready: ReadyArgs,\n    blocked: BlockedArgs,\n    search: SearchArgs,\n    stale: StaleArgs,\n    count: CountArgs,\n    \n    // Dependencies\n    dep: DepArgs,\n    \n    // Labels\n    label: LabelArgs,\n    \n    // Comments\n    comments: CommentsArgs,\n    \n    // Audit\n    history: HistoryArgs,\n    audit: AuditArgs,\n    \n    // Sync\n    sync: SyncArgs,\n    \n    // System\n    version: void,\n    schema: void,\n    completions: CompletionsArgs,\n    \n    // Help\n    help: ?[]const u8,\n};\n\n// Subcommand argument structs\npub const InitArgs = struct {\n    prefix: []const u8 = \"bd\",\n};\n\npub const CreateArgs = struct {\n    title: []const u8,\n    description: ?[]const u8 = null,\n    issue_type: ?[]const u8 = null,\n    priority: ?[]const u8 = null,\n    assignee: ?[]const u8 = null,\n    labels: []const []const u8 = &[_][]const u8{},\n    deps: []const []const u8 = &[_][]const u8{},\n    due: ?[]const u8 = null,\n    estimate: ?i32 = null,\n};\n\n// ... other Args structs ...\n\npub const ParseResult = struct {\n    global: GlobalOptions,\n    command: Command,\n};\n\npub const ArgParser = struct {\n    allocator: std.mem.Allocator,\n    args: []const []const u8,\n    index: usize = 0,\n\n    pub fn init(allocator: std.mem.Allocator, args: []const []const u8) ArgParser {\n        return .{ .allocator = allocator, .args = args };\n    }\n\n    pub fn parse(self: *ArgParser) !ParseResult {\n        var global = GlobalOptions{};\n        \n        // Parse global flags first\n        while (self.hasNext()) {\n            const arg = self.peek();\n            if (std.mem.startsWith(u8, arg, \"-\")) {\n                if (try self.parseGlobalFlag(&global)) continue;\n                break; // Unknown flag, let subcommand handle it\n            }\n            break;\n        }\n        \n        // Parse subcommand\n        const cmd_str = self.next() orelse return .{\n            .global = global,\n            .command = .{ .help = null },\n        };\n        \n        const command = try self.parseCommand(cmd_str);\n        \n        return .{\n            .global = global,\n            .command = command,\n        };\n    }\n\n    fn parseGlobalFlag(self: *ArgParser, global: *GlobalOptions) !bool {\n        const arg = self.next().?;\n        \n        if (std.mem.eql(u8, arg, \"--json\")) {\n            global.json = true;\n            return true;\n        }\n        if (std.mem.eql(u8, arg, \"-q\") or std.mem.eql(u8, arg, \"--quiet\")) {\n            global.quiet = true;\n            return true;\n        }\n        if (std.mem.eql(u8, arg, \"-v\")) {\n            global.verbose += 1;\n            return true;\n        }\n        // ... other global flags ...\n        \n        // Put back if not recognized\n        self.index -= 1;\n        return false;\n    }\n\n    fn parseCommand(self: *ArgParser, cmd: []const u8) !Command {\n        if (std.mem.eql(u8, cmd, \"init\")) {\n            return .{ .init = try self.parseInitArgs() };\n        }\n        if (std.mem.eql(u8, cmd, \"create\")) {\n            return .{ .create = try self.parseCreateArgs() };\n        }\n        // ... other commands ...\n        \n        return error.UnknownCommand;\n    }\n\n    fn hasNext(self: *ArgParser) bool {\n        return self.index < self.args.len;\n    }\n\n    fn peek(self: *ArgParser) []const u8 {\n        return self.args[self.index];\n    }\n\n    fn next(self: *ArgParser) ?[]const u8 {\n        if (self.index >= self.args.len) return null;\n        const arg = self.args[self.index];\n        self.index += 1;\n        return arg;\n    }\n};\n```\n\nUpdate `src/cli/mod.zig` to export ArgParser and related types.\n\n## Validation\n1. Test global flag parsing (--json, -v, --quiet, etc.)\n2. Test subcommand parsing\n3. Test subcommand argument parsing\n4. Test unknown command error\n5. Test missing required argument error\n6. Test flag combining (-vv)\n7. Test help command\n8. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:09:31.278295192Z","created_by":"hotschmoe","updated_at":"2026-01-30T20:01:16.661912319Z","closed_at":"2026-01-30T20:01:16.661880138Z","close_reason":"Completed successfully","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-1o5","title":"Implement shell completions command","description":"## Goal\nImplement `bz completions <shell>` for generating shell completion scripts.\n\n## Technical Approach\nCreate `src/cli/completions.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Output = @import(\"../output/mod.zig\").Output;\n\npub const CompletionsArgs = struct {\n    shell: Shell,\n};\n\npub const Shell = enum {\n    bash,\n    zsh,\n    fish,\n    powershell,\n};\n\npub fn run(args: CompletionsArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    \n    const script = switch (args.shell) {\n        .bash => BASH_COMPLETIONS,\n        .zsh => ZSH_COMPLETIONS,\n        .fish => FISH_COMPLETIONS,\n        .powershell => POWERSHELL_COMPLETIONS,\n    };\n    \n    try output.writer.writeAll(script);\n}\n\nconst BASH_COMPLETIONS = \n    \\\\# bash completion for bz\n    \\\\\n    \\\\_bz_completions() {\n    \\\\    local cur prev words cword\n    \\\\    _init_completion || return\n    \\\\\n    \\\\    local commands=\"init create q show update close reopen delete list ready blocked search dep label comments history audit sync config info stats doctor version schema completions\"\n    \\\\\n    \\\\    if [[ $cword -eq 1 ]]; then\n    \\\\        COMPREPLY=($(compgen -W \"$commands\" -- \"$cur\"))\n    \\\\        return\n    \\\\    fi\n    \\\\\n    \\\\    case ${words[1]} in\n    \\\\        show|update|close|reopen|delete|comments|history)\n    \\\\            # Complete with issue IDs\n    \\\\            local ids=$(bz list --quiet 2>/dev/null)\n    \\\\            COMPREPLY=($(compgen -W \"$ids\" -- \"$cur\"))\n    \\\\            ;;\n    \\\\        dep)\n    \\\\            if [[ $cword -eq 2 ]]; then\n    \\\\                COMPREPLY=($(compgen -W \"add remove list tree cycles\" -- \"$cur\"))\n    \\\\            fi\n    \\\\            ;;\n    \\\\        label)\n    \\\\            if [[ $cword -eq 2 ]]; then\n    \\\\                COMPREPLY=($(compgen -W \"add remove list list-all\" -- \"$cur\"))\n    \\\\            fi\n    \\\\            ;;\n    \\\\        completions)\n    \\\\            COMPREPLY=($(compgen -W \"bash zsh fish powershell\" -- \"$cur\"))\n    \\\\            ;;\n    \\\\    esac\n    \\\\}\n    \\\\\n    \\\\complete -F _bz_completions bz\n;\n\nconst ZSH_COMPLETIONS = \n    \\\\#compdef bz\n    \\\\\n    \\\\_bz() {\n    \\\\    local -a commands\n    \\\\    commands=(\n    \\\\        'init:Initialize beads workspace'\n    \\\\        'create:Create new issue'\n    \\\\        'q:Quick capture'\n    \\\\        'show:Display issue details'\n    \\\\        'update:Update issue'\n    \\\\        'close:Close issue'\n    \\\\        'reopen:Reopen issue'\n    \\\\        'delete:Delete issue'\n    \\\\        'list:List issues'\n    \\\\        'ready:Show actionable issues'\n    \\\\        'blocked:Show blocked issues'\n    \\\\        'search:Search issues'\n    \\\\        'dep:Manage dependencies'\n    \\\\        'label:Manage labels'\n    \\\\        'comments:Manage comments'\n    \\\\        'history:Show issue history'\n    \\\\        'audit:View audit log'\n    \\\\        'sync:JSONL sync'\n    \\\\        'config:Manage configuration'\n    \\\\        'info:Workspace info'\n    \\\\        'stats:Project statistics'\n    \\\\        'doctor:Run diagnostics'\n    \\\\        'version:Show version'\n    \\\\        'schema:View database schema'\n    \\\\        'completions:Generate completions'\n    \\\\    )\n    \\\\\n    \\\\    _arguments -C \\\n    \\\\        '1:command:->command' \\\n    \\\\        '*::arg:->args'\n    \\\\\n    \\\\    case $state in\n    \\\\        command)\n    \\\\            _describe 'command' commands\n    \\\\            ;;\n    \\\\    esac\n    \\\\}\n    \\\\\n    \\\\_bz\n;\n\nconst FISH_COMPLETIONS = \n    \\\\# fish completion for bz\n    \\\\\n    \\\\set -l commands init create q show update close reopen delete list ready blocked search dep label comments history audit sync config info stats doctor version schema completions\n    \\\\\n    \\\\complete -c bz -f\n    \\\\complete -c bz -n \"not __fish_seen_subcommand_from $commands\" -a init -d \"Initialize workspace\"\n    \\\\complete -c bz -n \"not __fish_seen_subcommand_from $commands\" -a create -d \"Create issue\"\n    \\\\complete -c bz -n \"not __fish_seen_subcommand_from $commands\" -a q -d \"Quick capture\"\n    \\\\complete -c bz -n \"not __fish_seen_subcommand_from $commands\" -a show -d \"Show issue\"\n    \\\\complete -c bz -n \"not __fish_seen_subcommand_from $commands\" -a list -d \"List issues\"\n    \\\\# ... etc\n;\n\nconst POWERSHELL_COMPLETIONS = \n    \\\\# PowerShell completion for bz\n    \\\\\n    \\\\Register-ArgumentCompleter -Native -CommandName bz -ScriptBlock {\n    \\\\    param($wordToComplete, $commandAst, $cursorPosition)\n    \\\\\n    \\\\    $commands = @(\n    \\\\        @{Name='init'; Description='Initialize workspace'}\n    \\\\        @{Name='create'; Description='Create issue'}\n    \\\\        @{Name='q'; Description='Quick capture'}\n    \\\\        @{Name='show'; Description='Show issue'}\n    \\\\        @{Name='list'; Description='List issues'}\n    \\\\        # ... etc\n    \\\\    )\n    \\\\\n    \\\\    $commands | Where-Object { $_.Name -like \"$wordToComplete*\" } | ForEach-Object {\n    \\\\        [System.Management.Automation.CompletionResult]::new($_.Name, $_.Name, 'ParameterValue', $_.Description)\n    \\\\    }\n    \\\\}\n;\n```\n\n## Validation\n1. Test bash completions syntax is valid\n2. Test zsh completions syntax is valid\n3. Test fish completions syntax is valid\n4. Test powershell completions syntax is valid\n5. Manual test: source and verify completions work\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-30T05:24:32.913624668Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:24:32.913624668Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-1sd","title":"Implement WAL (Write-Ahead Log) operations","description":"## Goal\nImplement Write-Ahead Log for constant-time concurrent writes.\n\n## Technical Approach\nCreate `src/storage/wal.zig`:\n\n```zig\npub const WalOp = enum {\n    add,\n    update,\n    close,\n    reopen,\n    delete,\n    set_blocked,\n    unset_blocked,\n};\n\npub const WalEntry = struct {\n    op: WalOp,\n    ts: i64,           // Unix timestamp for ordering\n    id: []const u8,    // Issue ID\n    data: ?Issue,      // Full issue for add/update, null for status ops\n};\n\n/// Append entry to WAL under lock.\npub fn appendWalEntry(entry: WalEntry) !void;\n\n/// Replay WAL entries onto IssueStore.\npub fn replayWal(store: *IssueStore, file: std.fs.File) !void;\n\n// Convenience wrappers\npub fn addIssue(issue: Issue) !void;\npub fn closeIssue(id: []const u8) !void;\npub fn updateIssue(issue: Issue) !void;\n```\n\nWAL entry format (JSON lines):\n```json\n{\"op\":\"add\",\"ts\":1706540000,\"id\":\"bd-abc123\",\"data\":{...}}\n{\"op\":\"close\",\"ts\":1706540001,\"id\":\"bd-abc123\",\"data\":null}\n```\n\nKey requirements:\n- Acquire BeadsLock before append\n- fsync after write, before lock release\n- WAL file: .beads/beads.wal\n\n## Validation\n1. Test appendWalEntry creates valid JSON line\n2. Test replayWal applies operations correctly\n3. Test operation ordering by timestamp\n4. Test fsync durability","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-30T19:42:15.766136139Z","created_by":"hotschmoe","updated_at":"2026-01-30T19:43:13.853776005Z","source_repo":".","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1sd","depends_on_id":"bd-fw7","type":"blocks","created_at":"2026-01-30T19:43:13.853719477Z","created_by":"hotschmoe","metadata":"{}","thread_id":""}]}
{"id":"bd-220","title":"Implement init command","description":"## Goal\nImplement the `bz init` command to initialize a beads workspace.\n\n## Technical Approach\nCreate `src/cli/init.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Database = @import(\"../storage/sqlite.zig\").Database;\nconst schema = @import(\"../storage/schema.zig\");\nconst Output = @import(\"../output/mod.zig\").Output;\n\npub const InitArgs = struct {\n    prefix: []const u8 = \"bd\",\n};\n\npub fn run(args: InitArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    \n    const beads_dir = \".beads\";\n    \n    // Check if already initialized\n    if (std.fs.cwd().statFile(beads_dir ++ \"/beads.db\")) |_| {\n        return error.AlreadyInitialized;\n    } else |_| {}\n    \n    // Create .beads directory\n    std.fs.cwd().makeDir(beads_dir) catch |err| switch (err) {\n        error.PathAlreadyExists => {}, // OK, directory exists\n        else => return err,\n    };\n    \n    // Create database\n    const db_path = beads_dir ++ \"/beads.db\";\n    var db = try Database.open(allocator, db_path);\n    defer db.close();\n    \n    // Initialize schema\n    try schema.createSchema(&db);\n    \n    // Store initial config\n    try db.exec(\"INSERT INTO config (key, value) VALUES ('issue_prefix', '\" ++ args.prefix ++ \"')\");\n    try db.exec(\"INSERT INTO config (key, value) VALUES ('initialized_at', '\" ++ // current timestamp ++ \"')\");\n    \n    // Create empty config.yaml\n    const config_content = \n        \\\\# beads_zig configuration\n        \\\\id:\n        \\\\  prefix: \"{s}\"\n        \\\\\n        \\\\defaults:\n        \\\\  priority: 2\n        \\\\  issue_type: \"task\"\n        \\\\\n        \\\\sync:\n        \\\\  auto_flush: true\n        \\\\  auto_import: true\n        \\\\\n        \\\\output:\n        \\\\  color: true\n    ;\n    var config_file = try std.fs.cwd().createFile(beads_dir ++ \"/config.yaml\", .{});\n    defer config_file.close();\n    try config_file.writer().print(config_content, .{args.prefix});\n    \n    // Create metadata.json\n    const metadata_content = \n        \\\\{{\n        \\\\  \"schema_version\": 1,\n        \\\\  \"created_at\": \"{s}\",\n        \\\\  \"issue_count\": 0\n        \\\\}}\n    ;\n    var metadata_file = try std.fs.cwd().createFile(beads_dir ++ \"/metadata.json\", .{});\n    defer metadata_file.close();\n    // Write with current timestamp\n    \n    // Create empty issues.jsonl\n    var jsonl_file = try std.fs.cwd().createFile(beads_dir ++ \"/issues.jsonl\", .{});\n    jsonl_file.close();\n    \n    // Success message\n    if (global.json) {\n        try output.printJson(.{\n            .success = true,\n            .path = beads_dir,\n            .prefix = args.prefix,\n        });\n    } else {\n        try output.success(\"Initialized beads workspace in {s}/\", .{beads_dir});\n        try output.print(\"  Issue prefix: {s}\\n\", .{args.prefix});\n        try output.print(\"  Database: {s}/beads.db\\n\", .{beads_dir});\n    }\n}\n```\n\nUpdate main.zig to dispatch to init command.\n\n## Validation\n1. Test init creates .beads directory\n2. Test init creates beads.db with schema\n3. Test init creates config.yaml\n4. Test init creates metadata.json\n5. Test init creates empty issues.jsonl\n6. Test init fails if already initialized\n7. Test --prefix option sets custom prefix\n8. Test --json output format\n9. `zig build test` passes\n10. Manual test in sandbox/: `../zig-out/bin/bz init`\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-2o2 (database schema)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-30T05:10:56.063432139Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:10:56.063432139Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-227","title":"Implement JSONL export","description":"## Goal\nImplement JSONL export for syncing issues to git-trackable format.\n\n## Technical Approach\nCreate `src/sync/export.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Issue = @import(\"../models/issue.zig\").Issue;\nconst timestamp = @import(\"../models/timestamp.zig\");\nconst IssueStore = @import(\"../storage/issues.zig\").IssueStore;\nconst DirtyTracker = @import(\"../storage/dirty.zig\").DirtyTracker;\n\npub const ExportOptions = struct {\n    output_path: []const u8,\n    force: bool = false,           // Force export even if no dirty issues\n    backup: bool = true,           // Backup existing file before overwrite\n};\n\npub const ExportResult = struct {\n    issues_exported: u32,\n    path: []const u8,\n    backup_path: ?[]const u8,\n};\n\npub const Exporter = struct {\n    issue_store: *IssueStore,\n    dirty_tracker: *DirtyTracker,\n    allocator: std.mem.Allocator,\n\n    pub fn init(issue_store: *IssueStore, dirty_tracker: *DirtyTracker, allocator: std.mem.Allocator) Exporter {\n        return .{\n            .issue_store = issue_store,\n            .dirty_tracker = dirty_tracker,\n            .allocator = allocator,\n        };\n    }\n\n    /// Export all issues to JSONL file\n    pub fn export(self: *Exporter, options: ExportOptions) !ExportResult {\n        // Safety check: don't export empty DB over non-empty JSONL\n        const issue_count = try self.countNonTombstoneIssues();\n        if (issue_count == 0 and !options.force) {\n            // Check if JSONL exists and has content\n            if (std.fs.cwd().openFile(options.output_path, .{})) |file| {\n                defer file.close();\n                const stat = try file.stat();\n                if (stat.size > 0) {\n                    return error.WouldOverwriteData;\n                }\n            } else |_| {}\n        }\n\n        // Backup existing file\n        var backup_path: ?[]const u8 = null;\n        if (options.backup) {\n            backup_path = try self.backupFile(options.output_path);\n        }\n\n        // Write to temp file first\n        const temp_path = try std.fmt.allocPrint(self.allocator, \"{s}.tmp\", .{options.output_path});\n        defer self.allocator.free(temp_path);\n\n        var temp_file = try std.fs.cwd().createFile(temp_path, .{});\n        defer temp_file.close();\n\n        var buffered = std.io.bufferedWriter(temp_file.writer());\n        var writer = buffered.writer();\n\n        // Query all non-tombstone issues with relations\n        const issues = try self.issue_store.listWithRelations(.{ .include_tombstones = false });\n        defer self.allocator.free(issues);\n\n        // Sort by ID for deterministic output\n        std.sort.sort(Issue, issues, {}, struct {\n            fn lessThan(_: void, a: Issue, b: Issue) bool {\n                return std.mem.lessThan(u8, a.id, b.id);\n            }\n        }.lessThan);\n\n        // Write each issue as JSON line\n        for (issues, 0..) |issue, i| {\n            if (i > 0) try writer.writeByte('\\n');\n            try self.writeIssueJson(writer, issue);\n        }\n\n        try buffered.flush();\n        temp_file.close();\n\n        // Atomic rename\n        try std.fs.cwd().rename(temp_path, options.output_path);\n\n        // Clear dirty flags\n        try self.dirty_tracker.clearAllDirty();\n\n        return .{\n            .issues_exported = @intCast(issues.len),\n            .path = options.output_path,\n            .backup_path = backup_path,\n        };\n    }\n\n    fn writeIssueJson(self: *Exporter, writer: anytype, issue: Issue) !void {\n        // Serialize issue to JSON with RFC3339 timestamps\n        // This is where timestamp.formatRfc3339 is used\n        try std.json.stringify(issue, .{}, writer);\n    }\n\n    fn countNonTombstoneIssues(self: *Exporter) !u32 {\n        // Count issues excluding tombstones\n    }\n\n    fn backupFile(self: *Exporter, path: []const u8) !?[]const u8 {\n        if (std.fs.cwd().openFile(path, .{})) |_| {\n            const backup = try std.fmt.allocPrint(self.allocator, \"{s}.bak\", .{path});\n            try std.fs.cwd().copyFile(path, path, .{ .name = backup });\n            return backup;\n        } else |_| {\n            return null;\n        }\n    }\n};\n```\n\nUpdate `src/sync/mod.zig` to export Exporter.\n\n## Validation\n1. Test export creates valid JSONL file\n2. Test each line is valid JSON\n3. Test issues are sorted by ID\n4. Test timestamps are RFC3339 format\n5. Test atomic write (temp file + rename)\n6. Test backup creation\n7. Test safety check for empty DB over non-empty JSONL\n8. Test dirty flags are cleared after export\n9. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-19r (Issue struct)\n- bd-283 (RFC3339 timestamps)\n- bd-abv (issue CRUD operations)\n- bd-3rn (dirty tracking)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:08:25.233398045Z","created_by":"hotschmoe","updated_at":"2026-01-30T19:39:23.176356301Z","closed_at":"2026-01-30T19:39:23.176322676Z","close_reason":"JSONL export implemented in IssueStore.saveToFile() with atomic writes (temp + fsync + rename)","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-22m","title":"Implement dependency operations","description":"## Goal\nImplement database operations for issue dependencies including cycle detection.\n\n## Technical Approach\nCreate `src/storage/dependencies.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Database = @import(\"sqlite.zig\").Database;\nconst Dependency = @import(\"../models/dependency.zig\").Dependency;\nconst DependencyType = @import(\"../models/dependency.zig\").DependencyType;\nconst Issue = @import(\"../models/issue.zig\").Issue;\n\npub const DependencyStore = struct {\n    db: *Database,\n    allocator: std.mem.Allocator,\n\n    pub fn init(db: *Database, allocator: std.mem.Allocator) DependencyStore {\n        return .{ .db = db, .allocator = allocator };\n    }\n\n    /// Add a dependency (issue_id depends on depends_on_id)\n    pub fn add(self: *DependencyStore, dep: Dependency) !void {\n        // Check for self-dependency\n        if (std.mem.eql(u8, dep.issue_id, dep.depends_on_id)) {\n            return error.SelfDependency;\n        }\n        \n        // Check for cycles before inserting\n        if (try self.wouldCreateCycle(dep.issue_id, dep.depends_on_id)) {\n            return error.CycleDetected;\n        }\n        \n        const sql = \n            \\\\INSERT INTO dependencies (issue_id, depends_on_id, dep_type, created_at, created_by, metadata, thread_id)\n            \\\\VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7)\n        ;\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindText(1, dep.issue_id);\n        try stmt.bindText(2, dep.depends_on_id);\n        try stmt.bindText(3, dep.dep_type.toString());\n        try stmt.bindInt(4, dep.created_at);\n        try stmt.bindText(5, dep.created_by);\n        try stmt.bindText(6, dep.metadata);\n        try stmt.bindText(7, dep.thread_id);\n        _ = try stmt.step();\n        \n        // Invalidate blocked cache\n        try self.invalidateBlockedCache(dep.issue_id);\n    }\n\n    /// Remove a dependency\n    pub fn remove(self: *DependencyStore, issue_id: []const u8, depends_on_id: []const u8) !void {\n        const sql = \"DELETE FROM dependencies WHERE issue_id = ?1 AND depends_on_id = ?2\";\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindText(1, issue_id);\n        try stmt.bindText(2, depends_on_id);\n        _ = try stmt.step();\n        \n        try self.invalidateBlockedCache(issue_id);\n    }\n\n    /// Get dependencies for an issue (what it depends on)\n    pub fn getDependencies(self: *DependencyStore, issue_id: []const u8) ![]Dependency {\n        const sql = \"SELECT * FROM dependencies WHERE issue_id = ?1\";\n        // Execute and return array\n    }\n\n    /// Get dependents of an issue (what depends on it)\n    pub fn getDependents(self: *DependencyStore, issue_id: []const u8) ![]Dependency {\n        const sql = \"SELECT * FROM dependencies WHERE depends_on_id = ?1\";\n        // Execute and return array\n    }\n\n    /// Check if adding dependency would create a cycle\n    /// Uses DFS from depends_on_id to see if it can reach issue_id\n    fn wouldCreateCycle(self: *DependencyStore, issue_id: []const u8, depends_on_id: []const u8) !bool {\n        var visited = std.StringHashMap(void).init(self.allocator);\n        defer visited.deinit();\n        \n        return try self.dfsReachable(depends_on_id, issue_id, &visited);\n    }\n\n    fn dfsReachable(self: *DependencyStore, from: []const u8, target: []const u8, visited: *std.StringHashMap(void)) !bool {\n        if (std.mem.eql(u8, from, target)) return true;\n        if (visited.contains(from)) return false;\n        try visited.put(from, {});\n        \n        const deps = try self.getDependencies(from);\n        defer self.allocator.free(deps);\n        \n        for (deps) |dep| {\n            if (try self.dfsReachable(dep.depends_on_id, target, visited)) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n    /// Detect all cycles in the dependency graph\n    pub fn detectCycles(self: *DependencyStore) !?[][]const u8 {\n        // Tarjan's algorithm or simple DFS to find all cycles\n        // Return array of cycle paths, or null if no cycles\n    }\n\n    /// Get all issues that are ready (open, not blocked, not deferred)\n    pub fn getReadyIssues(self: *DependencyStore) ![]Issue {\n        const sql = \n            \\\\SELECT i.* FROM issues i\n            \\\\WHERE i.status = 'open'\n            \\\\AND i.defer_until IS NULL OR i.defer_until <= ?1\n            \\\\AND NOT EXISTS (\n            \\\\    SELECT 1 FROM dependencies d\n            \\\\    JOIN issues blocker ON d.depends_on_id = blocker.id\n            \\\\    WHERE d.issue_id = i.id\n            \\\\    AND blocker.status NOT IN ('closed', 'tombstone')\n            \\\\)\n            \\\\ORDER BY i.priority ASC, i.created_at ASC\n        ;\n        // Execute and return issues\n    }\n\n    /// Get all blocked issues\n    pub fn getBlockedIssues(self: *DependencyStore) ![]Issue {\n        const sql = \n            \\\\SELECT DISTINCT i.* FROM issues i\n            \\\\JOIN dependencies d ON d.issue_id = i.id\n            \\\\JOIN issues blocker ON d.depends_on_id = blocker.id\n            \\\\WHERE i.status = 'open'\n            \\\\AND blocker.status NOT IN ('closed', 'tombstone')\n        ;\n        // Execute and return issues\n    }\n\n    // Blocked cache management\n    fn invalidateBlockedCache(self: *DependencyStore, issue_id: []const u8) !void {\n        const sql = \"DELETE FROM blocked_cache WHERE issue_id = ?1\";\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindText(1, issue_id);\n        _ = try stmt.step();\n    }\n\n    pub fn rebuildBlockedCache(self: *DependencyStore) !void {\n        try self.db.exec(\"DELETE FROM blocked_cache\");\n        // Rebuild from dependencies\n    }\n};\n```\n\nUpdate `src/storage/mod.zig` to export DependencyStore.\n\n## Validation\n1. Test add dependency\n2. Test remove dependency\n3. Test getDependencies/getDependents\n4. Test self-dependency rejection\n5. Test cycle detection (A->B->C->A should fail)\n6. Test getReadyIssues excludes blocked\n7. Test getBlockedIssues includes only blocked\n8. Test cache invalidation\n9. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-2o2 (database schema)\n- bd-2fo (Dependency struct)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:05:42.486166309Z","created_by":"hotschmoe","updated_at":"2026-01-30T07:44:49.218372421Z","closed_at":"2026-01-30T07:44:49.218346461Z","close_reason":"Completed successfully","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-236","title":"Implement BeadsError types and helpers","description":"## Goal\nImplement structured error types with helpful error messages.\n\n## Technical Approach\nCreate `src/errors.zig`:\n\n```zig\nconst std = @import(\"std\");\n\n/// All beads-specific errors\npub const BeadsError = error{\n    // Workspace\n    NotInitialized,\n    AlreadyInitialized,\n\n    // Issues\n    IssueNotFound,\n    InvalidIssueId,\n    EmptyTitle,\n    TitleTooLong,\n    InvalidPriority,\n    InvalidStatus,\n    DuplicateIssue,\n\n    // Dependencies\n    CycleDetected,\n    SelfDependency,\n    DependencyNotFound,\n    MaxHierarchyDepthExceeded,\n\n    // Sync\n    MergeConflictDetected,\n    JsonlParseError,\n    ExternalPathNotAllowed,\n    WouldOverwriteData,\n\n    // Database\n    DatabaseError,\n    LockTimeout,\n    TransactionFailed,\n    SchemaVersionMismatch,\n\n    // I/O\n    FileNotFound,\n    PermissionDenied,\n    WriteError,\n\n    // Config\n    InvalidConfigKey,\n    InvalidConfigValue,\n\n    // Comments\n    EmptyCommentBody,\n    EmptyAuthor,\n};\n\n/// Get user-friendly error message\npub fn errorMessage(err: anyerror) []const u8 {\n    return switch (err) {\n        error.NotInitialized => \"Not a beads workspace. Run 'bz init' first.\",\n        error.AlreadyInitialized => \"Workspace already initialized.\",\n        error.IssueNotFound => \"Issue not found.\",\n        error.InvalidIssueId => \"Invalid issue ID format.\",\n        error.EmptyTitle => \"Title cannot be empty.\",\n        error.TitleTooLong => \"Title exceeds 500 character limit.\",\n        error.InvalidPriority => \"Priority must be 0-4 (critical, high, medium, low, backlog).\",\n        error.InvalidStatus => \"Invalid status value.\",\n        error.CycleDetected => \"Cannot add dependency: would create a cycle.\",\n        error.SelfDependency => \"Issue cannot depend on itself.\",\n        error.MaxHierarchyDepthExceeded => \"Maximum hierarchy depth (3 levels) exceeded.\",\n        error.MergeConflictDetected => \"JSONL file contains unresolved merge conflicts.\",\n        error.JsonlParseError => \"Failed to parse JSONL file.\",\n        error.ExternalPathNotAllowed => \"Path must be within .beads/ directory.\",\n        error.WouldOverwriteData => \"Refusing to overwrite data. Use --force to override.\",\n        error.DatabaseError => \"Database operation failed.\",\n        error.LockTimeout => \"Database is locked. Try again later.\",\n        error.FileNotFound => \"File not found.\",\n        error.PermissionDenied => \"Permission denied.\",\n        else => @errorName(err),\n    };\n}\n\n/// Error context with additional information\npub const ErrorContext = struct {\n    err: anyerror,\n    message: ?[]const u8 = null,\n    suggestions: []const []const u8 = &[_][]const u8{},\n    \n    pub fn format(self: ErrorContext, writer: anytype) !void {\n        try writer.print(\"error: {s}\", .{errorMessage(self.err)});\n        \n        if (self.message) |msg| {\n            try writer.print(\"\\n  {s}\", .{msg});\n        }\n        \n        if (self.suggestions.len > 0) {\n            try writer.print(\"\\n\\nDid you mean:\", .{});\n            for (self.suggestions) |suggestion| {\n                try writer.print(\"\\n  {s}\", .{suggestion});\n            }\n        }\n    }\n};\n\n/// Create error context with issue ID suggestions\npub fn issueNotFoundError(allocator: std.mem.Allocator, id: []const u8, similar: []const Issue) ErrorContext {\n    var suggestions = std.ArrayList([]const u8).init(allocator);\n    for (similar) |issue| {\n        const suggestion = std.fmt.allocPrint(allocator, \"{s}  \\\"{s}\\\"\", .{ issue.id, issue.title }) catch continue;\n        suggestions.append(suggestion) catch continue;\n    }\n    \n    return .{\n        .err = error.IssueNotFound,\n        .message = std.fmt.allocPrint(allocator, \"Issue '{s}' not found\", .{id}) catch null,\n        .suggestions = suggestions.items,\n    };\n}\n\n/// Exit code for error type\npub fn exitCode(err: anyerror) u8 {\n    return switch (err) {\n        // User errors (bad input)\n        error.NotInitialized,\n        error.AlreadyInitialized,\n        error.IssueNotFound,\n        error.InvalidIssueId,\n        error.EmptyTitle,\n        error.TitleTooLong,\n        error.InvalidPriority,\n        error.InvalidStatus,\n        error.CycleDetected,\n        error.SelfDependency,\n        error.MergeConflictDetected,\n        error.ExternalPathNotAllowed,\n        => 1,\n        \n        // System errors\n        else => 2,\n    };\n}\n```\n\nUpdate error handling throughout the codebase to use these types.\n\n## Validation\n1. Test errorMessage returns helpful text for all errors\n2. Test ErrorContext formatting\n3. Test issueNotFoundError with suggestions\n4. Test exitCode returns correct values\n5. Integration: verify error messages in CLI output\n6. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-30T05:28:20.666806736Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:28:20.666806736Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-26k","title":"Implement update command","description":"## Goal\nImplement `bz update <id>` command to modify issue fields.\n\n## Technical Approach\nCreate `src/cli/update.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Issue = @import(\"../models/issue.zig\").Issue;\nconst Status = @import(\"../models/status.zig\").Status;\nconst Priority = @import(\"../models/priority.zig\").Priority;\nconst IssueType = @import(\"../models/issue_type.zig\").IssueType;\nconst IssueStore = @import(\"../storage/issues.zig\").IssueStore;\nconst EventStore = @import(\"../storage/events.zig\").EventStore;\nconst Event = @import(\"../models/event.zig\").Event;\nconst Output = @import(\"../output/mod.zig\").Output;\n\npub const UpdateArgs = struct {\n    id: []const u8,\n    title: ?[]const u8 = null,\n    description: ?[]const u8 = null,\n    design: ?[]const u8 = null,\n    acceptance_criteria: ?[]const u8 = null,\n    notes: ?[]const u8 = null,\n    status: ?[]const u8 = null,\n    priority: ?[]const u8 = null,\n    issue_type: ?[]const u8 = null,\n    assignee: ?[]const u8 = null,\n    owner: ?[]const u8 = null,\n    due: ?[]const u8 = null,\n    estimate: ?i32 = null,\n    clear_assignee: bool = false,\n    clear_due: bool = false,\n    pin: bool = false,\n    unpin: bool = false,\n};\n\npub fn run(args: UpdateArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    \n    // Open database\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var issue_store = IssueStore.init(&db, allocator);\n    var event_store = EventStore.init(&db, allocator);\n    \n    // Get existing issue\n    const existing = try issue_store.get(args.id) orelse {\n        try output.err(\"Issue '{s}' not found\", .{args.id});\n        return error.IssueNotFound;\n    };\n    \n    const actor = global.actor orelse try getActor();\n    const now = std.time.timestamp();\n    \n    // Build update struct\n    var updates = IssueStore.IssueUpdate{};\n    var events = std.ArrayList(Event).init(allocator);\n    defer events.deinit();\n    \n    // Track changes for event logging\n    if (args.title) |t| {\n        if (!std.mem.eql(u8, t, existing.title)) {\n            updates.title = t;\n            try events.append(Event.fieldChange(args.id, actor, \"title\", existing.title, t, now));\n        }\n    }\n    \n    if (args.status) |s| {\n        const new_status = Status.fromString(s);\n        if (!std.meta.eql(new_status, existing.status)) {\n            updates.status = new_status;\n            try events.append(Event.statusChange(args.id, actor, existing.status, new_status, now));\n        }\n    }\n    \n    if (args.priority) |p| {\n        const new_priority = try Priority.fromString(p);\n        if (new_priority.value != existing.priority.value) {\n            updates.priority = new_priority;\n            try events.append(Event.priorityChange(args.id, actor, existing.priority, new_priority, now));\n        }\n    }\n    \n    if (args.assignee) |a| {\n        if (existing.assignee == null or !std.mem.eql(u8, a, existing.assignee.?)) {\n            updates.assignee = a;\n            try events.append(Event.assigneeChange(args.id, actor, existing.assignee, a, now));\n        }\n    } else if (args.clear_assignee) {\n        if (existing.assignee != null) {\n            updates.assignee = null;\n            updates.clear_assignee = true;\n            try events.append(Event.assigneeChange(args.id, actor, existing.assignee, null, now));\n        }\n    }\n    \n    // ... handle other fields similarly ...\n    \n    if (args.pin) updates.pinned = true;\n    if (args.unpin) updates.pinned = false;\n    \n    // Check if anything changed\n    if (events.items.len == 0) {\n        try output.warn(\"No changes to apply\", .{});\n        return;\n    }\n    \n    // Apply updates in transaction\n    try db.exec(\"BEGIN IMMEDIATE\");\n    errdefer db.exec(\"ROLLBACK\") catch {};\n    \n    try issue_store.update(args.id, updates);\n    \n    for (events.items) |event| {\n        try event_store.log(event);\n    }\n    \n    try db.exec(\"COMMIT\");\n    \n    // Auto-flush\n    if (!global.no_auto_flush) {\n        try autoFlush(&db, allocator);\n    }\n    \n    // Output\n    if (global.json) {\n        const updated = try issue_store.get(args.id);\n        try output.printJson(updated);\n    } else {\n        try output.success(\"Updated issue {s}\", .{args.id});\n        for (events.items) |event| {\n            try output.print(\"  {s}: {s} -> {s}\\n\", .{\n                @tagName(event.event_type),\n                event.old_value orelse \"(none)\",\n                event.new_value orelse \"(none)\",\n            });\n        }\n    }\n}\n```\n\nUpdate main.zig to dispatch to update command.\n\n## Validation\n1. Test update single field\n2. Test update multiple fields\n3. Test status change\n4. Test priority change\n5. Test assignee change (set and clear)\n6. Test no-op when nothing changes\n7. Test event logging for each change\n8. Test auto-flush\n9. Test --json output\n10. Test issue not found error\n11. `zig build test` passes\n12. Manual test in sandbox/\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-19r (Issue struct)\n- bd-abv (issue CRUD)\n- bd-2hv (event operations)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-30T05:13:38.085015426Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:13:38.085015426Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-283","title":"Implement RFC3339 timestamp utilities","description":"## Goal\nImplement RFC3339 timestamp parsing and formatting utilities for JSONL compatibility.\n\n## Technical Approach\nCreate `src/models/timestamp.zig`:\n\n```zig\nconst std = @import(\"std\");\n\n/// Parse RFC3339 timestamp string to Unix epoch seconds\n/// Example: \"2024-01-29T15:30:00Z\" -> 1706538600\npub fn parseRfc3339(s: []const u8) !i64 {\n    // Parse format: YYYY-MM-DDTHH:MM:SSZ or YYYY-MM-DDTHH:MM:SS+HH:MM\n    // Use std.time for calendar calculations\n    // Handle timezone offsets\n}\n\n/// Format Unix epoch seconds as RFC3339 string (UTC)\n/// Example: 1706538600 -> \"2024-01-29T15:30:00Z\"\npub fn formatRfc3339(timestamp: i64, buffer: []u8) ![]const u8 {\n    // Always output in UTC (Z suffix)\n    // Format: YYYY-MM-DDTHH:MM:SSZ\n}\n\n/// Format to heap-allocated string\npub fn formatRfc3339Alloc(allocator: std.mem.Allocator, timestamp: i64) ![]u8 {\n    var buf: [30]u8 = undefined;\n    const result = try formatRfc3339(timestamp, &buf);\n    return allocator.dupe(u8, result);\n}\n\n/// Get current time as Unix epoch seconds\npub fn now() i64 {\n    return std.time.timestamp();\n}\n\ntest \"parseRfc3339 basic\" {\n    const ts = try parseRfc3339(\"2024-01-29T15:30:00Z\");\n    // Verify expected value\n}\n\ntest \"formatRfc3339 roundtrip\" {\n    const original: i64 = 1706538600;\n    var buf: [30]u8 = undefined;\n    const formatted = try formatRfc3339(original, &buf);\n    const parsed = try parseRfc3339(formatted);\n    try std.testing.expectEqual(original, parsed);\n}\n```\n\nKey details:\n- Always store internally as Unix epoch seconds (i64)\n- Always serialize to JSON as RFC3339 UTC string\n- Parse accepts both Z suffix and explicit +00:00 offset\n- Parsing should handle optional fractional seconds (ignore them)\n\nUpdate `src/models/mod.zig` to export timestamp utilities.\n\n## Validation\n1. Test parsing various RFC3339 formats\n2. Test formatting produces valid RFC3339\n3. Test roundtrip (format -> parse -> same value)\n4. Test edge cases (epoch 0, negative timestamps, year 2038+)\n5. Test timezone offset parsing\n6. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:01:53.945844463Z","created_by":"hotschmoe","updated_at":"2026-01-30T06:57:07.767887249Z","closed_at":"2026-01-30T06:57:07.767864046Z","close_reason":"Completed successfully","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2a4","title":"Implement version and schema commands","description":"## Goal\nImplement `bz version` and `bz schema` utility commands.\n\n## Technical Approach\nCreate `src/cli/version.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Output = @import(\"../output/mod.zig\").Output;\nconst builtin = @import(\"builtin\");\n\npub const VERSION = \"0.1.0\";\npub const BUILD_DATE = @embedFile(\"build_date.txt\");  // Generated at build time\n\npub fn run(global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    \n    if (global.json) {\n        try output.printJson(.{\n            .version = VERSION,\n            .zig_version = builtin.zig_version_string,\n            .target = @tagName(builtin.target.os.tag) ++ \"-\" ++ @tagName(builtin.target.cpu.arch),\n        });\n    } else {\n        try output.print(\"bz {s}\\n\", .{VERSION});\n        try output.print(\"zig {s}\\n\", .{builtin.zig_version_string});\n        try output.print(\"{s}-{s}\\n\", .{\n            @tagName(builtin.target.os.tag),\n            @tagName(builtin.target.cpu.arch),\n        });\n    }\n}\n```\n\nCreate `src/cli/schema.zig`:\n\n```zig\npub fn run(global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    const sql = \n        \\\\SELECT name, type, sql FROM sqlite_master\n        \\\\WHERE type IN ('table', 'index', 'trigger')\n        \\\\AND name NOT LIKE 'sqlite_%'\n        \\\\ORDER BY type, name\n    ;\n    \n    var stmt = try db.prepare(sql);\n    defer stmt.deinit();\n    \n    var objects = std.ArrayList(SchemaObject).init(allocator);\n    defer objects.deinit();\n    \n    while (try stmt.step()) {\n        try objects.append(.{\n            .name = try allocator.dupe(u8, stmt.columnText(0).?),\n            .obj_type = try allocator.dupe(u8, stmt.columnText(1).?),\n            .sql = if (stmt.columnText(2)) |s| try allocator.dupe(u8, s) else null,\n        });\n    }\n    \n    if (global.json) {\n        try output.printJson(objects.items);\n    } else {\n        var current_type: ?[]const u8 = null;\n        \n        for (objects.items) |obj| {\n            if (current_type == null or !std.mem.eql(u8, current_type.?, obj.obj_type)) {\n                current_type = obj.obj_type;\n                try output.print(\"\\n-- {s}s --\\n\", .{obj.obj_type});\n            }\n            \n            if (obj.sql) |sql_stmt| {\n                try output.print(\"{s};\\n\\n\", .{sql_stmt});\n            } else {\n                try output.print(\"-- {s} (auto-generated)\\n\", .{obj.name});\n            }\n        }\n    }\n}\n\nconst SchemaObject = struct {\n    name: []const u8,\n    obj_type: []const u8,\n    sql: ?[]const u8,\n};\n```\n\n## Validation\n1. Test version displays version info\n2. Test version --json format\n3. Test schema displays all tables\n4. Test schema displays indexes\n5. Test schema --json format\n6. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-30T05:23:58.056458376Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:23:58.056458376Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2bv","title":"Implement list command","description":"## Goal\nImplement `bz list` command with filtering, sorting, and pagination.\n\n## Technical Approach\nCreate `src/cli/list.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Issue = @import(\"../models/issue.zig\").Issue;\nconst Status = @import(\"../models/status.zig\").Status;\nconst Priority = @import(\"../models/priority.zig\").Priority;\nconst IssueType = @import(\"../models/issue_type.zig\").IssueType;\nconst IssueStore = @import(\"../storage/issues.zig\").IssueStore;\nconst Output = @import(\"../output/mod.zig\").Output;\n\npub const ListArgs = struct {\n    status: ?[]const u8 = null,\n    priority: ?[]const u8 = null,\n    issue_type: ?[]const u8 = null,\n    assignee: ?[]const u8 = null,\n    label: ?[]const u8 = null,\n    limit: ?u32 = null,\n    offset: ?u32 = null,\n    sort: enum { created, updated, priority } = .created,\n    desc: bool = true,\n    all: bool = false,  // Include closed/tombstone\n};\n\npub fn run(args: ListArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    \n    // Open database\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var issue_store = IssueStore.init(&db, allocator);\n    \n    // Build filters\n    const filters = IssueStore.ListFilters{\n        .status = if (args.status) |s| Status.fromString(s) else null,\n        .priority = if (args.priority) |p| try Priority.fromString(p) else null,\n        .issue_type = if (args.issue_type) |t| IssueType.fromString(t) else null,\n        .assignee = args.assignee,\n        .label = args.label,\n        .include_tombstones = args.all,\n        .limit = args.limit orelse 50,\n        .offset = args.offset,\n        .order_by = switch (args.sort) {\n            .created => .created_at,\n            .updated => .updated_at,\n            .priority => .priority,\n        },\n        .order_desc = args.desc,\n    };\n    \n    const issues = try issue_store.list(filters);\n    defer allocator.free(issues);\n    \n    if (global.json) {\n        try output.printJson(issues);\n    } else if (global.quiet) {\n        for (issues) |issue| {\n            try output.print(\"{s}\\n\", .{issue.id});\n        }\n    } else {\n        if (issues.len == 0) {\n            try output.print(\"No issues found.\\n\", .{});\n            return;\n        }\n        \n        try printIssueTable(&output, issues);\n        \n        // Summary\n        try output.print(\"\\n{d} issue(s)\", .{issues.len});\n        if (args.limit != null and issues.len == args.limit.?) {\n            try output.print(\" (limit reached)\", .{});\n        }\n        try output.print(\"\\n\", .{});\n    }\n}\n\nfn printIssueTable(output: *Output, issues: []const Issue) !void {\n    // Calculate column widths\n    var id_width: usize = 10;\n    var title_width: usize = 40;\n    \n    for (issues) |issue| {\n        id_width = @max(id_width, issue.id.len);\n        title_width = @max(title_width, @min(issue.title.len, 60));\n    }\n    \n    // Header\n    try output.printDim(\"ID\");\n    try output.print(\"{s: <[1]}\", .{ \"\", id_width - 2 });\n    try output.print(\"  \");\n    try output.printDim(\"Status\");\n    try output.print(\"     \");\n    try output.printDim(\"Pri\");\n    try output.print(\"  \");\n    try output.printDim(\"Title\\n\");\n    try output.printDim(\"{s:-<[1]}\\n\", .{ \"\", id_width + title_width + 20 });\n    \n    // Rows\n    for (issues) |issue| {\n        // ID\n        try output.print(\"{s: <[1]}  \", .{ issue.id, id_width });\n        \n        // Status (colored, 8 chars)\n        try output.printStatus(issue.status);\n        try output.print(\"  \");\n        \n        // Priority (colored, 3 chars)\n        try output.printPriority(issue.priority);\n        try output.print(\"  \");\n        \n        // Title (truncated)\n        const display_title = if (issue.title.len > title_width) \n            issue.title[0..title_width - 3] ++ \"...\"\n        else \n            issue.title;\n        try output.print(\"{s}\\n\", .{display_title});\n    }\n}\n```\n\nUpdate main.zig to dispatch to list command.\n\n## Validation\n1. Test list returns issues\n2. Test --status filter\n3. Test --priority filter\n4. Test --type filter\n5. Test --assignee filter\n6. Test --label filter\n7. Test --limit and --offset pagination\n8. Test --sort options (created, updated, priority)\n9. Test --desc/--asc ordering\n10. Test --all includes closed/tombstone\n11. Test --json output\n12. Test --quiet output (IDs only)\n13. Test empty result message\n14. `zig build test` passes\n15. Manual test in sandbox/\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-19r (Issue struct)\n- bd-abv (issue CRUD)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-30T05:13:11.000416221Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:13:11.000416221Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2dd","title":"Implement YAML config parser","description":"## Goal\nImplement YAML configuration file parsing for .beads/config.yaml.\n\n## Technical Approach\nCreate `src/config/yaml.zig`:\n\n```zig\nconst std = @import(\"std\");\n\n/// Minimal YAML parser for beads config files\n/// Only supports the subset needed for config.yaml:\n/// - String values\n/// - Integer values\n/// - Boolean values (true/false)\n/// - Nested keys with indentation\n/// - Comments starting with #\n\npub const YamlValue = union(enum) {\n    string: []const u8,\n    integer: i64,\n    boolean: bool,\n    map: std.StringHashMap(YamlValue),\n};\n\npub const YamlParser = struct {\n    allocator: std.mem.Allocator,\n    content: []const u8,\n    pos: usize = 0,\n    line: usize = 1,\n\n    pub fn init(allocator: std.mem.Allocator, content: []const u8) YamlParser {\n        return .{ .allocator = allocator, .content = content };\n    }\n\n    pub fn parse(self: *YamlParser) !std.StringHashMap(YamlValue) {\n        var root = std.StringHashMap(YamlValue).init(self.allocator);\n        try self.parseMap(&root, 0);\n        return root;\n    }\n\n    fn parseMap(self: *YamlParser, map: *std.StringHashMap(YamlValue), indent: usize) !void {\n        while (self.pos < self.content.len) {\n            self.skipWhitespaceAndComments();\n            if (self.pos >= self.content.len) break;\n            \n            const line_indent = self.countIndent();\n            if (line_indent < indent) break;  // Dedent, return to parent\n            \n            const key = try self.parseKey();\n            self.skipColon();\n            \n            // Check if value is on same line or nested\n            self.skipInlineWhitespace();\n            \n            if (self.peekNewline()) {\n                // Nested map\n                self.skipNewline();\n                var nested = std.StringHashMap(YamlValue).init(self.allocator);\n                try self.parseMap(&nested, line_indent + 2);\n                try map.put(key, .{ .map = nested });\n            } else {\n                // Inline value\n                const value = try self.parseValue();\n                try map.put(key, value);\n                self.skipToEndOfLine();\n            }\n        }\n    }\n\n    fn parseKey(self: *YamlParser) ![]const u8 {\n        const start = self.pos;\n        while (self.pos < self.content.len) {\n            const c = self.content[self.pos];\n            if (c == ':' or c == '\\n' or c == ' ') break;\n            self.pos += 1;\n        }\n        return self.content[start..self.pos];\n    }\n\n    fn parseValue(self: *YamlParser) !YamlValue {\n        self.skipInlineWhitespace();\n        \n        const start = self.pos;\n        \n        // Check for quoted string\n        if (self.content[self.pos] == '\"') {\n            self.pos += 1;\n            const str_start = self.pos;\n            while (self.pos < self.content.len and self.content[self.pos] != '\"') {\n                self.pos += 1;\n            }\n            const str = self.content[str_start..self.pos];\n            self.pos += 1;  // Skip closing quote\n            return .{ .string = str };\n        }\n        \n        // Read unquoted value\n        while (self.pos < self.content.len) {\n            const c = self.content[self.pos];\n            if (c == '\\n' or c == '#') break;\n            self.pos += 1;\n        }\n        \n        var value = std.mem.trim(u8, self.content[start..self.pos], \" \\t\");\n        \n        // Try to parse as boolean\n        if (std.mem.eql(u8, value, \"true\")) return .{ .boolean = true };\n        if (std.mem.eql(u8, value, \"false\")) return .{ .boolean = false };\n        \n        // Try to parse as integer\n        if (std.fmt.parseInt(i64, value, 10)) |int| {\n            return .{ .integer = int };\n        } else |_| {}\n        \n        return .{ .string = value };\n    }\n\n    // ... helper functions ...\n};\n\n/// Load and parse config from file path\npub fn loadConfig(allocator: std.mem.Allocator, path: []const u8) !std.StringHashMap(YamlValue) {\n    const file = try std.fs.cwd().openFile(path, .{});\n    defer file.close();\n    const content = try file.readToEndAlloc(allocator, 1024 * 1024);\n    defer allocator.free(content);\n    \n    var parser = YamlParser.init(allocator, content);\n    return parser.parse();\n}\n\n/// Get nested value using dot notation: \"id.prefix\"\npub fn getNestedValue(root: std.StringHashMap(YamlValue), path: []const u8) ?YamlValue {\n    var current = root;\n    var parts = std.mem.split(u8, path, \".\");\n    \n    while (parts.next()) |part| {\n        const val = current.get(part) orelse return null;\n        switch (val) {\n            .map => |m| current = m,\n            else => return val,\n        }\n    }\n    return null;\n}\n\ntest \"parse simple config\" {\n    const content =\n        \\\\id:\n        \\\\  prefix: \"bd\"\n        \\\\  min_hash_length: 3\n        \\\\\n        \\\\defaults:\n        \\\\  priority: 2\n        \\\\\n        \\\\sync:\n        \\\\  auto_flush: true\n    ;\n    \n    var parser = YamlParser.init(std.testing.allocator, content);\n    const config = try parser.parse();\n    defer config.deinit();\n    \n    const prefix = getNestedValue(config, \"id.prefix\").?;\n    try std.testing.expectEqualStrings(\"bd\", prefix.string);\n}\n```\n\nUpdate `src/config/mod.zig` to export YAML functions.\n\n## Validation\n1. Test parse string values\n2. Test parse integer values\n3. Test parse boolean values\n4. Test parse nested maps\n5. Test comments are ignored\n6. Test quoted strings\n7. Test loadConfig from file\n8. Test getNestedValue with dot notation\n9. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-30T05:26:10.546923738Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:26:10.546923738Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2do","title":"Implement create and q commands","description":"## Goal\nImplement `bz create` (full issue creation) and `bz q` (quick capture) commands.\n\n## Technical Approach\nCreate `src/cli/create.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Issue = @import(\"../models/issue.zig\").Issue;\nconst Status = @import(\"../models/status.zig\").Status;\nconst Priority = @import(\"../models/priority.zig\").Priority;\nconst IssueType = @import(\"../models/issue_type.zig\").IssueType;\nconst IssueStore = @import(\"../storage/issues.zig\").IssueStore;\nconst LabelStore = @import(\"../storage/labels.zig\").LabelStore;\nconst DependencyStore = @import(\"../storage/dependencies.zig\").DependencyStore;\nconst EventStore = @import(\"../storage/events.zig\").EventStore;\nconst IdGenerator = @import(\"../id/generator.zig\").IdGenerator;\nconst contentHash = @import(\"../id/hash.zig\").contentHash;\nconst Output = @import(\"../output/mod.zig\").Output;\n\npub const CreateArgs = struct {\n    title: []const u8,\n    description: ?[]const u8 = null,\n    design: ?[]const u8 = null,\n    acceptance_criteria: ?[]const u8 = null,\n    notes: ?[]const u8 = null,\n    issue_type: ?[]const u8 = null,\n    priority: ?[]const u8 = null,\n    assignee: ?[]const u8 = null,\n    owner: ?[]const u8 = null,\n    labels: []const []const u8 = &[_][]const u8{},\n    deps: []const []const u8 = &[_][]const u8{},\n    due: ?[]const u8 = null,\n    estimate: ?i32 = null,\n    external_ref: ?[]const u8 = null,\n    pinned: bool = false,\n    is_template: bool = false,\n};\n\npub fn run(args: CreateArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    \n    // Validate title\n    if (args.title.len == 0) {\n        try output.err(\"Title cannot be empty\", .{});\n        return error.EmptyTitle;\n    }\n    if (args.title.len > 500) {\n        try output.err(\"Title exceeds 500 character limit\", .{});\n        return error.TitleTooLong;\n    }\n    \n    // Open database\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var issue_store = IssueStore.init(&db, allocator);\n    var label_store = LabelStore.init(&db, allocator);\n    var dep_store = DependencyStore.init(&db, allocator);\n    var event_store = EventStore.init(&db, allocator);\n    \n    // Get config\n    const prefix = try getConfigValue(&db, \"issue_prefix\") orelse \"bd\";\n    const actor = global.actor orelse try getActor();\n    \n    // Generate ID\n    var id_gen = IdGenerator.init(prefix);\n    const issue_count = try issue_store.count(.{});\n    const id = try id_gen.generate(allocator, issue_count);\n    \n    // Parse optional fields\n    const priority = if (args.priority) |p| try Priority.fromString(p) else Priority.MEDIUM;\n    const issue_type = if (args.issue_type) |t| IssueType.fromString(t) else .task;\n    const due_at = if (args.due) |d| try parseDate(d) else null;\n    \n    const now = std.time.timestamp();\n    \n    // Create issue\n    var issue = Issue{\n        .id = id,\n        .content_hash = null, // Computed below\n        .title = args.title,\n        .description = args.description,\n        .design = args.design,\n        .acceptance_criteria = args.acceptance_criteria,\n        .notes = args.notes,\n        .status = .open,\n        .priority = priority,\n        .issue_type = issue_type,\n        .assignee = args.assignee,\n        .owner = args.owner,\n        .created_at = now,\n        .created_by = actor,\n        .updated_at = now,\n        .closed_at = null,\n        .close_reason = null,\n        .due_at = due_at,\n        .defer_until = null,\n        .estimated_minutes = args.estimate,\n        .external_ref = args.external_ref,\n        .source_system = null,\n        .pinned = args.pinned,\n        .is_template = args.is_template,\n        .labels = &[_][]const u8{},\n        .dependencies = &[_]Dependency{},\n        .comments = &[_]Comment{},\n    };\n    \n    // Compute content hash\n    issue.content_hash = &contentHash(issue);\n    \n    // Insert in transaction\n    try db.exec(\"BEGIN IMMEDIATE\");\n    errdefer db.exec(\"ROLLBACK\") catch {};\n    \n    try issue_store.insert(issue);\n    \n    // Add labels\n    if (args.labels.len > 0) {\n        try label_store.addMany(id, args.labels);\n    }\n    \n    // Add dependencies\n    for (args.deps) |dep_id| {\n        try dep_store.add(.{\n            .issue_id = id,\n            .depends_on_id = dep_id,\n            .dep_type = .blocks,\n            .created_at = now,\n            .created_by = actor,\n            .metadata = null,\n            .thread_id = null,\n        });\n    }\n    \n    // Log creation event\n    try event_store.log(.{\n        .id = 0,\n        .issue_id = id,\n        .event_type = .created,\n        .actor = actor,\n        .old_value = null,\n        .new_value = try std.json.stringifyAlloc(allocator, issue, .{}),\n        .created_at = now,\n    });\n    \n    try db.exec(\"COMMIT\");\n    \n    // Auto-flush if enabled\n    if (!global.no_auto_flush) {\n        try autoFlush(&db, allocator);\n    }\n    \n    // Output\n    if (global.json) {\n        try output.printJson(.{ .id = id, .title = issue.title });\n    } else {\n        try output.success(\"Created issue {s}\", .{id});\n    }\n}\n\n/// Quick capture - create + print ID only\npub fn runQuick(args: struct { title: []const u8 }, global: anytype, allocator: std.mem.Allocator) !void {\n    // Force quiet mode for q command\n    var quiet_global = global;\n    quiet_global.quiet = true;\n    \n    try run(.{ .title = args.title }, quiet_global, allocator);\n}\n```\n\nUpdate main.zig to dispatch to create/q commands.\n\n## Validation\n1. Test create issue with minimal args (just title)\n2. Test create with all optional fields\n3. Test title validation (empty, too long)\n4. Test ID generation\n5. Test content hash computation\n6. Test label addition\n7. Test dependency addition\n8. Test event logging\n9. Test auto-flush\n10. Test --json output\n11. Test `bz q` returns only ID\n12. `zig build test` passes\n13. Manual test in sandbox/\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-19r (Issue struct)\n- bd-2sy (ID generation)\n- bd-qhg (content hash)\n- bd-abv (issue CRUD)\n- bd-3pk (label operations)\n- bd-22m (dependency operations)\n- bd-2hv (event operations)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-30T05:11:22.951919455Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:11:22.951919455Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2e8","title":"Implement show command","description":"## Goal\nImplement `bz show <id>` command to display issue details.\n\n## Technical Approach\nCreate `src/cli/show.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Issue = @import(\"../models/issue.zig\").Issue;\nconst IssueStore = @import(\"../storage/issues.zig\").IssueStore;\nconst Output = @import(\"../output/mod.zig\").Output;\n\npub const ShowArgs = struct {\n    id: []const u8,\n    with_comments: bool = true,\n    with_history: bool = false,\n};\n\npub fn run(args: ShowArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    \n    // Open database\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var issue_store = IssueStore.init(&db, allocator);\n    \n    // Get issue with relations\n    const issue = try issue_store.getWithRelations(args.id) orelse {\n        try output.err(\"Issue '{s}' not found\", .{args.id});\n        \n        // Suggest similar IDs\n        const similar = try issue_store.findSimilarIds(args.id, 3);\n        if (similar.len > 0) {\n            try output.print(\"\\nDid you mean one of these?\\n\", .{});\n            for (similar) |suggestion| {\n                try output.print(\"  {s}  \\\"{s}\\\"\\n\", .{ suggestion.id, suggestion.title });\n            }\n        }\n        \n        return error.IssueNotFound;\n    };\n    \n    // Display issue\n    if (global.json) {\n        var full_issue = issue;\n        if (args.with_history) {\n            var event_store = EventStore.init(&db, allocator);\n            full_issue.history = try event_store.getHistory(args.id);\n        }\n        try output.printJson(full_issue);\n    } else {\n        try printIssueDetails(&output, issue, args.with_comments);\n        \n        if (args.with_history) {\n            var event_store = EventStore.init(&db, allocator);\n            const history = try event_store.getHistory(args.id);\n            try printHistory(&output, history);\n        }\n    }\n}\n\nfn printIssueDetails(output: *Output, issue: Issue, with_comments: bool) !void {\n    // Header\n    try output.printBold(\"{s}\\n\", .{issue.id});\n    try output.print(\"\\n\", .{});\n    \n    // Title\n    try output.print(\"{s}\\n\", .{issue.title});\n    try output.print(\"\\n\", .{});\n    \n    // Status and priority with colors\n    try output.print(\"Status:   \", .{});\n    try output.printStatus(issue.status);\n    try output.print(\"\\n\", .{});\n    \n    try output.print(\"Priority: \", .{});\n    try output.printPriority(issue.priority);\n    try output.print(\"\\n\", .{});\n    \n    try output.print(\"Type:     {s}\\n\", .{issue.issue_type.toString()});\n    \n    // Assignee/owner\n    if (issue.assignee) |a| try output.print(\"Assignee: {s}\\n\", .{a});\n    if (issue.owner) |o| try output.print(\"Owner:    {s}\\n\", .{o});\n    \n    // Timestamps\n    try output.print(\"\\nCreated:  {s}\", .{formatTimestamp(issue.created_at)});\n    if (issue.created_by) |c| try output.print(\" by {s}\", .{c});\n    try output.print(\"\\n\", .{});\n    try output.print(\"Updated:  {s}\\n\", .{formatTimestamp(issue.updated_at)});\n    if (issue.closed_at) |c| try output.print(\"Closed:   {s}\\n\", .{formatTimestamp(c)});\n    \n    // Description\n    if (issue.description) |d| {\n        try output.print(\"\\n--- Description ---\\n{s}\\n\", .{d});\n    }\n    \n    // Labels\n    if (issue.labels.len > 0) {\n        try output.print(\"\\nLabels: \", .{});\n        for (issue.labels, 0..) |label, i| {\n            if (i > 0) try output.print(\", \", .{});\n            try output.printLabel(label);\n        }\n        try output.print(\"\\n\", .{});\n    }\n    \n    // Dependencies\n    if (issue.dependencies.len > 0) {\n        try output.print(\"\\nDependencies:\\n\", .{});\n        for (issue.dependencies) |dep| {\n            try output.print(\"  -> {s} ({s})\\n\", .{ dep.depends_on_id, dep.dep_type.toString() });\n        }\n    }\n    \n    // Comments\n    if (with_comments and issue.comments.len > 0) {\n        try output.print(\"\\n--- Comments ({d}) ---\\n\", .{issue.comments.len});\n        for (issue.comments) |comment| {\n            try output.print(\"\\n[{s}] {s}:\\n{s}\\n\", .{\n                formatTimestamp(comment.created_at),\n                comment.author,\n                comment.body,\n            });\n        }\n    }\n}\n```\n\nUpdate main.zig to dispatch to show command.\n\n## Validation\n1. Test show displays all issue fields\n2. Test show with --json output\n3. Test issue not found error\n4. Test similar ID suggestions\n5. Test with_comments flag\n6. Test with_history flag\n7. Test label display\n8. Test dependency display\n9. Test comment display\n10. `zig build test` passes\n11. Manual test in sandbox/\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-19r (Issue struct)\n- bd-abv (issue CRUD)\n- bd-2hv (event operations)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-30T05:12:42.526145647Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:12:42.526145647Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2f0","title":"Implement stale and count commands","description":"## Goal\nImplement `bz stale` and `bz count` query commands.\n\n## Technical Approach\nCreate `src/cli/stale.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst IssueStore = @import(\"../storage/issues.zig\").IssueStore;\nconst Output = @import(\"../output/mod.zig\").Output;\n\npub const StaleArgs = struct {\n    days: u32 = 30,\n};\n\npub fn run(args: StaleArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var issue_store = IssueStore.init(&db, allocator);\n    \n    const cutoff = std.time.timestamp() - (@as(i64, args.days) * 24 * 60 * 60);\n    \n    const sql = \n        \\\\SELECT * FROM issues\n        \\\\WHERE status NOT IN ('closed', 'tombstone')\n        \\\\AND updated_at < ?1\n        \\\\ORDER BY updated_at ASC\n    ;\n    \n    var stmt = try db.prepare(sql);\n    defer stmt.deinit();\n    try stmt.bindInt(1, cutoff);\n    \n    var stale_issues = std.ArrayList(Issue).init(allocator);\n    defer stale_issues.deinit();\n    \n    while (try stmt.step()) {\n        try stale_issues.append(try issue_store.rowToIssue(&stmt));\n    }\n    \n    if (global.json) {\n        try output.printJson(stale_issues.items);\n    } else {\n        if (stale_issues.items.len == 0) {\n            try output.print(\"No issues stale for >{d} days.\\n\", .{args.days});\n            return;\n        }\n        \n        try output.printBold(\"Stale Issues (not updated in {d}+ days)\\n\\n\", .{args.days});\n        \n        for (stale_issues.items) |issue| {\n            const days_stale = @divFloor(std.time.timestamp() - issue.updated_at, 24 * 60 * 60);\n            try output.print(\"{s}  {d}d ago  {s}\\n\", .{ issue.id, days_stale, issue.title });\n        }\n        \n        try output.print(\"\\n{d} stale issue(s)\\n\", .{stale_issues.items.len});\n    }\n}\n```\n\nCreate `src/cli/count.zig`:\n\n```zig\npub const CountArgs = struct {\n    by: ?enum { status, priority, type, assignee } = null,\n};\n\npub fn run(args: CountArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    if (args.by) |group_by| {\n        const field = switch (group_by) {\n            .status => \"status\",\n            .priority => \"priority\",\n            .type => \"issue_type\",\n            .assignee => \"assignee\",\n        };\n        \n        const sql = std.fmt.allocPrint(allocator,\n            \"SELECT {s}, COUNT(*) FROM issues WHERE status != 'tombstone' GROUP BY {s} ORDER BY COUNT(*) DESC\",\n            .{ field, field }\n        );\n        defer allocator.free(sql);\n        \n        var stmt = try db.prepare(sql);\n        defer stmt.deinit();\n        \n        var counts = std.ArrayList(CountEntry).init(allocator);\n        defer counts.deinit();\n        \n        while (try stmt.step()) {\n            try counts.append(.{\n                .key = stmt.columnText(0) orelse \"(none)\",\n                .count = @intCast(stmt.columnInt(1)),\n            });\n        }\n        \n        if (global.json) {\n            try output.printJson(counts.items);\n        } else {\n            for (counts.items) |entry| {\n                try output.print(\"{s: <20} {d}\\n\", .{ entry.key, entry.count });\n            }\n        }\n    } else {\n        // Total count\n        const sql = \"SELECT COUNT(*) FROM issues WHERE status != 'tombstone'\";\n        var stmt = try db.prepare(sql);\n        defer stmt.deinit();\n        _ = try stmt.step();\n        const count = stmt.columnInt(0);\n        \n        if (global.json) {\n            try output.printJson(.{ .count = count });\n        } else {\n            try output.print(\"{d} issue(s)\\n\", .{count});\n        }\n    }\n}\n\nconst CountEntry = struct {\n    key: []const u8,\n    count: u32,\n};\n```\n\n## Validation\n1. Test stale with default 30 days\n2. Test stale with custom --days\n3. Test stale excludes closed/tombstone\n4. Test count total\n5. Test count --by status\n6. Test count --by priority\n7. Test count --by assignee\n8. Test --json output\n9. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-abv (issue CRUD)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-30T05:26:34.296826110Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:26:34.296826110Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2fo","title":"Implement DependencyType enum and Dependency struct","description":"## Goal\nImplement dependency types and the Dependency struct for tracking relationships between issues.\n\n## Technical Approach\nCreate `src/models/dependency.zig`:\n\n```zig\npub const DependencyType = union(enum) {\n    blocks,\n    parent_child,\n    conditional_blocks,\n    waits_for,\n    related,\n    discovered_from,\n    replies_to,\n    relates_to,\n    duplicates,\n    supersedes,\n    caused_by,\n    custom: []const u8,\n\n    pub fn toString(self: DependencyType) []const u8 { ... }\n    pub fn fromString(s: []const u8) DependencyType { ... }\n    pub fn jsonStringify(...) // Serialize as string\n    pub fn jsonParse(...)\n};\n\npub const Dependency = struct {\n    issue_id: []const u8,         // Dependent issue (the one being blocked)\n    depends_on_id: []const u8,    // Blocker issue (the one doing the blocking)\n    dep_type: DependencyType,\n    created_at: i64,              // Unix timestamp\n    created_by: ?[]const u8,\n    metadata: ?[]const u8,        // JSON blob for extra data\n    thread_id: ?[]const u8,       // For threading/conversation context\n\n    // JSON serialization for JSONL export\n    pub fn jsonStringify(...)\n    pub fn jsonParse(...)\n    \n    // Deep equality check\n    pub fn eql(a: Dependency, b: Dependency) bool { ... }\n};\n```\n\nKey details:\n- \"blocks\" is the default/most common dependency type\n- issue_id depends ON depends_on_id (issue_id is blocked BY depends_on_id)\n- metadata is opaque JSON for extensibility\n- All optional fields can be null\n\nUpdate `src/models/mod.zig` to export DependencyType and Dependency.\n\n## Validation\n1. Test DependencyType toString/fromString roundtrip\n2. Test Dependency struct JSON serialization\n3. Test null field handling in JSON\n4. Test equality comparison\n5. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:01:00.304227496Z","created_by":"hotschmoe","updated_at":"2026-01-30T06:12:14.305986324Z","closed_at":"2026-01-30T06:12:14.305960566Z","close_reason":"Completed successfully","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2hi","title":"Implement delete command","description":"## Goal\nImplement `bz delete <id>` command for soft deletion (tombstone).\n\n## Technical Approach\nCreate `src/cli/delete.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Status = @import(\"../models/status.zig\").Status;\nconst IssueStore = @import(\"../storage/issues.zig\").IssueStore;\nconst EventStore = @import(\"../storage/events.zig\").EventStore;\nconst Output = @import(\"../output/mod.zig\").Output;\n\npub const DeleteArgs = struct {\n    id: []const u8,\n    reason: ?[]const u8 = null,\n    force: bool = false,  // Skip confirmation\n};\n\npub fn run(args: DeleteArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    \n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var issue_store = IssueStore.init(&db, allocator);\n    var event_store = EventStore.init(&db, allocator);\n    \n    const existing = try issue_store.get(args.id) orelse {\n        try output.err(\"Issue '{s}' not found\", .{args.id});\n        return error.IssueNotFound;\n    };\n    \n    // Check if already deleted\n    if (existing.status == .tombstone) {\n        try output.warn(\"Issue '{s}' is already deleted\", .{args.id});\n        return;\n    }\n    \n    // Warn about open dependencies\n    const dep_store = DependencyStore.init(&db, allocator);\n    const dependents = try dep_store.getDependents(args.id);\n    if (dependents.len > 0 and !args.force) {\n        try output.warn(\"Issue '{s}' is blocking {d} other issue(s):\", .{ args.id, dependents.len });\n        for (dependents) |dep| {\n            try output.print(\"  {s}\\n\", .{dep.issue_id});\n        }\n        try output.print(\"\\nUse --force to delete anyway.\\n\", .{});\n        return error.HasDependents;\n    }\n    \n    const actor = global.actor orelse try getActor();\n    const now = std.time.timestamp();\n    \n    try db.exec(\"BEGIN IMMEDIATE\");\n    errdefer db.exec(\"ROLLBACK\") catch {};\n    \n    // Set tombstone status\n    try issue_store.update(args.id, .{\n        .status = .tombstone,\n        .closed_at = now,\n        .close_reason = args.reason orelse \"deleted\",\n    });\n    \n    try event_store.log(.{\n        .id = 0,\n        .issue_id = args.id,\n        .event_type = .deleted,\n        .actor = actor,\n        .old_value = existing.status.toString(),\n        .new_value = \"tombstone\",\n        .created_at = now,\n    });\n    \n    try db.exec(\"COMMIT\");\n    \n    if (!global.no_auto_flush) {\n        try autoFlush(&db, allocator);\n    }\n    \n    if (global.json) {\n        try output.printJson(.{ .id = args.id, .deleted = true });\n    } else {\n        try output.success(\"Deleted issue {s}\", .{args.id});\n        if (args.reason) |r| {\n            try output.print(\"  Reason: {s}\\n\", .{r});\n        }\n    }\n}\n```\n\n## Validation\n1. Test delete sets status to tombstone\n2. Test delete sets closed_at\n3. Test delete with --reason\n4. Test delete already deleted warns\n5. Test delete warns about dependents\n6. Test --force bypasses dependent warning\n7. Test event logging\n8. Test --json output\n9. `zig build test` passes\n10. Manual test in sandbox/\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-abv (issue CRUD)\n- bd-22m (dependency operations)\n- bd-2hv (event operations)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-30T05:15:16.325872706Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:15:16.325872706Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2hv","title":"Implement event/audit operations","description":"## Goal\nImplement database operations for the audit log (events table).\n\n## Technical Approach\nCreate `src/storage/events.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Database = @import(\"sqlite.zig\").Database;\nconst Event = @import(\"../models/event.zig\").Event;\nconst EventType = @import(\"../models/event.zig\").EventType;\n\npub const EventStore = struct {\n    db: *Database,\n    allocator: std.mem.Allocator,\n\n    pub fn init(db: *Database, allocator: std.mem.Allocator) EventStore {\n        return .{ .db = db, .allocator = allocator };\n    }\n\n    /// Log an event\n    pub fn log(self: *EventStore, event: Event) !i64 {\n        const sql = \n            \\\\INSERT INTO events (issue_id, event_type, actor, old_value, new_value, created_at)\n            \\\\VALUES (?1, ?2, ?3, ?4, ?5, ?6)\n        ;\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindText(1, event.issue_id);\n        try stmt.bindText(2, event.event_type.toString());\n        try stmt.bindText(3, event.actor);\n        try stmt.bindText(4, event.old_value);\n        try stmt.bindText(5, event.new_value);\n        try stmt.bindInt(6, event.created_at);\n        _ = try stmt.step();\n        \n        return self.db.lastInsertRowId();\n    }\n\n    /// Get history for a specific issue\n    pub fn getHistory(self: *EventStore, issue_id: []const u8) ![]Event {\n        const sql = \n            \\\\SELECT id, issue_id, event_type, actor, old_value, new_value, created_at\n            \\\\FROM events\n            \\\\WHERE issue_id = ?1\n            \\\\ORDER BY created_at ASC, id ASC\n        ;\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindText(1, issue_id);\n        \n        return try self.collectEvents(&stmt);\n    }\n\n    /// Get audit log with filters\n    pub const AuditFilters = struct {\n        issue_id: ?[]const u8 = null,\n        actor: ?[]const u8 = null,\n        event_type: ?EventType = null,\n        since: ?i64 = null,\n        until: ?i64 = null,\n        limit: ?u32 = null,\n        offset: ?u32 = null,\n    };\n\n    pub fn getAuditLog(self: *EventStore, filters: AuditFilters) ![]Event {\n        // Build dynamic query based on filters\n        var sql = std.ArrayList(u8).init(self.allocator);\n        defer sql.deinit();\n        \n        try sql.appendSlice(\"SELECT id, issue_id, event_type, actor, old_value, new_value, created_at FROM events WHERE 1=1\");\n        \n        if (filters.issue_id != null) try sql.appendSlice(\" AND issue_id = ?\");\n        if (filters.actor != null) try sql.appendSlice(\" AND actor = ?\");\n        if (filters.event_type != null) try sql.appendSlice(\" AND event_type = ?\");\n        if (filters.since != null) try sql.appendSlice(\" AND created_at >= ?\");\n        if (filters.until != null) try sql.appendSlice(\" AND created_at <= ?\");\n        \n        try sql.appendSlice(\" ORDER BY created_at DESC, id DESC\");\n        \n        if (filters.limit != null) try sql.appendSlice(\" LIMIT ?\");\n        if (filters.offset != null) try sql.appendSlice(\" OFFSET ?\");\n        \n        var stmt = try self.db.prepare(sql.items);\n        defer stmt.deinit();\n        \n        // Bind parameters...\n        \n        return try self.collectEvents(&stmt);\n    }\n\n    /// Get latest event for an issue\n    pub fn getLatestEvent(self: *EventStore, issue_id: []const u8) !?Event {\n        const sql = \n            \\\\SELECT id, issue_id, event_type, actor, old_value, new_value, created_at\n            \\\\FROM events\n            \\\\WHERE issue_id = ?1\n            \\\\ORDER BY created_at DESC, id DESC\n            \\\\LIMIT 1\n        ;\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindText(1, issue_id);\n        \n        if (try stmt.step()) {\n            return try self.rowToEvent(&stmt);\n        }\n        return null;\n    }\n\n    fn collectEvents(self: *EventStore, stmt: *Statement) ![]Event {\n        var events = std.ArrayList(Event).init(self.allocator);\n        errdefer events.deinit();\n        \n        while (try stmt.step()) {\n            try events.append(try self.rowToEvent(stmt));\n        }\n        \n        return events.toOwnedSlice();\n    }\n\n    fn rowToEvent(self: *EventStore, stmt: *Statement) !Event {\n        return .{\n            .id = stmt.columnInt(0),\n            .issue_id = try self.allocator.dupe(u8, stmt.columnText(1).?),\n            .event_type = EventType.fromString(stmt.columnText(2).?).?,\n            .actor = try self.allocator.dupe(u8, stmt.columnText(3).?),\n            .old_value = if (stmt.columnText(4)) |v| try self.allocator.dupe(u8, v) else null,\n            .new_value = if (stmt.columnText(5)) |v| try self.allocator.dupe(u8, v) else null,\n            .created_at = stmt.columnInt(6),\n        };\n    }\n};\n```\n\nUpdate `src/storage/mod.zig` to export EventStore.\n\n## Validation\n1. Test log event\n2. Test getHistory returns chronological events\n3. Test getAuditLog with various filters\n4. Test getLatestEvent\n5. Test old_value/new_value null handling\n6. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-2o2 (database schema)\n- bd-sbg (Event/EventType structs)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:06:39.438747944Z","created_by":"hotschmoe","updated_at":"2026-01-30T19:41:06.225285132Z","closed_at":"2026-01-30T19:41:06.225217332Z","close_reason":"Event/EventType structs implemented in src/models/event.zig with full serialization","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2lr","title":"Implement info, stats, and doctor commands","description":"## Goal\nImplement workspace information commands: `bz info`, `bz stats`, `bz doctor`.\n\n## Technical Approach\nCreate `src/cli/info.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Output = @import(\"../output/mod.zig\").Output;\n\npub fn run(global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    const info = WorkspaceInfo{\n        .beads_dir = \".beads\",\n        .db_path = \".beads/beads.db\",\n        .jsonl_path = \".beads/issues.jsonl\",\n        .schema_version = try getSchemaVersion(&db),\n        .issue_prefix = try getConfigValue(&db, \"issue_prefix\") orelse \"bd\",\n        .issue_count = try countIssues(&db),\n        .db_size = try getFileSize(\".beads/beads.db\"),\n        .jsonl_size = try getFileSize(\".beads/issues.jsonl\"),\n    };\n    \n    if (global.json) {\n        try output.printJson(info);\n    } else {\n        try output.printBold(\"beads_zig workspace\\n\\n\", .{});\n        try output.print(\"Directory:      {s}\\n\", .{info.beads_dir});\n        try output.print(\"Database:       {s} ({s})\\n\", .{ info.db_path, formatBytes(info.db_size) });\n        try output.print(\"JSONL:          {s} ({s})\\n\", .{ info.jsonl_path, formatBytes(info.jsonl_size) });\n        try output.print(\"Schema version: {d}\\n\", .{info.schema_version});\n        try output.print(\"Issue prefix:   {s}\\n\", .{info.issue_prefix});\n        try output.print(\"Total issues:   {d}\\n\", .{info.issue_count});\n    }\n}\n\nconst WorkspaceInfo = struct {\n    beads_dir: []const u8,\n    db_path: []const u8,\n    jsonl_path: []const u8,\n    schema_version: u32,\n    issue_prefix: []const u8,\n    issue_count: u32,\n    db_size: u64,\n    jsonl_size: u64,\n};\n```\n\nCreate `src/cli/stats.zig`:\n\n```zig\npub fn run(global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var issue_store = IssueStore.init(&db, allocator);\n    \n    const stats = Stats{\n        .by_status = try issue_store.countByStatus(),\n        .by_priority = try issue_store.countByPriority(),\n        .by_type = try issue_store.countByType(),\n        .by_assignee = try issue_store.countByAssignee(),\n        .total = try issue_store.countTotal(),\n        .open = try issue_store.countByStatusValue(.open),\n        .closed = try issue_store.countByStatusValue(.closed),\n    };\n    \n    if (global.json) {\n        try output.printJson(stats);\n    } else {\n        try output.printBold(\"Issue Statistics\\n\\n\", .{});\n        \n        try output.print(\"Total: {d} issues ({d} open, {d} closed)\\n\\n\", .{\n            stats.total,\n            stats.open,\n            stats.closed,\n        });\n        \n        try output.print(\"By Status:\\n\", .{});\n        for (stats.by_status) |entry| {\n            try output.print(\"  {s: <12} {d}\\n\", .{ entry.key, entry.count });\n        }\n        \n        try output.print(\"\\nBy Priority:\\n\", .{});\n        for (stats.by_priority) |entry| {\n            try output.print(\"  {s: <12} {d}\\n\", .{ entry.key, entry.count });\n        }\n        \n        try output.print(\"\\nBy Type:\\n\", .{});\n        for (stats.by_type) |entry| {\n            try output.print(\"  {s: <12} {d}\\n\", .{ entry.key, entry.count });\n        }\n    }\n}\n```\n\nCreate `src/cli/doctor.zig`:\n\n```zig\npub fn run(global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var checks = std.ArrayList(Check).init(allocator);\n    defer checks.deinit();\n    \n    // Check 1: Database integrity\n    try checks.append(checkDatabaseIntegrity(&db));\n    \n    // Check 2: Schema version\n    try checks.append(checkSchemaVersion(&db));\n    \n    // Check 3: JSONL exists\n    try checks.append(checkJsonlExists());\n    \n    // Check 4: No orphan dependencies\n    try checks.append(try checkOrphanDependencies(&db));\n    \n    // Check 5: No cycles\n    try checks.append(try checkNoCycles(&db, allocator));\n    \n    // Check 6: FTS index sync\n    try checks.append(try checkFtsSync(&db));\n    \n    var passed: u32 = 0;\n    var failed: u32 = 0;\n    var warnings: u32 = 0;\n    \n    for (checks.items) |check| {\n        switch (check.status) {\n            .pass => passed += 1,\n            .fail => failed += 1,\n            .warn => warnings += 1,\n        }\n    }\n    \n    if (global.json) {\n        try output.printJson(.{\n            .checks = checks.items,\n            .passed = passed,\n            .failed = failed,\n            .warnings = warnings,\n        });\n    } else {\n        try output.printBold(\"Workspace Health Check\\n\\n\", .{});\n        \n        for (checks.items) |check| {\n            const icon = switch (check.status) {\n                .pass => \"[OK]  \",\n                .fail => \"[FAIL]\",\n                .warn => \"[WARN]\",\n            };\n            try output.print(\"{s} {s}\\n\", .{ icon, check.name });\n            if (check.message) |msg| {\n                try output.printDim(\"      {s}\\n\", .{msg});\n            }\n        }\n        \n        try output.print(\"\\n{d} passed, {d} warnings, {d} failed\\n\", .{ passed, warnings, failed });\n    }\n}\n\nconst Check = struct {\n    name: []const u8,\n    status: enum { pass, fail, warn },\n    message: ?[]const u8,\n};\n\nfn checkDatabaseIntegrity(db: *Database) Check {\n    db.exec(\"PRAGMA integrity_check\") catch {\n        return .{ .name = \"Database integrity\", .status = .fail, .message = \"PRAGMA integrity_check failed\" };\n    };\n    return .{ .name = \"Database integrity\", .status = .pass, .message = null };\n}\n```\n\n## Validation\n1. Test info displays workspace info\n2. Test stats shows counts by category\n3. Test doctor runs all checks\n4. Test doctor reports failures\n5. Test --json output for all\n6. `zig build test` passes\n7. Manual test in sandbox/\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-abv (issue CRUD)\n- bd-22m (dependency operations)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-30T05:22:02.008402539Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:22:02.008402539Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2n2","title":"Implement label commands","description":"## Goal\nImplement `bz label` subcommands for label management.\n\n## Technical Approach\nCreate `src/cli/label.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst LabelStore = @import(\"../storage/labels.zig\").LabelStore;\nconst EventStore = @import(\"../storage/events.zig\").EventStore;\nconst Output = @import(\"../output/mod.zig\").Output;\n\npub const LabelArgs = union(enum) {\n    add: struct {\n        id: []const u8,\n        labels: []const []const u8,\n    },\n    remove: struct {\n        id: []const u8,\n        labels: []const []const u8,\n    },\n    list: struct {\n        id: []const u8,\n    },\n    list_all: void,\n};\n\npub fn run(args: LabelArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    switch (args) {\n        .add => |a| try runAdd(a.id, a.labels, global, allocator),\n        .remove => |r| try runRemove(r.id, r.labels, global, allocator),\n        .list => |l| try runList(l.id, global, allocator),\n        .list_all => try runListAll(global, allocator),\n    }\n}\n\nfn runAdd(id: []const u8, labels: []const []const u8, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var label_store = LabelStore.init(&db, allocator);\n    var event_store = EventStore.init(&db, allocator);\n    \n    // Verify issue exists\n    var issue_store = IssueStore.init(&db, allocator);\n    _ = try issue_store.get(id) orelse {\n        try output.err(\"Issue '{s}' not found\", .{id});\n        return error.IssueNotFound;\n    };\n    \n    const actor = global.actor orelse try getActor();\n    const now = std.time.timestamp();\n    \n    var added = std.ArrayList([]const u8).init(allocator);\n    defer added.deinit();\n    \n    for (labels) |label| {\n        const had_label = try label_store.hasLabel(id, label);\n        try label_store.add(id, label);\n        if (!had_label) {\n            try added.append(label);\n            try event_store.log(.{\n                .id = 0,\n                .issue_id = id,\n                .event_type = .label_added,\n                .actor = actor,\n                .old_value = null,\n                .new_value = label,\n                .created_at = now,\n            });\n        }\n    }\n    \n    if (!global.no_auto_flush) {\n        try autoFlush(&db, allocator);\n    }\n    \n    if (global.json) {\n        try output.printJson(.{ .id = id, .added = added.items });\n    } else {\n        if (added.items.len > 0) {\n            try output.success(\"Added {d} label(s) to {s}\", .{ added.items.len, id });\n        } else {\n            try output.print(\"No new labels added (already present).\\n\", .{});\n        }\n    }\n}\n\nfn runRemove(id: []const u8, labels: []const []const u8, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var label_store = LabelStore.init(&db, allocator);\n    var event_store = EventStore.init(&db, allocator);\n    \n    const actor = global.actor orelse try getActor();\n    const now = std.time.timestamp();\n    \n    var removed = std.ArrayList([]const u8).init(allocator);\n    defer removed.deinit();\n    \n    for (labels) |label| {\n        const had_label = try label_store.hasLabel(id, label);\n        if (had_label) {\n            try label_store.remove(id, label);\n            try removed.append(label);\n            try event_store.log(.{\n                .id = 0,\n                .issue_id = id,\n                .event_type = .label_removed,\n                .actor = actor,\n                .old_value = label,\n                .new_value = null,\n                .created_at = now,\n            });\n        }\n    }\n    \n    if (!global.no_auto_flush) {\n        try autoFlush(&db, allocator);\n    }\n    \n    if (global.json) {\n        try output.printJson(.{ .id = id, .removed = removed.items });\n    } else {\n        if (removed.items.len > 0) {\n            try output.success(\"Removed {d} label(s) from {s}\", .{ removed.items.len, id });\n        } else {\n            try output.print(\"No labels removed (not present).\\n\", .{});\n        }\n    }\n}\n\nfn runList(id: []const u8, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var label_store = LabelStore.init(&db, allocator);\n    const labels = try label_store.getLabels(id);\n    \n    if (global.json) {\n        try output.printJson(.{ .id = id, .labels = labels });\n    } else {\n        if (labels.len == 0) {\n            try output.print(\"No labels on {s}\\n\", .{id});\n        } else {\n            for (labels) |label| {\n                try output.printLabel(label);\n                try output.print(\"\\n\", .{});\n            }\n        }\n    }\n}\n\nfn runListAll(global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var label_store = LabelStore.init(&db, allocator);\n    const labels = try label_store.getAllLabels();\n    \n    if (global.json) {\n        try output.printJson(.{ .labels = labels });\n    } else {\n        if (labels.len == 0) {\n            try output.print(\"No labels in project.\\n\", .{});\n        } else {\n            try output.print(\"Labels ({d}):\\n\", .{labels.len});\n            for (labels) |label| {\n                try output.print(\"  {s}\\n\", .{label});\n            }\n        }\n    }\n}\n```\n\n## Validation\n1. Test label add adds labels\n2. Test label add skips existing labels\n3. Test label remove removes labels\n4. Test label list shows labels on issue\n5. Test label list-all shows all project labels\n6. Test event logging\n7. Test --json output\n8. `zig build test` passes\n9. Manual test in sandbox/\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-3pk (label operations)\n- bd-2hv (event operations)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-30T05:18:51.045234197Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:18:51.045234197Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2o0","title":"Implement JSONL import","description":"## Goal\nImplement JSONL import for loading issues from git-tracked files.\n\n## Technical Approach\nCreate `src/sync/import.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Issue = @import(\"../models/issue.zig\").Issue;\nconst timestamp = @import(\"../models/timestamp.zig\");\nconst IssueStore = @import(\"../storage/issues.zig\").IssueStore;\nconst hash = @import(\"../id/hash.zig\");\n\npub const ImportOptions = struct {\n    input_path: []const u8,\n    force: bool = false,           // Force import even with conflicts\n    dry_run: bool = false,         // Don't actually modify database\n};\n\npub const ImportResult = struct {\n    issues_created: u32,\n    issues_updated: u32,\n    issues_skipped: u32,\n    conflicts: []ConflictInfo,\n};\n\npub const ConflictInfo = struct {\n    issue_id: []const u8,\n    reason: ConflictReason,\n};\n\npub const ConflictReason = enum {\n    merge_conflict_markers,\n    id_collision_different_content,\n    newer_in_database,\n};\n\npub const Importer = struct {\n    issue_store: *IssueStore,\n    allocator: std.mem.Allocator,\n\n    pub fn init(issue_store: *IssueStore, allocator: std.mem.Allocator) Importer {\n        return .{\n            .issue_store = issue_store,\n            .allocator = allocator,\n        };\n    }\n\n    /// Import issues from JSONL file\n    pub fn import(self: *Importer, options: ImportOptions) !ImportResult {\n        // Validate path is within .beads/\n        if (!self.isValidPath(options.input_path)) {\n            return error.ExternalPathNotAllowed;\n        }\n\n        // Read file\n        const file = try std.fs.cwd().openFile(options.input_path, .{});\n        defer file.close();\n        const content = try file.readToEndAlloc(self.allocator, 100 * 1024 * 1024); // 100MB limit\n        defer self.allocator.free(content);\n\n        // Check for merge conflict markers\n        if (self.hasMergeConflicts(content)) {\n            return error.MergeConflictDetected;\n        }\n\n        var result = ImportResult{\n            .issues_created = 0,\n            .issues_updated = 0,\n            .issues_skipped = 0,\n            .conflicts = &[_]ConflictInfo{},\n        };\n\n        var conflicts = std.ArrayList(ConflictInfo).init(self.allocator);\n        errdefer conflicts.deinit();\n\n        // Parse line by line\n        var lines = std.mem.split(u8, content, \"\\n\");\n        while (lines.next()) |line| {\n            if (line.len == 0) continue;\n            \n            const issue = std.json.parseFromSlice(Issue, self.allocator, line, .{}) catch |err| {\n                return error.JsonlParseError;\n            };\n            defer issue.deinit();\n\n            // Four-phase collision detection (per SPEC.md)\n            const resolution = try self.resolveCollision(issue.value);\n            \n            switch (resolution) {\n                .create => {\n                    if (!options.dry_run) try self.issue_store.insert(issue.value);\n                    result.issues_created += 1;\n                },\n                .update => {\n                    if (!options.dry_run) try self.issue_store.upsert(issue.value);\n                    result.issues_updated += 1;\n                },\n                .skip => {\n                    result.issues_skipped += 1;\n                },\n                .conflict => |reason| {\n                    try conflicts.append(.{\n                        .issue_id = try self.allocator.dupe(u8, issue.value.id),\n                        .reason = reason,\n                    });\n                    if (options.force) {\n                        if (!options.dry_run) try self.issue_store.upsert(issue.value);\n                        result.issues_updated += 1;\n                    } else {\n                        result.issues_skipped += 1;\n                    }\n                },\n            }\n        }\n\n        result.conflicts = try conflicts.toOwnedSlice();\n        return result;\n    }\n\n    /// Four-phase collision detection per SPEC.md\n    const Resolution = union(enum) {\n        create,\n        update,\n        skip,\n        conflict: ConflictReason,\n    };\n\n    fn resolveCollision(self: *Importer, issue: Issue) !Resolution {\n        // Phase 1: Match by external_ref\n        if (issue.external_ref) |ref| {\n            if (try self.issue_store.getByExternalRef(ref)) |existing| {\n                return if (issue.updated_at > existing.updated_at) .update else .skip;\n            }\n        }\n\n        // Phase 2: Match by content_hash\n        if (issue.content_hash) |hash| {\n            if (try self.issue_store.getByContentHash(hash)) |_| {\n                return .skip; // Exact duplicate\n            }\n        }\n\n        // Phase 3: Match by ID\n        if (try self.issue_store.get(issue.id)) |existing| {\n            // Same ID, different content - check timestamps\n            if (issue.updated_at > existing.updated_at) {\n                return .update;\n            } else if (issue.updated_at < existing.updated_at) {\n                return .{ .conflict = .newer_in_database };\n            } else {\n                return .skip; // Same timestamp, skip\n            }\n        }\n\n        // Phase 4: New issue\n        return .create;\n    }\n\n    fn hasMergeConflicts(self: *Importer, content: []const u8) bool {\n        return std.mem.indexOf(u8, content, \"<<<<<<<\") != null or\n               std.mem.indexOf(u8, content, \"=======\") != null or\n               std.mem.indexOf(u8, content, \">>>>>>>\") != null;\n    }\n\n    fn isValidPath(self: *Importer, path: []const u8) bool {\n        // Check path is within .beads/ directory\n        return std.mem.startsWith(u8, path, \".beads/\") or\n               std.mem.indexOf(u8, path, \"/.beads/\") != null;\n    }\n};\n```\n\nUpdate `src/sync/mod.zig` to export Importer.\n\n## Validation\n1. Test import creates new issues\n2. Test import updates existing issues (newer timestamp wins)\n3. Test import skips duplicates (same content hash)\n4. Test merge conflict detection rejects file\n5. Test path validation rejects external paths\n6. Test dry_run doesn't modify database\n7. Test four-phase collision detection\n8. Test RFC3339 timestamp parsing\n9. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-19r (Issue struct)\n- bd-283 (RFC3339 timestamps)\n- bd-qhg (content hash)\n- bd-abv (issue CRUD operations)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:08:37.873913223Z","created_by":"hotschmoe","updated_at":"2026-01-30T19:39:47.267375264Z","closed_at":"2026-01-30T19:39:47.267348453Z","close_reason":"JSONL import implemented in IssueStore.loadFromFile() via JsonlFile.readAll()","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2o2","title":"Implement database schema creation","description":"## Goal\nImplement the complete SQLite schema for beads_zig as defined in SPEC.md.\n\n## Technical Approach\nCreate `src/storage/schema.zig`:\n\n```zig\nconst Database = @import(\"sqlite.zig\").Database;\n\n/// Schema version for migrations\npub const SCHEMA_VERSION: u32 = 1;\n\n/// Create all tables and indexes\npub fn createSchema(db: *Database) !void {\n    // Issues table\n    try db.exec(\n        \\\\CREATE TABLE IF NOT EXISTS issues (\n        \\\\    id TEXT PRIMARY KEY,\n        \\\\    content_hash TEXT,\n        \\\\    title TEXT NOT NULL CHECK(length(title) <= 500),\n        \\\\    description TEXT,\n        \\\\    design TEXT,\n        \\\\    acceptance_criteria TEXT,\n        \\\\    notes TEXT,\n        \\\\    status TEXT NOT NULL DEFAULT 'open',\n        \\\\    priority INTEGER NOT NULL DEFAULT 2 CHECK(priority >= 0 AND priority <= 4),\n        \\\\    issue_type TEXT NOT NULL DEFAULT 'task',\n        \\\\    assignee TEXT,\n        \\\\    owner TEXT,\n        \\\\    estimated_minutes INTEGER,\n        \\\\    created_at INTEGER NOT NULL,\n        \\\\    created_by TEXT,\n        \\\\    updated_at INTEGER NOT NULL,\n        \\\\    closed_at INTEGER,\n        \\\\    close_reason TEXT,\n        \\\\    due_at INTEGER,\n        \\\\    defer_until INTEGER,\n        \\\\    external_ref TEXT UNIQUE,\n        \\\\    source_system TEXT,\n        \\\\    pinned INTEGER NOT NULL DEFAULT 0,\n        \\\\    is_template INTEGER NOT NULL DEFAULT 0\n        \\\\)\n    );\n\n    // Dependencies table\n    try db.exec(\n        \\\\CREATE TABLE IF NOT EXISTS dependencies (\n        \\\\    issue_id TEXT NOT NULL,\n        \\\\    depends_on_id TEXT NOT NULL,\n        \\\\    dep_type TEXT NOT NULL DEFAULT 'blocks',\n        \\\\    created_at INTEGER NOT NULL,\n        \\\\    created_by TEXT,\n        \\\\    metadata TEXT,\n        \\\\    thread_id TEXT,\n        \\\\    PRIMARY KEY (issue_id, depends_on_id),\n        \\\\    FOREIGN KEY (issue_id) REFERENCES issues(id) ON DELETE CASCADE\n        \\\\)\n    );\n\n    // Labels table\n    try db.exec(\n        \\\\CREATE TABLE IF NOT EXISTS labels (\n        \\\\    issue_id TEXT NOT NULL,\n        \\\\    label TEXT NOT NULL,\n        \\\\    PRIMARY KEY (issue_id, label),\n        \\\\    FOREIGN KEY (issue_id) REFERENCES issues(id) ON DELETE CASCADE\n        \\\\)\n    );\n\n    // Comments table\n    try db.exec(\n        \\\\CREATE TABLE IF NOT EXISTS comments (\n        \\\\    id INTEGER PRIMARY KEY AUTOINCREMENT,\n        \\\\    issue_id TEXT NOT NULL,\n        \\\\    author TEXT NOT NULL,\n        \\\\    body TEXT NOT NULL,\n        \\\\    created_at INTEGER NOT NULL,\n        \\\\    FOREIGN KEY (issue_id) REFERENCES issues(id) ON DELETE CASCADE\n        \\\\)\n    );\n\n    // Events table (audit log)\n    try db.exec(\n        \\\\CREATE TABLE IF NOT EXISTS events (\n        \\\\    id INTEGER PRIMARY KEY AUTOINCREMENT,\n        \\\\    issue_id TEXT NOT NULL,\n        \\\\    event_type TEXT NOT NULL,\n        \\\\    actor TEXT NOT NULL,\n        \\\\    old_value TEXT,\n        \\\\    new_value TEXT,\n        \\\\    created_at INTEGER NOT NULL,\n        \\\\    FOREIGN KEY (issue_id) REFERENCES issues(id) ON DELETE CASCADE\n        \\\\)\n    );\n\n    // Dirty tracking for sync\n    try db.exec(\n        \\\\CREATE TABLE IF NOT EXISTS dirty_issues (\n        \\\\    issue_id TEXT PRIMARY KEY,\n        \\\\    marked_at INTEGER NOT NULL\n        \\\\)\n    );\n\n    // Blocked cache for query optimization\n    try db.exec(\n        \\\\CREATE TABLE IF NOT EXISTS blocked_cache (\n        \\\\    issue_id TEXT PRIMARY KEY,\n        \\\\    blocked_by TEXT NOT NULL,\n        \\\\    cached_at INTEGER NOT NULL\n        \\\\)\n    );\n\n    // Config storage\n    try db.exec(\n        \\\\CREATE TABLE IF NOT EXISTS config (\n        \\\\    key TEXT PRIMARY KEY,\n        \\\\    value TEXT NOT NULL\n        \\\\)\n    );\n\n    // Create indexes\n    try createIndexes(db);\n\n    // Create FTS table\n    try createFts(db);\n\n    // Store schema version\n    try db.exec(\"INSERT OR REPLACE INTO config (key, value) VALUES ('schema_version', '1')\");\n}\n\nfn createIndexes(db: *Database) !void {\n    try db.exec(\"CREATE INDEX IF NOT EXISTS idx_issues_status ON issues(status)\");\n    try db.exec(\"CREATE INDEX IF NOT EXISTS idx_issues_priority ON issues(priority)\");\n    try db.exec(\"CREATE INDEX IF NOT EXISTS idx_issues_assignee ON issues(assignee)\");\n    try db.exec(\"CREATE INDEX IF NOT EXISTS idx_issues_created_at ON issues(created_at)\");\n    try db.exec(\"CREATE INDEX IF NOT EXISTS idx_issues_updated_at ON issues(updated_at)\");\n    try db.exec(\"CREATE INDEX IF NOT EXISTS idx_issues_content_hash ON issues(content_hash)\");\n    try db.exec(\"CREATE INDEX IF NOT EXISTS idx_deps_depends_on ON dependencies(depends_on_id)\");\n    try db.exec(\"CREATE INDEX IF NOT EXISTS idx_labels_label ON labels(label)\");\n    try db.exec(\"CREATE INDEX IF NOT EXISTS idx_comments_issue ON comments(issue_id)\");\n    try db.exec(\"CREATE INDEX IF NOT EXISTS idx_events_issue ON events(issue_id)\");\n    try db.exec(\"CREATE INDEX IF NOT EXISTS idx_events_created ON events(created_at)\");\n}\n\nfn createFts(db: *Database) !void {\n    try db.exec(\n        \\\\CREATE VIRTUAL TABLE IF NOT EXISTS issues_fts USING fts5(\n        \\\\    id,\n        \\\\    title,\n        \\\\    description,\n        \\\\    notes,\n        \\\\    content='issues',\n        \\\\    content_rowid='rowid'\n        \\\\)\n    );\n}\n\n/// Get current schema version\npub fn getSchemaVersion(db: *Database) !?u32 {\n    var stmt = try db.prepare(\"SELECT value FROM config WHERE key = 'schema_version'\");\n    defer stmt.deinit();\n    if (try stmt.step()) {\n        const val = stmt.columnText(0) orelse return null;\n        return std.fmt.parseInt(u32, val, 10) catch null;\n    }\n    return null;\n}\n```\n\nUpdate `src/storage/mod.zig` to export schema functions.\n\n## Validation\n1. Test createSchema on fresh database\n2. Test tables exist with correct columns\n3. Test indexes exist\n4. Test FTS table exists\n5. Test schema version is stored\n6. Test createSchema is idempotent (can run twice)\n7. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)","notes":"SUPERSEDED: Removed SQLite in favor of pure JSONL storage. No database schema needed - data stored in beads.jsonl with in-memory indexing.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:04:00.199857284Z","created_by":"hotschmoe","updated_at":"2026-01-30T19:45:19.065815538Z","closed_at":"2026-01-30T07:24:50.462951727Z","close_reason":"Completed successfully","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2q5","title":"Implement orphans and lint commands","description":"## Goal\nImplement `bz orphans` (find issues with missing parent refs) and `bz lint` (validate database consistency) commands.\n\n## Technical Approach\nCreate `src/cli/orphans.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst IssueStore = @import(\"../storage/issues.zig\").IssueStore;\nconst DependencyStore = @import(\"../storage/dependencies.zig\").DependencyStore;\nconst Output = @import(\"../output/mod.zig\").Output;\n\npub fn run(global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var issue_store = IssueStore.init(&db, allocator);\n    var dep_store = DependencyStore.init(&db, allocator);\n    \n    var orphans = std.ArrayList(OrphanInfo).init(allocator);\n    defer orphans.deinit();\n    \n    // Find issues with hierarchical IDs whose parents don't exist\n    // e.g., bd-abc.1 exists but bd-abc doesn't\n    const sql_hierarchical = \n        \\\\SELECT i.id FROM issues i\n        \\\\WHERE i.id LIKE '%.%'\n        \\\\AND NOT EXISTS (\n        \\\\    SELECT 1 FROM issues p\n        \\\\    WHERE p.id = substr(i.id, 1, instr(i.id, '.') - 1)\n        \\\\)\n    ;\n    \n    var stmt1 = try db.prepare(sql_hierarchical);\n    defer stmt1.deinit();\n    while (try stmt1.step()) {\n        const id = stmt1.columnText(0).?;\n        try orphans.append(.{\n            .id = try allocator.dupe(u8, id),\n            .reason = .missing_parent,\n            .detail = \"Parent issue not found\",\n        });\n    }\n    \n    // Find issues with dependencies pointing to non-existent issues\n    const sql_broken_deps = \n        \\\\SELECT d.issue_id, d.depends_on_id FROM dependencies d\n        \\\\WHERE NOT EXISTS (\n        \\\\    SELECT 1 FROM issues i WHERE i.id = d.depends_on_id\n        \\\\)\n    ;\n    \n    var stmt2 = try db.prepare(sql_broken_deps);\n    defer stmt2.deinit();\n    while (try stmt2.step()) {\n        const issue_id = stmt2.columnText(0).?;\n        const missing_dep = stmt2.columnText(1).?;\n        try orphans.append(.{\n            .id = try allocator.dupe(u8, issue_id),\n            .reason = .broken_dependency,\n            .detail = try std.fmt.allocPrint(allocator, \"Depends on non-existent {s}\", .{missing_dep}),\n        });\n    }\n    \n    if (global.json) {\n        try output.printJson(orphans.items);\n    } else {\n        if (orphans.items.len == 0) {\n            try output.success(\"No orphaned issues found.\", .{});\n        } else {\n            try output.printBold(\"Orphaned Issues ({d})\\n\\n\", .{orphans.items.len});\n            for (orphans.items) |orphan| {\n                try output.print(\"{s}  [{s}] {s}\\n\", .{\n                    orphan.id,\n                    @tagName(orphan.reason),\n                    orphan.detail,\n                });\n            }\n        }\n    }\n}\n\nconst OrphanInfo = struct {\n    id: []const u8,\n    reason: enum { missing_parent, broken_dependency },\n    detail: []const u8,\n};\n```\n\nCreate `src/cli/lint.zig`:\n\n```zig\npub const LintArgs = struct {\n    fix: bool = false,  // Attempt to fix issues\n};\n\npub fn run(args: LintArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var issues = std.ArrayList(LintIssue).init(allocator);\n    defer issues.deinit();\n    \n    // Check 1: Database integrity\n    {\n        var stmt = try db.prepare(\"PRAGMA integrity_check\");\n        defer stmt.deinit();\n        _ = try stmt.step();\n        const result = stmt.columnText(0).?;\n        if (!std.mem.eql(u8, result, \"ok\")) {\n            try issues.append(.{\n                .severity = .error,\n                .code = \"DB001\",\n                .message = \"Database integrity check failed\",\n                .detail = result,\n            });\n        }\n    }\n    \n    // Check 2: Foreign key violations\n    {\n        var stmt = try db.prepare(\"PRAGMA foreign_key_check\");\n        defer stmt.deinit();\n        while (try stmt.step()) {\n            try issues.append(.{\n                .severity = .error,\n                .code = \"FK001\",\n                .message = \"Foreign key violation\",\n                .detail = stmt.columnText(0).?,\n            });\n        }\n    }\n    \n    // Check 3: Issues with invalid status\n    {\n        const valid_statuses = [_][]const u8{ \"open\", \"in_progress\", \"blocked\", \"deferred\", \"closed\", \"tombstone\", \"pinned\" };\n        const sql = \"SELECT id, status FROM issues WHERE status NOT IN ('open', 'in_progress', 'blocked', 'deferred', 'closed', 'tombstone', 'pinned')\";\n        var stmt = try db.prepare(sql);\n        defer stmt.deinit();\n        while (try stmt.step()) {\n            try issues.append(.{\n                .severity = .warning,\n                .code = \"ST001\",\n                .message = try std.fmt.allocPrint(allocator, \"Issue {s} has unknown status\", .{stmt.columnText(0).?}),\n                .detail = stmt.columnText(1).?,\n            });\n        }\n    }\n    \n    // Check 4: Issues with invalid priority (should be 0-4)\n    {\n        const sql = \"SELECT id, priority FROM issues WHERE priority < 0 OR priority > 4\";\n        var stmt = try db.prepare(sql);\n        defer stmt.deinit();\n        while (try stmt.step()) {\n            try issues.append(.{\n                .severity = .error,\n                .code = \"PR001\",\n                .message = try std.fmt.allocPrint(allocator, \"Issue {s} has invalid priority\", .{stmt.columnText(0).?}),\n                .detail = try std.fmt.allocPrint(allocator, \"{d}\", .{stmt.columnInt(1)}),\n            });\n        }\n    }\n    \n    // Check 5: Duplicate content hashes (potential duplicates)\n    {\n        const sql = \n            \\\\SELECT content_hash, COUNT(*) as cnt, GROUP_CONCAT(id, ', ') as ids\n            \\\\FROM issues\n            \\\\WHERE content_hash IS NOT NULL\n            \\\\GROUP BY content_hash\n            \\\\HAVING cnt > 1\n        ;\n        var stmt = try db.prepare(sql);\n        defer stmt.deinit();\n        while (try stmt.step()) {\n            try issues.append(.{\n                .severity = .warning,\n                .code = \"DUP01\",\n                .message = \"Potential duplicate issues\",\n                .detail = stmt.columnText(2).?,\n            });\n        }\n    }\n    \n    // Check 6: FTS index out of sync\n    {\n        const sql = \n            \\\\SELECT COUNT(*) FROM issues WHERE id NOT IN (SELECT id FROM issues_fts)\n        ;\n        var stmt = try db.prepare(sql);\n        defer stmt.deinit();\n        _ = try stmt.step();\n        const missing = stmt.columnInt(0);\n        if (missing > 0) {\n            try issues.append(.{\n                .severity = .warning,\n                .code = \"FTS01\",\n                .message = try std.fmt.allocPrint(allocator, \"{d} issues not in FTS index\", .{missing}),\n                .detail = \"Run 'bz doctor --fix' to rebuild index\",\n            });\n        }\n    }\n    \n    // Attempt fixes if requested\n    if (args.fix) {\n        try output.print(\"Attempting fixes...\\n\", .{});\n        // Rebuild FTS index\n        try db.exec(\"DELETE FROM issues_fts\");\n        try db.exec(\"INSERT INTO issues_fts (id, title, description, notes) SELECT id, title, description, notes FROM issues WHERE status != 'tombstone'\");\n        try output.success(\"Rebuilt FTS index\", .{});\n    }\n    \n    // Output results\n    var errors: u32 = 0;\n    var warnings: u32 = 0;\n    for (issues.items) |issue| {\n        switch (issue.severity) {\n            .error => errors += 1,\n            .warning => warnings += 1,\n        }\n    }\n    \n    if (global.json) {\n        try output.printJson(.{\n            .issues = issues.items,\n            .errors = errors,\n            .warnings = warnings,\n        });\n    } else {\n        if (issues.items.len == 0) {\n            try output.success(\"No issues found. Database is healthy.\", .{});\n        } else {\n            for (issues.items) |issue| {\n                const icon = switch (issue.severity) {\n                    .error => \"[ERROR]\",\n                    .warning => \"[WARN] \",\n                };\n                try output.print(\"{s} {s}: {s}\\n\", .{ icon, issue.code, issue.message });\n                if (issue.detail.len > 0) {\n                    try output.printDim(\"        {s}\\n\", .{issue.detail});\n                }\n            }\n            try output.print(\"\\n{d} error(s), {d} warning(s)\\n\", .{ errors, warnings });\n        }\n    }\n    \n    if (errors > 0) {\n        return error.LintErrors;\n    }\n}\n\nconst LintIssue = struct {\n    severity: enum { error, warning },\n    code: []const u8,\n    message: []const u8,\n    detail: []const u8,\n};\n```\n\nUpdate main.zig to dispatch to orphans/lint commands.\n\n## Validation\n1. Test orphans detects missing parent issues\n2. Test orphans detects broken dependencies\n3. Test lint checks database integrity\n4. Test lint checks foreign key violations\n5. Test lint checks invalid statuses/priorities\n6. Test lint detects duplicate content hashes\n7. Test lint --fix rebuilds FTS index\n8. Test --json output for both\n9. `zig build test` passes\n10. Manual test in sandbox/\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-abv (issue CRUD operations)\n- bd-22m (dependency operations)\n- bd-39h (full-text search)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-30T05:38:33.627405632Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:38:33.627405632Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2rh","title":"Implement defer and undefer commands","description":"## Goal\nImplement `bz defer <id> --until <date>` and `bz undefer <id>` commands for temporarily hiding issues from ready queue.\n\n## Technical Approach\nCreate `src/cli/defer.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst IssueStore = @import(\"../storage/issues.zig\").IssueStore;\nconst EventStore = @import(\"../storage/events.zig\").EventStore;\nconst Output = @import(\"../output/mod.zig\").Output;\nconst timestamp = @import(\"../models/timestamp.zig\");\n\npub const DeferArgs = struct {\n    id: []const u8,\n    until: []const u8,  // Date string (ISO format or relative like \"1w\", \"2d\")\n};\n\npub fn run(args: DeferArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var issue_store = IssueStore.init(&db, allocator);\n    var event_store = EventStore.init(&db, allocator);\n    \n    const existing = try issue_store.get(args.id) orelse {\n        try output.err(\"Issue '{s}' not found\", .{args.id});\n        return error.IssueNotFound;\n    };\n    \n    // Parse the \"until\" date\n    const defer_until = try parseUntilDate(args.until);\n    \n    const actor = global.actor orelse try getActor();\n    const now = std.time.timestamp();\n    \n    try db.exec(\"BEGIN IMMEDIATE\");\n    errdefer db.exec(\"ROLLBACK\") catch {};\n    \n    try issue_store.update(args.id, .{\n        .defer_until = defer_until,\n    });\n    \n    try event_store.log(.{\n        .id = 0,\n        .issue_id = args.id,\n        .event_type = .updated,\n        .actor = actor,\n        .old_value = if (existing.defer_until) |d| try timestamp.formatRfc3339Alloc(allocator, d) else null,\n        .new_value = try timestamp.formatRfc3339Alloc(allocator, defer_until),\n        .created_at = now,\n    });\n    \n    try db.exec(\"COMMIT\");\n    \n    if (!global.no_auto_flush) {\n        try autoFlush(&db, allocator);\n    }\n    \n    if (global.json) {\n        try output.printJson(.{\n            .id = args.id,\n            .defer_until = try timestamp.formatRfc3339Alloc(allocator, defer_until),\n        });\n    } else {\n        try output.success(\"Deferred {s} until {s}\", .{\n            args.id,\n            try timestamp.formatRfc3339Alloc(allocator, defer_until),\n        });\n    }\n}\n\n/// Parse date formats:\n/// - ISO 8601: \"2024-02-15\" or \"2024-02-15T10:00:00Z\"\n/// - Relative: \"1d\" (1 day), \"1w\" (1 week), \"2w\" (2 weeks), \"1m\" (1 month)\nfn parseUntilDate(s: []const u8) !i64 {\n    const now = std.time.timestamp();\n    \n    // Try relative format first\n    if (s.len >= 2) {\n        const num_str = s[0 .. s.len - 1];\n        const unit = s[s.len - 1];\n        \n        if (std.fmt.parseInt(i64, num_str, 10)) |num| {\n            const seconds: i64 = switch (unit) {\n                'd' => num * 24 * 60 * 60,           // days\n                'w' => num * 7 * 24 * 60 * 60,       // weeks\n                'm' => num * 30 * 24 * 60 * 60,      // months (approximate)\n                else => return error.InvalidDateFormat,\n            };\n            return now + seconds;\n        } else |_| {}\n    }\n    \n    // Try ISO date format\n    return timestamp.parseRfc3339(s);\n}\n\npub const UndeferArgs = struct {\n    id: []const u8,\n};\n\npub fn runUndefer(args: UndeferArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var issue_store = IssueStore.init(&db, allocator);\n    var event_store = EventStore.init(&db, allocator);\n    \n    const existing = try issue_store.get(args.id) orelse {\n        try output.err(\"Issue '{s}' not found\", .{args.id});\n        return error.IssueNotFound;\n    };\n    \n    if (existing.defer_until == null) {\n        try output.warn(\"Issue '{s}' is not deferred\", .{args.id});\n        return;\n    }\n    \n    const actor = global.actor orelse try getActor();\n    const now = std.time.timestamp();\n    \n    try db.exec(\"BEGIN IMMEDIATE\");\n    errdefer db.exec(\"ROLLBACK\") catch {};\n    \n    try issue_store.update(args.id, .{\n        .defer_until = null,\n        .clear_defer_until = true,\n    });\n    \n    try event_store.log(.{\n        .id = 0,\n        .issue_id = args.id,\n        .event_type = .updated,\n        .actor = actor,\n        .old_value = try timestamp.formatRfc3339Alloc(allocator, existing.defer_until.?),\n        .new_value = null,\n        .created_at = now,\n    });\n    \n    try db.exec(\"COMMIT\");\n    \n    if (!global.no_auto_flush) {\n        try autoFlush(&db, allocator);\n    }\n    \n    if (global.json) {\n        try output.printJson(.{ .id = args.id, .undeferred = true });\n    } else {\n        try output.success(\"Undeferred {s}\", .{args.id});\n    }\n}\n```\n\nUpdate main.zig to dispatch to defer/undefer commands.\n\n## Validation\n1. Test defer with ISO date\n2. Test defer with relative dates (1d, 1w, 2w, 1m)\n3. Test defer excludes issue from ready queue\n4. Test undefer clears defer_until\n5. Test undefer on non-deferred issue warns\n6. Test event logging\n7. Test --json output\n8. `zig build test` passes\n9. Manual test in sandbox/\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-283 (RFC3339 timestamp utilities)\n- bd-abv (issue CRUD operations)\n- bd-2hv (event operations)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-30T05:38:12.718982234Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:38:12.718982234Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2sy","title":"Implement issue ID generation","description":"## Goal\nImplement the hash-based issue ID generation system with adaptive length.\n\n## Technical Approach\nCreate `src/id/generator.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst base36 = @import(\"base36.zig\");\n\npub const IdGenerator = struct {\n    prefix: []const u8,      // Default: \"bd\"\n    min_length: u8,          // Default: 3\n    max_length: u8,          // Default: 8\n    rng: std.rand.Random,    // For entropy\n\n    pub fn init(prefix: []const u8) IdGenerator {\n        return .{\n            .prefix = prefix,\n            .min_length = 3,\n            .max_length = 8,\n            .rng = std.rand.DefaultPrng.init(@intCast(std.time.nanoTimestamp())).random(),\n        };\n    }\n\n    /// Generate a new issue ID\n    /// Format: <prefix>-<base36_hash>\n    /// Example: \"bd-a3f8k2\"\n    pub fn generate(self: *IdGenerator, allocator: std.mem.Allocator, issue_count: usize) ![]u8 {\n        // 1. Generate 16 random bytes\n        var random_bytes: [16]u8 = undefined;\n        self.rng.bytes(&random_bytes);\n        \n        // 2. Mix with nanosecond timestamp\n        const timestamp = std.time.nanoTimestamp();\n        var hasher = std.crypto.hash.sha2.Sha256.init(.{});\n        hasher.update(&random_bytes);\n        hasher.update(std.mem.asBytes(&timestamp));\n        const digest = hasher.finalResult();\n        \n        // 3. Take first N bytes based on issue count (adaptive length)\n        const hash_length = self.adaptiveLength(issue_count);\n        const hash_value = std.mem.readInt(u64, digest[0..8], .big);\n        \n        // 4. Encode as base36\n        var hash_buf: [13]u8 = undefined;\n        const hash_str = base36.encode(hash_value, &hash_buf);\n        \n        // 5. Truncate/pad to desired length\n        const final_hash = hash_str[0..@min(hash_str.len, hash_length)];\n        \n        // 6. Format: prefix-hash\n        return std.fmt.allocPrint(allocator, \"{s}-{s}\", .{ self.prefix, final_hash });\n    }\n\n    /// Adaptive hash length based on issue count (from SPEC.md)\n    /// Uses birthday problem approximation: need sqrt(36^n) entries for ~50% collision\n    fn adaptiveLength(self: IdGenerator, count: usize) u8 {\n        if (count < 1000) return @max(self.min_length, 3);      // 36^3 = 46,656\n        if (count < 50000) return @max(self.min_length, 4);     // 36^4 = 1,679,616\n        if (count < 1000000) return @max(self.min_length, 5);   // 36^5 = 60,466,176\n        return @min(self.max_length, 6);                         // 36^6 = 2,176,782,336\n    }\n\n    /// Generate child ID for hierarchical issues\n    /// Example: \"bd-abc123\" -> \"bd-abc123.1\"\n    pub fn generateChild(self: *IdGenerator, allocator: std.mem.Allocator, parent_id: []const u8, child_index: u32) ![]u8 {\n        // Validate depth (max 3 levels per SPEC)\n        const depth = std.mem.count(u8, parent_id, \".\");\n        if (depth >= 2) return error.MaxHierarchyDepthExceeded;\n        \n        return std.fmt.allocPrint(allocator, \"{s}.{d}\", .{ parent_id, child_index });\n    }\n};\n\n/// Parse an ID into its components\npub const ParsedId = struct {\n    prefix: []const u8,\n    hash: []const u8,\n    child_path: ?[]const u8,  // e.g., \"1.2\" for bd-abc.1.2\n};\n\npub fn parseId(id: []const u8) !ParsedId {\n    // Find prefix-hash boundary\n    const dash_idx = std.mem.indexOf(u8, id, \"-\") orelse return error.InvalidIssueId;\n    const prefix = id[0..dash_idx];\n    const rest = id[dash_idx + 1 ..];\n    \n    // Find hash-child boundary\n    if (std.mem.indexOf(u8, rest, \".\")) |dot_idx| {\n        return .{\n            .prefix = prefix,\n            .hash = rest[0..dot_idx],\n            .child_path = rest[dot_idx + 1 ..],\n        };\n    }\n    \n    return .{\n        .prefix = prefix,\n        .hash = rest,\n        .child_path = null,\n    };\n}\n\n/// Validate ID format\npub fn validateId(id: []const u8) bool {\n    const parsed = parseId(id) catch return false;\n    if (parsed.prefix.len == 0 or parsed.hash.len == 0) return false;\n    // Validate hash is valid base36\n    _ = base36.decode(parsed.hash) catch return false;\n    return true;\n}\n```\n\nUpdate `src/id/mod.zig` to export IdGenerator, parseId, validateId.\n\n## Validation\n1. Test ID format matches \"prefix-hash\"\n2. Test adaptive length increases with issue count\n3. Test child ID generation\n4. Test max hierarchy depth (3 levels)\n5. Test ID parsing extracts correct components\n6. Test ID validation\n7. Test uniqueness (generate many IDs, no collisions)\n8. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-15t (Base36 encoding)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:03:03.532789755Z","created_by":"hotschmoe","updated_at":"2026-01-30T07:13:25.611382222Z","closed_at":"2026-01-30T07:13:25.611356093Z","close_reason":"Completed successfully","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2sz","title":"Implement close and reopen commands","description":"## Goal\nImplement `bz close <id>` and `bz reopen <id>` commands for issue lifecycle.\n\n## Technical Approach\nCreate `src/cli/close.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Status = @import(\"../models/status.zig\").Status;\nconst IssueStore = @import(\"../storage/issues.zig\").IssueStore;\nconst EventStore = @import(\"../storage/events.zig\").EventStore;\nconst Output = @import(\"../output/mod.zig\").Output;\n\npub const CloseArgs = struct {\n    id: []const u8,\n    reason: ?[]const u8 = null,\n};\n\npub fn run(args: CloseArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    \n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var issue_store = IssueStore.init(&db, allocator);\n    var event_store = EventStore.init(&db, allocator);\n    \n    const existing = try issue_store.get(args.id) orelse {\n        try output.err(\"Issue '{s}' not found\", .{args.id});\n        return error.IssueNotFound;\n    };\n    \n    // Check if already closed\n    if (existing.status == .closed) {\n        try output.warn(\"Issue '{s}' is already closed\", .{args.id});\n        return;\n    }\n    \n    const actor = global.actor orelse try getActor();\n    const now = std.time.timestamp();\n    \n    // Update in transaction\n    try db.exec(\"BEGIN IMMEDIATE\");\n    errdefer db.exec(\"ROLLBACK\") catch {};\n    \n    try issue_store.update(args.id, .{\n        .status = .closed,\n        .closed_at = now,\n        .close_reason = args.reason,\n    });\n    \n    try event_store.log(.{\n        .id = 0,\n        .issue_id = args.id,\n        .event_type = .closed,\n        .actor = actor,\n        .old_value = existing.status.toString(),\n        .new_value = \"closed\",\n        .created_at = now,\n    });\n    \n    try db.exec(\"COMMIT\");\n    \n    if (!global.no_auto_flush) {\n        try autoFlush(&db, allocator);\n    }\n    \n    if (global.json) {\n        try output.printJson(.{ .id = args.id, .status = \"closed\" });\n    } else {\n        try output.success(\"Closed issue {s}\", .{args.id});\n    }\n}\n```\n\nCreate `src/cli/reopen.zig`:\n\n```zig\npub const ReopenArgs = struct {\n    id: []const u8,\n};\n\npub fn run(args: ReopenArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    \n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var issue_store = IssueStore.init(&db, allocator);\n    var event_store = EventStore.init(&db, allocator);\n    \n    const existing = try issue_store.get(args.id) orelse {\n        try output.err(\"Issue '{s}' not found\", .{args.id});\n        return error.IssueNotFound;\n    };\n    \n    // Check if not closed\n    if (existing.status != .closed and existing.status != .tombstone) {\n        try output.warn(\"Issue '{s}' is not closed (status: {s})\", .{ args.id, existing.status.toString() });\n        return;\n    }\n    \n    const actor = global.actor orelse try getActor();\n    const now = std.time.timestamp();\n    \n    try db.exec(\"BEGIN IMMEDIATE\");\n    errdefer db.exec(\"ROLLBACK\") catch {};\n    \n    try issue_store.update(args.id, .{\n        .status = .open,\n        .closed_at = null,\n        .close_reason = null,\n    });\n    \n    try event_store.log(.{\n        .id = 0,\n        .issue_id = args.id,\n        .event_type = .reopened,\n        .actor = actor,\n        .old_value = existing.status.toString(),\n        .new_value = \"open\",\n        .created_at = now,\n    });\n    \n    try db.exec(\"COMMIT\");\n    \n    if (!global.no_auto_flush) {\n        try autoFlush(&db, allocator);\n    }\n    \n    if (global.json) {\n        try output.printJson(.{ .id = args.id, .status = \"open\" });\n    } else {\n        try output.success(\"Reopened issue {s}\", .{args.id});\n    }\n}\n```\n\n## Validation\n1. Test close sets status to closed\n2. Test close sets closed_at timestamp\n3. Test close with --reason\n4. Test close already closed issue warns\n5. Test reopen sets status to open\n6. Test reopen clears closed_at\n7. Test reopen non-closed issue warns\n8. Test reopen tombstoned issue (restore)\n9. Test event logging for both\n10. Test --json output\n11. `zig build test` passes\n12. Manual test in sandbox/\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-abv (issue CRUD)\n- bd-2hv (event operations)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-30T05:14:46.301977030Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:14:46.301977030Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2u2","title":"Implement comments commands","description":"## Goal\nImplement `bz comments` subcommands for comment management.\n\n## Technical Approach\nCreate `src/cli/comments.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Comment = @import(\"../models/comment.zig\").Comment;\nconst CommentStore = @import(\"../storage/comments.zig\").CommentStore;\nconst EventStore = @import(\"../storage/events.zig\").EventStore;\nconst Output = @import(\"../output/mod.zig\").Output;\n\npub const CommentsArgs = union(enum) {\n    add: struct {\n        id: []const u8,\n        text: []const u8,\n    },\n    list: struct {\n        id: []const u8,\n    },\n};\n\npub fn run(args: CommentsArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    switch (args) {\n        .add => |a| try runAdd(a.id, a.text, global, allocator),\n        .list => |l| try runList(l.id, global, allocator),\n    }\n}\n\nfn runAdd(id: []const u8, text: []const u8, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    \n    if (text.len == 0) {\n        try output.err(\"Comment text cannot be empty\", .{});\n        return error.EmptyCommentBody;\n    }\n    \n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var comment_store = CommentStore.init(&db, allocator);\n    var event_store = EventStore.init(&db, allocator);\n    \n    // Verify issue exists\n    var issue_store = IssueStore.init(&db, allocator);\n    _ = try issue_store.get(id) orelse {\n        try output.err(\"Issue '{s}' not found\", .{id});\n        return error.IssueNotFound;\n    };\n    \n    const actor = global.actor orelse try getActor();\n    const now = std.time.timestamp();\n    \n    const comment_id = try comment_store.add(.{\n        .id = 0,\n        .issue_id = id,\n        .author = actor,\n        .body = text,\n        .created_at = now,\n    });\n    \n    try event_store.log(.{\n        .id = 0,\n        .issue_id = id,\n        .event_type = .commented,\n        .actor = actor,\n        .old_value = null,\n        .new_value = text,\n        .created_at = now,\n    });\n    \n    if (!global.no_auto_flush) {\n        try autoFlush(&db, allocator);\n    }\n    \n    if (global.json) {\n        try output.printJson(.{\n            .id = comment_id,\n            .issue_id = id,\n            .author = actor,\n        });\n    } else {\n        try output.success(\"Added comment to {s}\", .{id});\n    }\n}\n\nfn runList(id: []const u8, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var comment_store = CommentStore.init(&db, allocator);\n    \n    // Verify issue exists\n    var issue_store = IssueStore.init(&db, allocator);\n    _ = try issue_store.get(id) orelse {\n        try output.err(\"Issue '{s}' not found\", .{id});\n        return error.IssueNotFound;\n    };\n    \n    const comments = try comment_store.getComments(id);\n    \n    if (global.json) {\n        try output.printJson(comments);\n    } else {\n        if (comments.len == 0) {\n            try output.print(\"No comments on {s}\\n\", .{id});\n        } else {\n            try output.print(\"Comments on {s} ({d}):\\n\", .{ id, comments.len });\n            for (comments) |comment| {\n                try output.print(\"\\n\", .{});\n                try output.printDim(\"[{s}] \", .{formatTimestamp(comment.created_at)});\n                try output.printBold(\"{s}:\\n\", .{comment.author});\n                try output.print(\"{s}\\n\", .{comment.body});\n            }\n        }\n    }\n}\n```\n\n## Validation\n1. Test comments add creates comment\n2. Test comments add with empty text fails\n3. Test comments list shows comments\n4. Test comments list in chronological order\n5. Test event logging\n6. Test --json output\n7. `zig build test` passes\n8. Manual test in sandbox/\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-nwm (Comment struct)\n- bd-1c7 (comment operations)\n- bd-2hv (event operations)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-30T05:19:23.029735843Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:19:23.029735843Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2ui","title":"Implement search command","description":"## Goal\nImplement `bz search <query>` command for full-text search.\n\n## Technical Approach\nCreate `src/cli/search.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst SearchStore = @import(\"../storage/search.zig\").SearchStore;\nconst Output = @import(\"../output/mod.zig\").Output;\n\npub const SearchArgs = struct {\n    query: []const u8,\n    limit: ?u32 = null,\n    status: ?[]const u8 = null,\n};\n\npub fn run(args: SearchArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    \n    if (args.query.len == 0) {\n        try output.err(\"Search query cannot be empty\", .{});\n        return error.EmptyQuery;\n    }\n    \n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var search_store = SearchStore.init(&db, allocator);\n    \n    const results = try search_store.search(args.query, args.limit orelse 20);\n    \n    // Filter by status if specified\n    var filtered = results;\n    if (args.status) |s| {\n        const status = Status.fromString(s);\n        filtered = filterByStatus(results, status);\n    }\n    \n    if (global.json) {\n        try output.printJson(filtered);\n    } else if (global.quiet) {\n        for (filtered) |result| {\n            try output.print(\"{s}\\n\", .{result.issue.id});\n        }\n    } else {\n        if (filtered.len == 0) {\n            try output.print(\"No issues matching \\\"{s}\\\"\\n\", .{args.query});\n            return;\n        }\n        \n        try output.print(\"Search results for \\\"{s}\\\" ({d} matches)\\n\\n\", .{ args.query, filtered.len });\n        \n        for (filtered) |result| {\n            try output.print(\"{s}  \", .{result.issue.id});\n            try output.printStatus(result.issue.status);\n            try output.print(\"  {s}\\n\", .{result.issue.title});\n            \n            // Show snippet of matching content\n            if (result.issue.description) |desc| {\n                const snippet = truncate(desc, 80);\n                try output.printDim(\"    {s}\\n\", .{snippet});\n            }\n        }\n    }\n}\n\nfn truncate(s: []const u8, max_len: usize) []const u8 {\n    if (s.len <= max_len) return s;\n    return s[0 .. max_len - 3];\n}\n```\n\n## Validation\n1. Test search returns matching issues\n2. Test search ranking (FTS5 bm25)\n3. Test --limit\n4. Test --status filter\n5. Test empty query error\n6. Test no results message\n7. Test --json output\n8. `zig build test` passes\n9. Manual test in sandbox/\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-39h (full-text search)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-30T05:17:41.409698117Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:17:41.409698117Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2uu","title":"Add comprehensive unit tests","description":"## Goal\nAdd comprehensive unit tests for all core modules.\n\n## Technical Approach\nAdd inline tests to each module following Zig conventions. Create `src/tests/` for integration tests.\n\nKey test areas:\n\n1. **Models tests** (inline in each model file):\n```zig\n// src/models/status.zig\ntest \"Status.fromString case insensitive\" {\n    try std.testing.expectEqual(Status.open, Status.fromString(\"OPEN\"));\n    try std.testing.expectEqual(Status.open, Status.fromString(\"Open\"));\n    try std.testing.expectEqual(Status.open, Status.fromString(\"open\"));\n}\n\ntest \"Status.fromString custom\" {\n    const custom = Status.fromString(\"my_custom_status\");\n    try std.testing.expectEqual(@as(Status, .{ .custom = \"my_custom_status\" }), custom);\n}\n```\n\n2. **ID generation tests**:\n```zig\n// src/id/generator.zig\ntest \"generateId format\" {\n    var gen = IdGenerator.init(\"bd\");\n    const id = try gen.generate(std.testing.allocator, 0);\n    defer std.testing.allocator.free(id);\n    \n    try std.testing.expect(std.mem.startsWith(u8, id, \"bd-\"));\n    try std.testing.expect(id.len >= 5);  // \"bd-\" + at least 3 chars\n}\n\ntest \"generateId uniqueness\" {\n    var gen = IdGenerator.init(\"bd\");\n    var ids = std.StringHashMap(void).init(std.testing.allocator);\n    defer ids.deinit();\n    \n    // Generate 1000 IDs, expect no collisions\n    var i: usize = 0;\n    while (i < 1000) : (i += 1) {\n        const id = try gen.generate(std.testing.allocator, i);\n        try std.testing.expect(!ids.contains(id));\n        try ids.put(id, {});\n    }\n}\n```\n\n3. **Storage tests** (using temp databases):\n```zig\n// src/tests/storage_test.zig\ntest \"IssueStore insert and get\" {\n    var tmp = std.testing.tmpDir(.{});\n    defer tmp.cleanup();\n    \n    const db_path = try tmp.dir.realpathAlloc(std.testing.allocator, \"test.db\");\n    defer std.testing.allocator.free(db_path);\n    \n    var db = try Database.open(std.testing.allocator, db_path);\n    defer db.close();\n    try schema.createSchema(&db);\n    \n    var store = IssueStore.init(&db, std.testing.allocator);\n    \n    const issue = Issue{ /* ... */ };\n    try store.insert(issue);\n    \n    const retrieved = try store.get(issue.id);\n    try std.testing.expect(retrieved != null);\n    try std.testing.expectEqualStrings(issue.title, retrieved.?.title);\n}\n```\n\n4. **JSONL tests**:\n```zig\n// src/tests/sync_test.zig\ntest \"JSONL roundtrip preserves all fields\" {\n    // Create issue with all fields populated\n    // Export to JSONL\n    // Clear database\n    // Import from JSONL\n    // Verify all fields match\n}\n\ntest \"JSONL import detects merge conflicts\" {\n    const content = \"<<<<<<< HEAD\\n{...}\\n=======\\n{...}\\n>>>>>>>\";\n    // Verify error.MergeConflictDetected\n}\n```\n\n5. **Dependency tests**:\n```zig\ntest \"cycle detection simple\" {\n    // A -> B -> A should fail\n}\n\ntest \"cycle detection complex\" {\n    // A -> B -> C -> D -> B should fail\n}\n\ntest \"getReadyIssues excludes blocked\" {\n    // Create A, B, C\n    // B depends on A\n    // Ready should return A and C only\n}\n```\n\n## Validation\n1. All model tests pass\n2. All ID generation tests pass\n3. All storage tests pass\n4. All sync tests pass\n5. All dependency tests pass\n6. `zig build test` passes with 0 failures\n7. Test coverage of critical paths\n\n## Dependencies\n- All model implementations\n- All storage implementations\n- All sync implementations","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-30T05:28:39.485469146Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:28:39.485469146Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-31b","title":"Add CLI integration tests","description":"## Goal\nAdd integration tests that test the CLI end-to-end.\n\n## Technical Approach\nCreate `src/tests/cli_test.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst ChildProcess = std.process.Child;\n\nfn runBz(allocator: std.mem.Allocator, args: []const []const u8, cwd: ?[]const u8) !struct { stdout: []u8, stderr: []u8, term: std.process.Child.Term } {\n    var argv = std.ArrayList([]const u8).init(allocator);\n    defer argv.deinit();\n    \n    try argv.append(\"./zig-out/bin/bz\");\n    for (args) |arg| try argv.append(arg);\n    \n    var child = ChildProcess.init(argv.items, allocator);\n    child.cwd = cwd;\n    child.stdout_behavior = .Pipe;\n    child.stderr_behavior = .Pipe;\n    \n    try child.spawn();\n    \n    const stdout = try child.stdout.?.reader().readAllAlloc(allocator, 1024 * 1024);\n    const stderr = try child.stderr.?.reader().readAllAlloc(allocator, 1024 * 1024);\n    const term = try child.wait();\n    \n    return .{ .stdout = stdout, .stderr = stderr, .term = term };\n}\n\ntest \"bz init creates workspace\" {\n    var tmp = std.testing.tmpDir(.{});\n    defer tmp.cleanup();\n    \n    const cwd = try tmp.dir.realpathAlloc(std.testing.allocator, \".\");\n    defer std.testing.allocator.free(cwd);\n    \n    const result = try runBz(std.testing.allocator, &[_][]const u8{\"init\"}, cwd);\n    defer std.testing.allocator.free(result.stdout);\n    defer std.testing.allocator.free(result.stderr);\n    \n    try std.testing.expectEqual(@as(u32, 0), result.term.Exited);\n    \n    // Verify files created\n    try tmp.dir.access(\".beads/beads.db\", .{});\n    try tmp.dir.access(\".beads/config.yaml\", .{});\n}\n\ntest \"bz create returns ID\" {\n    var tmp = std.testing.tmpDir(.{});\n    defer tmp.cleanup();\n    \n    const cwd = try tmp.dir.realpathAlloc(std.testing.allocator, \".\");\n    defer std.testing.allocator.free(cwd);\n    \n    // Init first\n    _ = try runBz(std.testing.allocator, &[_][]const u8{\"init\"}, cwd);\n    \n    // Create issue\n    const result = try runBz(std.testing.allocator, &[_][]const u8{ \"create\", \"Test issue\" }, cwd);\n    defer std.testing.allocator.free(result.stdout);\n    defer std.testing.allocator.free(result.stderr);\n    \n    try std.testing.expectEqual(@as(u32, 0), result.term.Exited);\n    try std.testing.expect(std.mem.indexOf(u8, result.stdout, \"bd-\") != null);\n}\n\ntest \"bz list --json returns valid JSON\" {\n    var tmp = std.testing.tmpDir(.{});\n    defer tmp.cleanup();\n    \n    const cwd = try tmp.dir.realpathAlloc(std.testing.allocator, \".\");\n    \n    _ = try runBz(std.testing.allocator, &[_][]const u8{\"init\"}, cwd);\n    _ = try runBz(std.testing.allocator, &[_][]const u8{ \"create\", \"Test\" }, cwd);\n    \n    const result = try runBz(std.testing.allocator, &[_][]const u8{ \"list\", \"--json\" }, cwd);\n    defer std.testing.allocator.free(result.stdout);\n    \n    // Verify valid JSON\n    const parsed = try std.json.parseFromSlice(std.json.Value, std.testing.allocator, result.stdout, .{});\n    defer parsed.deinit();\n    \n    try std.testing.expect(parsed.value == .array);\n}\n\ntest \"bz show not-found suggests similar\" {\n    var tmp = std.testing.tmpDir(.{});\n    defer tmp.cleanup();\n    \n    const cwd = try tmp.dir.realpathAlloc(std.testing.allocator, \".\");\n    \n    _ = try runBz(std.testing.allocator, &[_][]const u8{\"init\"}, cwd);\n    _ = try runBz(std.testing.allocator, &[_][]const u8{ \"create\", \"Test issue\" }, cwd);\n    \n    const result = try runBz(std.testing.allocator, &[_][]const u8{ \"show\", \"bd-nonexistent\" }, cwd);\n    defer std.testing.allocator.free(result.stderr);\n    \n    try std.testing.expectEqual(@as(u32, 1), result.term.Exited);\n    try std.testing.expect(std.mem.indexOf(u8, result.stderr, \"Did you mean\") != null);\n}\n\ntest \"bz dep add rejects cycles\" {\n    var tmp = std.testing.tmpDir(.{});\n    defer tmp.cleanup();\n    \n    const cwd = try tmp.dir.realpathAlloc(std.testing.allocator, \".\");\n    \n    _ = try runBz(std.testing.allocator, &[_][]const u8{\"init\"}, cwd);\n    \n    // Create A and B\n    const a_result = try runBz(std.testing.allocator, &[_][]const u8{ \"q\", \"Issue A\" }, cwd);\n    const id_a = std.mem.trim(u8, a_result.stdout, \"\\n \");\n    \n    const b_result = try runBz(std.testing.allocator, &[_][]const u8{ \"q\", \"Issue B\" }, cwd);\n    const id_b = std.mem.trim(u8, b_result.stdout, \"\\n \");\n    \n    // A depends on B\n    _ = try runBz(std.testing.allocator, &[_][]const u8{ \"dep\", \"add\", id_a, id_b }, cwd);\n    \n    // B depends on A should fail\n    const result = try runBz(std.testing.allocator, &[_][]const u8{ \"dep\", \"add\", id_b, id_a }, cwd);\n    \n    try std.testing.expectEqual(@as(u32, 1), result.term.Exited);\n    try std.testing.expect(std.mem.indexOf(u8, result.stderr, \"cycle\") != null);\n}\n```\n\n## Validation\n1. All CLI integration tests pass\n2. Tests verify correct exit codes\n3. Tests verify stdout/stderr content\n4. Tests use isolated temp directories\n5. Tests cover critical user workflows\n6. `zig build test` passes\n\n## Dependencies\n- bd-1f5 (main CLI dispatcher)\n- bd-2uu (comprehensive unit tests - test infrastructure patterns)","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-30T05:29:03.339629761Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:36:20.446925308Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-39h","title":"Implement full-text search","description":"## Goal\nImplement FTS5-based full-text search for issues.\n\n## Technical Approach\nCreate `src/storage/search.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Database = @import(\"sqlite.zig\").Database;\nconst Issue = @import(\"../models/issue.zig\").Issue;\n\npub const SearchStore = struct {\n    db: *Database,\n    allocator: std.mem.Allocator,\n\n    pub fn init(db: *Database, allocator: std.mem.Allocator) SearchStore {\n        return .{ .db = db, .allocator = allocator };\n    }\n\n    /// Search issues by query string\n    /// Uses FTS5 for ranking and matching\n    pub fn search(self: *SearchStore, query: []const u8, limit: ?u32) ![]SearchResult {\n        const sql = \n            \\\\SELECT i.*, bm25(issues_fts) as rank\n            \\\\FROM issues_fts\n            \\\\JOIN issues i ON issues_fts.id = i.id\n            \\\\WHERE issues_fts MATCH ?1\n            \\\\AND i.status != 'tombstone'\n            \\\\ORDER BY rank\n            \\\\LIMIT ?2\n        ;\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindText(1, query);\n        try stmt.bindInt(2, @intCast(limit orelse 50));\n        \n        var results = std.ArrayList(SearchResult).init(self.allocator);\n        errdefer results.deinit();\n        \n        while (try stmt.step()) {\n            try results.append(.{\n                .issue = try self.rowToIssue(&stmt),\n                .rank = stmt.columnFloat(stmt.columnCount() - 1),\n            });\n        }\n        \n        return results.toOwnedSlice();\n    }\n\n    /// Update FTS index for an issue\n    pub fn indexIssue(self: *SearchStore, issue: Issue) !void {\n        // Delete old entry\n        const del_sql = \"DELETE FROM issues_fts WHERE id = ?1\";\n        var del_stmt = try self.db.prepare(del_sql);\n        defer del_stmt.deinit();\n        try del_stmt.bindText(1, issue.id);\n        _ = try del_stmt.step();\n        \n        // Insert new entry\n        const ins_sql = \n            \\\\INSERT INTO issues_fts (id, title, description, notes)\n            \\\\VALUES (?1, ?2, ?3, ?4)\n        ;\n        var ins_stmt = try self.db.prepare(ins_sql);\n        defer ins_stmt.deinit();\n        try ins_stmt.bindText(1, issue.id);\n        try ins_stmt.bindText(2, issue.title);\n        try ins_stmt.bindText(3, issue.description);\n        try ins_stmt.bindText(4, issue.notes);\n        _ = try ins_stmt.step();\n    }\n\n    /// Remove issue from FTS index\n    pub fn removeFromIndex(self: *SearchStore, issue_id: []const u8) !void {\n        const sql = \"DELETE FROM issues_fts WHERE id = ?1\";\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindText(1, issue_id);\n        _ = try stmt.step();\n    }\n\n    /// Rebuild entire FTS index from issues table\n    pub fn rebuildIndex(self: *SearchStore) !void {\n        try self.db.exec(\"DELETE FROM issues_fts\");\n        try self.db.exec(\n            \\\\INSERT INTO issues_fts (id, title, description, notes)\n            \\\\SELECT id, title, description, notes FROM issues\n            \\\\WHERE status != 'tombstone'\n        );\n    }\n};\n\npub const SearchResult = struct {\n    issue: Issue,\n    rank: f64,  // FTS5 bm25 score (lower is better)\n};\n```\n\nUpdate `src/storage/mod.zig` to export SearchStore.\n\n## Validation\n1. Test basic search returns matching issues\n2. Test search ranking (relevant results first)\n3. Test indexIssue adds to index\n4. Test removeFromIndex removes from index\n5. Test rebuildIndex recreates full index\n6. Test search excludes tombstoned issues\n7. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-2o2 (database schema)\n- bd-abv (issue CRUD operations)","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-30T05:07:20.251254740Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:07:20.251254740Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-3jg","title":"Create project directory structure","description":"## Goal\nEstablish the complete directory structure for beads_zig as defined in FEATURE_PARITY.md.\n\n## Technical Approach\nCreate the following directory tree:\n```\nsrc/\n main.zig              # CLI entry point (exists)\n root.zig              # Library exports (exists)\n cli/                  # Command implementations\n    mod.zig           # CLI module root\n storage/              # Database layer\n    mod.zig\n models/               # Data structures\n    mod.zig\n sync/                 # JSONL import/export\n    mod.zig\n id/                   # ID generation\n    mod.zig\n config/               # Configuration\n    mod.zig\n output/               # Formatting\n     mod.zig\n```\n\nEach `mod.zig` should:\n1. Be a minimal placeholder with a comment describing the module's purpose\n2. Export any public declarations (empty for now)\n3. Import and re-export submodules as they're created\n\nUpdate `root.zig` to import all module roots.\n\n## Validation\n1. `zig build` succeeds\n2. All directories exist\n3. Each mod.zig compiles without errors\n4. `zig build test` passes (no test failures from empty modules)\n\n## Dependencies\nNone - this is foundational","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T04:59:49.396440099Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:49:43.330196667Z","closed_at":"2026-01-30T05:49:43.330165848Z","close_reason":"Completed successfully","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-3pk","title":"Implement label operations","description":"## Goal\nImplement database operations for issue labels.\n\n## Technical Approach\nCreate `src/storage/labels.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Database = @import(\"sqlite.zig\").Database;\nconst Issue = @import(\"../models/issue.zig\").Issue;\n\npub const LabelStore = struct {\n    db: *Database,\n    allocator: std.mem.Allocator,\n\n    pub fn init(db: *Database, allocator: std.mem.Allocator) LabelStore {\n        return .{ .db = db, .allocator = allocator };\n    }\n\n    /// Add a label to an issue\n    pub fn add(self: *LabelStore, issue_id: []const u8, label: []const u8) !void {\n        const sql = \"INSERT OR IGNORE INTO labels (issue_id, label) VALUES (?1, ?2)\";\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindText(1, issue_id);\n        try stmt.bindText(2, label);\n        _ = try stmt.step();\n        \n        // Mark issue as dirty\n        try self.markIssueDirty(issue_id);\n    }\n\n    /// Add multiple labels to an issue\n    pub fn addMany(self: *LabelStore, issue_id: []const u8, labels: []const []const u8) !void {\n        for (labels) |label| {\n            try self.add(issue_id, label);\n        }\n    }\n\n    /// Remove a label from an issue\n    pub fn remove(self: *LabelStore, issue_id: []const u8, label: []const u8) !void {\n        const sql = \"DELETE FROM labels WHERE issue_id = ?1 AND label = ?2\";\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindText(1, issue_id);\n        try stmt.bindText(2, label);\n        _ = try stmt.step();\n        \n        try self.markIssueDirty(issue_id);\n    }\n\n    /// Get all labels for an issue\n    pub fn getLabels(self: *LabelStore, issue_id: []const u8) ![][]const u8 {\n        const sql = \"SELECT label FROM labels WHERE issue_id = ?1 ORDER BY label\";\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindText(1, issue_id);\n        \n        var labels = std.ArrayList([]const u8).init(self.allocator);\n        errdefer labels.deinit();\n        \n        while (try stmt.step()) {\n            const label = stmt.columnText(0) orelse continue;\n            try labels.append(try self.allocator.dupe(u8, label));\n        }\n        \n        return labels.toOwnedSlice();\n    }\n\n    /// Get all unique labels in the project\n    pub fn getAllLabels(self: *LabelStore) ![][]const u8 {\n        const sql = \"SELECT DISTINCT label FROM labels ORDER BY label\";\n        // Execute and return array\n    }\n\n    /// Get all issues with a specific label\n    pub fn getIssuesByLabel(self: *LabelStore, label: []const u8) ![]Issue {\n        const sql = \n            \\\\SELECT i.* FROM issues i\n            \\\\JOIN labels l ON l.issue_id = i.id\n            \\\\WHERE l.label = ?1\n            \\\\ORDER BY i.priority ASC, i.created_at DESC\n        ;\n        // Execute and return issues\n    }\n\n    /// Check if issue has a specific label\n    pub fn hasLabel(self: *LabelStore, issue_id: []const u8, label: []const u8) !bool {\n        const sql = \"SELECT 1 FROM labels WHERE issue_id = ?1 AND label = ?2\";\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindText(1, issue_id);\n        try stmt.bindText(2, label);\n        return try stmt.step();\n    }\n\n    fn markIssueDirty(self: *LabelStore, issue_id: []const u8) !void {\n        const sql = \"INSERT OR REPLACE INTO dirty_issues (issue_id, marked_at) VALUES (?1, ?2)\";\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindText(1, issue_id);\n        try stmt.bindInt(2, std.time.timestamp());\n        _ = try stmt.step();\n    }\n};\n```\n\nUpdate `src/storage/mod.zig` to export LabelStore.\n\n## Validation\n1. Test add label\n2. Test add duplicate label (should not error)\n3. Test remove label\n4. Test getLabels returns sorted list\n5. Test getAllLabels returns unique labels\n6. Test getIssuesByLabel\n7. Test hasLabel\n8. Test dirty marking on label change\n9. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-2o2 (database schema)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:06:01.869775645Z","created_by":"hotschmoe","updated_at":"2026-01-30T19:40:17.199550632Z","closed_at":"2026-01-30T19:40:17.199518380Z","close_reason":"Label operations implemented in IssueStore: addLabel(), removeLabel(), labels stored in Issue struct","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-3rn","title":"Implement dirty tracking for sync","description":"## Goal\nImplement dirty issue tracking for incremental JSONL sync.\n\n## Technical Approach\nCreate `src/storage/dirty.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Database = @import(\"sqlite.zig\").Database;\n\npub const DirtyTracker = struct {\n    db: *Database,\n    allocator: std.mem.Allocator,\n\n    pub fn init(db: *Database, allocator: std.mem.Allocator) DirtyTracker {\n        return .{ .db = db, .allocator = allocator };\n    }\n\n    /// Mark an issue as dirty (needs to be exported)\n    pub fn markDirty(self: *DirtyTracker, issue_id: []const u8) !void {\n        const sql = \"INSERT OR REPLACE INTO dirty_issues (issue_id, marked_at) VALUES (?1, ?2)\";\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindText(1, issue_id);\n        try stmt.bindInt(2, std.time.timestamp());\n        _ = try stmt.step();\n    }\n\n    /// Mark multiple issues as dirty\n    pub fn markDirtyBatch(self: *DirtyTracker, issue_ids: []const []const u8) !void {\n        const sql = \"INSERT OR REPLACE INTO dirty_issues (issue_id, marked_at) VALUES (?1, ?2)\";\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        \n        const now = std.time.timestamp();\n        for (issue_ids) |id| {\n            try stmt.bindText(1, id);\n            try stmt.bindInt(2, now);\n            _ = try stmt.step();\n            try stmt.reset();\n        }\n    }\n\n    /// Get all dirty issue IDs\n    pub fn getDirtyIssues(self: *DirtyTracker) ![][]const u8 {\n        const sql = \"SELECT issue_id FROM dirty_issues ORDER BY marked_at ASC\";\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        \n        var ids = std.ArrayList([]const u8).init(self.allocator);\n        errdefer ids.deinit();\n        \n        while (try stmt.step()) {\n            const id = stmt.columnText(0) orelse continue;\n            try ids.append(try self.allocator.dupe(u8, id));\n        }\n        \n        return ids.toOwnedSlice();\n    }\n\n    /// Check if any issues are dirty\n    pub fn hasDirtyIssues(self: *DirtyTracker) !bool {\n        const sql = \"SELECT 1 FROM dirty_issues LIMIT 1\";\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        return try stmt.step();\n    }\n\n    /// Get count of dirty issues\n    pub fn countDirty(self: *DirtyTracker) !u32 {\n        const sql = \"SELECT COUNT(*) FROM dirty_issues\";\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        _ = try stmt.step();\n        return @intCast(stmt.columnInt(0));\n    }\n\n    /// Clear dirty flag for specific issues (after successful export)\n    pub fn clearDirty(self: *DirtyTracker, issue_ids: []const []const u8) !void {\n        if (issue_ids.len == 0) return;\n        \n        const sql = \"DELETE FROM dirty_issues WHERE issue_id = ?1\";\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        \n        for (issue_ids) |id| {\n            try stmt.bindText(1, id);\n            _ = try stmt.step();\n            try stmt.reset();\n        }\n    }\n\n    /// Clear all dirty flags\n    pub fn clearAllDirty(self: *DirtyTracker) !void {\n        try self.db.exec(\"DELETE FROM dirty_issues\");\n    }\n\n    /// Check if a specific issue is dirty\n    pub fn isDirty(self: *DirtyTracker, issue_id: []const u8) !bool {\n        const sql = \"SELECT 1 FROM dirty_issues WHERE issue_id = ?1\";\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindText(1, issue_id);\n        return try stmt.step();\n    }\n};\n```\n\nUpdate `src/storage/mod.zig` to export DirtyTracker.\n\n## Validation\n1. Test markDirty adds entry\n2. Test markDirtyBatch adds multiple\n3. Test getDirtyIssues returns correct IDs\n4. Test hasDirtyIssues returns correct boolean\n5. Test countDirty returns correct count\n6. Test clearDirty removes specific entries\n7. Test clearAllDirty removes all entries\n8. Test isDirty checks specific issue\n9. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-2o2 (database schema)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:07:31.280230753Z","created_by":"hotschmoe","updated_at":"2026-01-30T19:39:00.130492488Z","closed_at":"2026-01-30T19:39:00.130445197Z","close_reason":"Dirty tracking implemented in IssueStore (src/storage/store.zig) using JSONL architecture instead of SQLite","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-3t8","title":"Implement Priority struct","description":"## Goal\nImplement the Priority struct for issue prioritization (0-4 scale, lower = higher priority).\n\n## Technical Approach\nCreate `src/models/priority.zig`:\n\n```zig\npub const Priority = struct {\n    value: u3,  // 0-4\n\n    pub const CRITICAL = Priority{ .value = 0 };\n    pub const HIGH = Priority{ .value = 1 };\n    pub const MEDIUM = Priority{ .value = 2 };  // Default\n    pub const LOW = Priority{ .value = 3 };\n    pub const BACKLOG = Priority{ .value = 4 };\n\n    pub fn fromInt(n: anytype) !Priority {\n        const val = std.math.cast(u3, n) orelse return error.InvalidPriority;\n        if (val > 4) return error.InvalidPriority;\n        return Priority{ .value = val };\n    }\n\n    pub fn fromString(s: []const u8) !Priority {\n        // Parse \"critical\", \"high\", \"medium\", \"low\", \"backlog\"\n        // Also parse numeric strings \"0\", \"1\", \"2\", \"3\", \"4\"\n        // Case-insensitive\n    }\n\n    pub fn toString(self: Priority) []const u8 {\n        return switch (self.value) {\n            0 => \"critical\",\n            1 => \"high\",\n            2 => \"medium\",\n            3 => \"low\",\n            4 => \"backlog\",\n            else => unreachable,\n        };\n    }\n\n    pub fn toInt(self: Priority) u3 {\n        return self.value;\n    }\n\n    // Comparison: lower value = higher priority\n    pub fn compare(a: Priority, b: Priority) std.math.Order {\n        return std.math.order(a.value, b.value);\n    }\n\n    // JSON serialization as integer\n    pub fn jsonStringify(...)\n    pub fn jsonParse(...)\n};\n```\n\nKey details:\n- u3 constrains to 0-7 at type level, runtime check for 0-4\n- Support both string names and numeric values for parsing\n- Serialize as integer in JSON (matches beads_rust JSONL format)\n\nUpdate `src/models/mod.zig` to export Priority.\n\n## Validation\n1. Test fromInt with valid (0-4) and invalid (5, -1) values\n2. Test fromString with names and numbers\n3. Test comparison ordering (0 < 1 < 2 < 3 < 4)\n4. Test JSON roundtrip (serializes as integer)\n5. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:00:26.884276666Z","created_by":"hotschmoe","updated_at":"2026-01-30T06:01:48.902341508Z","closed_at":"2026-01-30T06:01:48.902317160Z","close_reason":"Completed successfully","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-4y7","title":"Implement IssueType enum","description":"## Goal\nImplement the IssueType enum for categorizing issues.\n\n## Technical Approach\nCreate `src/models/issue_type.zig`:\n\n```zig\npub const IssueType = union(enum) {\n    task,       // Default\n    bug,\n    feature,\n    epic,\n    chore,\n    docs,\n    question,\n    custom: []const u8,\n\n    pub fn toString(self: IssueType) []const u8 {\n        return switch (self) {\n            .task => \"task\",\n            .bug => \"bug\",\n            .feature => \"feature\",\n            .epic => \"epic\",\n            .chore => \"chore\",\n            .docs => \"docs\",\n            .question => \"question\",\n            .custom => |s| s,\n        };\n    }\n\n    pub fn fromString(s: []const u8) IssueType {\n        // Case-insensitive matching\n        // Return .custom for unknown values\n    }\n\n    // JSON serialization as string\n    pub fn jsonStringify(...)\n    pub fn jsonParse(...)\n};\n```\n\nKey details:\n- Tagged union allows custom types while providing type safety for known types\n- Case-insensitive parsing\n- Serialize as lowercase string in JSON\n- \"task\" is the default type (handled at usage site, not in this struct)\n\nUpdate `src/models/mod.zig` to export IssueType.\n\n## Validation\n1. Test toString/fromString roundtrip for all variants\n2. Test case-insensitive parsing\n3. Test custom type handling\n4. Test JSON serialization (as string)\n5. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:00:32.493986266Z","created_by":"hotschmoe","updated_at":"2026-01-30T06:05:56.814551299Z","closed_at":"2026-01-30T06:05:56.814521944Z","close_reason":"Completed successfully","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-5hg","title":"Implement output formatting system","description":"## Goal\nImplement output formatting with support for plain text, colored, JSON, and quiet modes.\n\n## Technical Approach\nCreate `src/output/mod.zig` and supporting files:\n\n```zig\n// src/output/mod.zig\nconst std = @import(\"std\");\n\npub const OutputMode = enum {\n    plain,      // No colors, basic formatting\n    rich,       // Colors and formatting (TTY)\n    json,       // Structured JSON output\n    quiet,      // Minimal output\n};\n\npub const Output = struct {\n    mode: OutputMode,\n    writer: std.fs.File.Writer,\n    allocator: std.mem.Allocator,\n\n    pub fn init(allocator: std.mem.Allocator, global_opts: anytype) Output {\n        const stdout = std.io.getStdOut();\n        \n        var mode: OutputMode = .plain;\n        if (global_opts.json) {\n            mode = .json;\n        } else if (global_opts.quiet) {\n            mode = .quiet;\n        } else if (!global_opts.no_color and stdout.isTty()) {\n            mode = .rich;\n        }\n        \n        return .{\n            .mode = mode,\n            .writer = stdout.writer(),\n            .allocator = allocator,\n        };\n    }\n\n    // Issue display\n    pub fn printIssue(self: *Output, issue: Issue) !void {\n        switch (self.mode) {\n            .json => try self.printIssueJson(issue),\n            .quiet => try self.printIssueQuiet(issue),\n            .rich => try self.printIssueRich(issue),\n            .plain => try self.printIssuePlain(issue),\n        }\n    }\n\n    pub fn printIssueList(self: *Output, issues: []const Issue) !void {\n        switch (self.mode) {\n            .json => try self.printIssueListJson(issues),\n            .quiet => try self.printIssueListQuiet(issues),\n            .rich => try self.printIssueListRich(issues),\n            .plain => try self.printIssueListPlain(issues),\n        }\n    }\n\n    // Generic messages\n    pub fn print(self: *Output, comptime fmt: []const u8, args: anytype) !void {\n        if (self.mode == .quiet) return;\n        try self.writer.print(fmt, args);\n    }\n\n    pub fn success(self: *Output, comptime fmt: []const u8, args: anytype) !void {\n        if (self.mode == .quiet) return;\n        if (self.mode == .rich) try self.writer.writeAll(\"\\x1b[32m\"); // Green\n        try self.writer.print(fmt, args);\n        if (self.mode == .rich) try self.writer.writeAll(\"\\x1b[0m\");\n        try self.writer.writeByte('\\n');\n    }\n\n    pub fn err(self: *Output, comptime fmt: []const u8, args: anytype) !void {\n        const stderr = std.io.getStdErr().writer();\n        if (self.mode == .rich) try stderr.writeAll(\"\\x1b[31m\"); // Red\n        try stderr.print(\"error: \" ++ fmt, args);\n        if (self.mode == .rich) try stderr.writeAll(\"\\x1b[0m\");\n        try stderr.writeByte('\\n');\n    }\n\n    pub fn warn(self: *Output, comptime fmt: []const u8, args: anytype) !void {\n        if (self.mode == .quiet) return;\n        const stderr = std.io.getStdErr().writer();\n        if (self.mode == .rich) try stderr.writeAll(\"\\x1b[33m\"); // Yellow\n        try stderr.print(\"warning: \" ++ fmt, args);\n        if (self.mode == .rich) try stderr.writeAll(\"\\x1b[0m\");\n        try stderr.writeByte('\\n');\n    }\n\n    // JSON mode helpers\n    fn printIssueJson(self: *Output, issue: Issue) !void {\n        try std.json.stringify(issue, .{}, self.writer);\n        try self.writer.writeByte('\\n');\n    }\n\n    fn printIssueListJson(self: *Output, issues: []const Issue) !void {\n        try std.json.stringify(issues, .{}, self.writer);\n        try self.writer.writeByte('\\n');\n    }\n\n    // Plain mode helpers\n    fn printIssuePlain(self: *Output, issue: Issue) !void {\n        try self.writer.print(\"ID: {s}\\n\", .{issue.id});\n        try self.writer.print(\"Title: {s}\\n\", .{issue.title});\n        try self.writer.print(\"Status: {s}\\n\", .{issue.status.toString()});\n        try self.writer.print(\"Priority: {s}\\n\", .{issue.priority.toString()});\n        // ... etc\n    }\n\n    fn printIssueListPlain(self: *Output, issues: []const Issue) !void {\n        for (issues) |issue| {\n            try self.writer.print(\"{s}  [{s}] {s}\\n\", .{\n                issue.id,\n                issue.status.toString()[0..4],  // Abbreviated\n                issue.title,\n            });\n        }\n    }\n\n    // Rich mode helpers (with ANSI colors)\n    fn printIssueRich(self: *Output, issue: Issue) !void {\n        // Bold ID\n        try self.writer.print(\"\\x1b[1m{s}\\x1b[0m\\n\", .{issue.id});\n        // Colored status\n        const status_color = switch (issue.status) {\n            .open => \"\\x1b[32m\",      // Green\n            .in_progress => \"\\x1b[33m\", // Yellow\n            .blocked => \"\\x1b[31m\",    // Red\n            .closed => \"\\x1b[90m\",     // Gray\n            else => \"\\x1b[0m\",\n        };\n        try self.writer.print(\"Status: {s}{s}\\x1b[0m\\n\", .{ status_color, issue.status.toString() });\n        // ... etc\n    }\n\n    // Quiet mode helpers (minimal)\n    fn printIssueQuiet(self: *Output, issue: Issue) !void {\n        try self.writer.print(\"{s}\\n\", .{issue.id});\n    }\n\n    fn printIssueListQuiet(self: *Output, issues: []const Issue) !void {\n        for (issues) |issue| {\n            try self.writer.print(\"{s}\\n\", .{issue.id});\n        }\n    }\n};\n\n// ANSI color constants\npub const Color = struct {\n    pub const reset = \"\\x1b[0m\";\n    pub const bold = \"\\x1b[1m\";\n    pub const red = \"\\x1b[31m\";\n    pub const green = \"\\x1b[32m\";\n    pub const yellow = \"\\x1b[33m\";\n    pub const blue = \"\\x1b[34m\";\n    pub const magenta = \"\\x1b[35m\";\n    pub const cyan = \"\\x1b[36m\";\n    pub const gray = \"\\x1b[90m\";\n};\n```\n\n## Validation\n1. Test plain mode produces readable output\n2. Test JSON mode produces valid JSON\n3. Test quiet mode produces minimal output\n4. Test rich mode includes ANSI codes\n5. Test TTY detection for automatic mode selection\n6. Test --no-color forces plain mode\n7. Test --json overrides other modes\n8. Test error/warning output goes to stderr\n9. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-19r (Issue struct)","status":"in_progress","priority":1,"issue_type":"task","created_at":"2026-01-30T05:09:58.045058649Z","created_by":"hotschmoe","updated_at":"2026-01-30T20:01:47.707773677Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-8ev","title":"Implement Status enum","description":"## Goal\nImplement the Status enum for issue lifecycle states as defined in SPEC.md.\n\n## Technical Approach\nCreate `src/models/status.zig`:\n\n```zig\npub const Status = union(enum) {\n    open,\n    in_progress,\n    blocked,\n    deferred,\n    closed,\n    tombstone,      // Soft deleted\n    pinned,\n    custom: []const u8,\n\n    pub fn toString(self: Status) []const u8 {\n        return switch (self) {\n            .open => \"open\",\n            .in_progress => \"in_progress\",\n            .blocked => \"blocked\",\n            .deferred => \"deferred\",\n            .closed => \"closed\",\n            .tombstone => \"tombstone\",\n            .pinned => \"pinned\",\n            .custom => |s| s,\n        };\n    }\n\n    pub fn fromString(s: []const u8) Status {\n        // Case-insensitive matching using std.ascii.eqlIgnoreCase\n        // Return .custom for unknown values\n    }\n    \n    // For JSON serialization\n    pub fn jsonStringify(...) // std.json compatible\n    pub fn jsonParse(...) // std.json compatible\n};\n```\n\nKey implementation details:\n- Use tagged union for type safety with custom status support\n- Case-insensitive parsing (use std.ascii.eqlIgnoreCase)\n- std.json compatible serialization\n- The custom variant holds a string payload for user-defined statuses\n\nUpdate `src/models/mod.zig` to export Status.\n\n## Validation\n1. Unit tests for toString/fromString roundtrip\n2. Test case-insensitive parsing (\"OPEN\" -> .open)\n3. Test custom status handling\n4. Test JSON serialization/deserialization\n5. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:00:20.833910684Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:55:43.885323057Z","closed_at":"2026-01-30T05:55:43.885291617Z","close_reason":"Completed successfully","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-abv","title":"Implement issue CRUD operations","description":"## Goal\nImplement core database operations for issues: insert, get, update, delete, list.\n\n## Technical Approach\nCreate `src/storage/issues.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Database = @import(\"sqlite.zig\").Database;\nconst Statement = @import(\"sqlite.zig\").Statement;\nconst Issue = @import(\"../models/issue.zig\").Issue;\nconst Status = @import(\"../models/status.zig\").Status;\nconst Priority = @import(\"../models/priority.zig\").Priority;\nconst IssueType = @import(\"../models/issue_type.zig\").IssueType;\n\npub const IssueStore = struct {\n    db: *Database,\n    allocator: std.mem.Allocator,\n\n    pub fn init(db: *Database, allocator: std.mem.Allocator) IssueStore {\n        return .{ .db = db, .allocator = allocator };\n    }\n\n    /// Insert a new issue\n    pub fn insert(self: *IssueStore, issue: Issue) !void {\n        const sql = \n            \\\\INSERT INTO issues (\n            \\\\    id, content_hash, title, description, design, acceptance_criteria,\n            \\\\    notes, status, priority, issue_type, assignee, owner,\n            \\\\    estimated_minutes, created_at, created_by, updated_at,\n            \\\\    closed_at, close_reason, due_at, defer_until,\n            \\\\    external_ref, source_system, pinned, is_template\n            \\\\) VALUES (\n            \\\\    ?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11, ?12,\n            \\\\    ?13, ?14, ?15, ?16, ?17, ?18, ?19, ?20, ?21, ?22, ?23, ?24\n            \\\\)\n        ;\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        \n        try stmt.bindText(1, issue.id);\n        try stmt.bindText(2, issue.content_hash);\n        try stmt.bindText(3, issue.title);\n        // ... bind all fields\n        try stmt.bindInt(23, if (issue.pinned) 1 else 0);\n        try stmt.bindInt(24, if (issue.is_template) 1 else 0);\n        \n        _ = try stmt.step();\n        \n        // Mark as dirty for sync\n        try self.markDirty(issue.id);\n    }\n\n    /// Get issue by ID (without embedded relations)\n    pub fn get(self: *IssueStore, id: []const u8) !?Issue {\n        const sql = \"SELECT * FROM issues WHERE id = ?1\";\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindText(1, id);\n        \n        if (try stmt.step()) {\n            return try self.rowToIssue(&stmt);\n        }\n        return null;\n    }\n\n    /// Get issue with all embedded relations (labels, deps, comments)\n    pub fn getWithRelations(self: *IssueStore, id: []const u8) !?Issue {\n        var issue = try self.get(id) orelse return null;\n        issue.labels = try self.getLabels(id);\n        issue.dependencies = try self.getDependencies(id);\n        issue.comments = try self.getComments(id);\n        return issue;\n    }\n\n    /// Update issue fields\n    pub const IssueUpdate = struct {\n        title: ?[]const u8 = null,\n        description: ?[]const u8 = null,\n        status: ?Status = null,\n        priority: ?Priority = null,\n        issue_type: ?IssueType = null,\n        assignee: ?[]const u8 = null,\n        // ... other updatable fields\n    };\n\n    pub fn update(self: *IssueStore, id: []const u8, updates: IssueUpdate) !void {\n        // Build dynamic UPDATE SQL based on which fields are set\n        // Always update updated_at timestamp\n        // Mark as dirty\n    }\n\n    /// Soft delete (set status to tombstone)\n    pub fn delete(self: *IssueStore, id: []const u8) !void {\n        try self.update(id, .{ .status = .tombstone });\n    }\n\n    /// List issues with filters\n    pub const ListFilters = struct {\n        status: ?Status = null,\n        priority: ?Priority = null,\n        issue_type: ?IssueType = null,\n        assignee: ?[]const u8 = null,\n        label: ?[]const u8 = null,\n        include_tombstones: bool = false,\n        limit: ?u32 = null,\n        offset: ?u32 = null,\n        order_by: enum { created_at, updated_at, priority } = .created_at,\n        order_desc: bool = true,\n    };\n\n    pub fn list(self: *IssueStore, filters: ListFilters) ![]Issue {\n        // Build dynamic SELECT with WHERE clauses\n        // Join with labels if label filter is set\n        // Return array of issues (caller owns memory)\n    }\n\n    /// Count issues grouped by field\n    pub fn count(self: *IssueStore, group_by: ?enum { status, priority, issue_type, assignee }) !CountResult { ... }\n\n    // Helper: convert row to Issue struct\n    fn rowToIssue(self: *IssueStore, stmt: *Statement) !Issue { ... }\n\n    // Helper: mark issue as dirty for sync\n    fn markDirty(self: *IssueStore, id: []const u8) !void {\n        const sql = \"INSERT OR REPLACE INTO dirty_issues (issue_id, marked_at) VALUES (?1, ?2)\";\n        var stmt = try self.db.prepare(sql);\n        defer stmt.deinit();\n        try stmt.bindText(1, id);\n        try stmt.bindInt(2, std.time.timestamp());\n        _ = try stmt.step();\n    }\n};\n```\n\nUpdate `src/storage/mod.zig` to export IssueStore.\n\n## Validation\n1. Test insert creates issue\n2. Test get retrieves issue\n3. Test getWithRelations includes embedded data\n4. Test update modifies fields\n5. Test delete sets tombstone status\n6. Test list with various filters\n7. Test list ordering\n8. Test dirty marking\n9. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-2o2 (database schema)\n- bd-19r (Issue struct)","notes":"NOTE: Description references SQLite but actual implementation uses pure JSONL + in-memory IssueStore (src/storage/store.zig). 19 passing tests.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:05:25.257778714Z","created_by":"hotschmoe","updated_at":"2026-01-30T19:45:48.597702227Z","closed_at":"2026-01-30T07:35:02.351716320Z","close_reason":"Completed successfully","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-fw7","title":"Implement BeadsLock (flock-based locking)","description":"## Goal\nImplement flock-based file locking for concurrent write safety.\n\n## Technical Approach\nCreate `src/storage/lock.zig`:\n\n```zig\npub const BeadsLock = struct {\n    file: std.fs.File,\n\n    const lock_path = \".beads/beads.lock\";\n\n    /// Acquire exclusive lock. Blocks until available.\n    pub fn acquire() !BeadsLock;\n\n    /// Try to acquire lock without blocking.\n    /// Returns null if lock is held by another process.\n    pub fn tryAcquire() !?BeadsLock;\n\n    /// Acquire with timeout (in milliseconds).\n    pub fn acquireTimeout(timeout_ms: u64) !?BeadsLock;\n\n    /// Release lock.\n    pub fn release(self: *BeadsLock) void;\n};\n\n/// Execute a function while holding the beads lock.\npub fn withLock(comptime f: fn () anyerror!void) !void;\n```\n\nKey requirements:\n- Use POSIX flock(LOCK_EX) for blocking exclusive lock\n- Use LOCK_NB for non-blocking try\n- Auto-release on process crash (kernel-managed)\n- Windows compatibility via LockFileEx\n\n## Validation\n1. Test acquire/release cycle\n2. Test tryAcquire returns null when locked\n3. Test acquireTimeout respects timeout\n4. Test withLock RAII pattern\n5. Test lock auto-releases on process exit","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-30T19:41:44.594075175Z","created_by":"hotschmoe","updated_at":"2026-01-30T19:41:44.594075175Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-ke1","title":"Implement ready and blocked commands","description":"## Goal\nImplement `bz ready` and `bz blocked` commands for dependency-aware queries.\n\n## Technical Approach\nCreate `src/cli/ready.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst DependencyStore = @import(\"../storage/dependencies.zig\").DependencyStore;\nconst Output = @import(\"../output/mod.zig\").Output;\n\npub const ReadyArgs = struct {\n    limit: ?u32 = null,\n    assignee: ?[]const u8 = null,\n    label: ?[]const u8 = null,\n};\n\npub fn run(args: ReadyArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    \n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var dep_store = DependencyStore.init(&db, allocator);\n    \n    // Get ready issues (open, not blocked, not deferred)\n    var issues = try dep_store.getReadyIssues();\n    \n    // Apply additional filters\n    if (args.assignee) |a| {\n        issues = filterByAssignee(issues, a);\n    }\n    if (args.label) |l| {\n        issues = try filterByLabel(&db, issues, l, allocator);\n    }\n    \n    // Apply limit\n    if (args.limit) |limit| {\n        if (issues.len > limit) {\n            issues = issues[0..limit];\n        }\n    }\n    \n    if (global.json) {\n        try output.printJson(issues);\n    } else if (global.quiet) {\n        for (issues) |issue| {\n            try output.print(\"{s}\\n\", .{issue.id});\n        }\n    } else {\n        if (issues.len == 0) {\n            try output.print(\"No ready issues found.\\n\", .{});\n            try output.print(\"All open issues are either blocked or deferred.\\n\", .{});\n            return;\n        }\n        \n        try output.printBold(\"Ready Issues ({d})\\n\", .{issues.len});\n        try output.print(\"\\n\", .{});\n        \n        for (issues) |issue| {\n            try output.printPriority(issue.priority);\n            try output.print(\"  {s}  {s}\\n\", .{ issue.id, issue.title });\n        }\n    }\n}\n```\n\nCreate `src/cli/blocked.zig`:\n\n```zig\npub const BlockedArgs = struct {\n    show_blockers: bool = true,\n};\n\npub fn run(args: BlockedArgs, global: anytype, allocator: std.mem.Allocator) !void {\n    var output = Output.init(allocator, global);\n    \n    var db = try openDatabase(allocator, global);\n    defer db.close();\n    \n    var dep_store = DependencyStore.init(&db, allocator);\n    var issue_store = IssueStore.init(&db, allocator);\n    \n    const blocked_issues = try dep_store.getBlockedIssues();\n    \n    if (global.json) {\n        // Include blocker info in JSON\n        var result = std.ArrayList(BlockedInfo).init(allocator);\n        for (blocked_issues) |issue| {\n            const blockers = try dep_store.getBlockers(issue.id);\n            try result.append(.{\n                .issue = issue,\n                .blocked_by = blockers,\n            });\n        }\n        try output.printJson(result.items);\n    } else if (global.quiet) {\n        for (blocked_issues) |issue| {\n            try output.print(\"{s}\\n\", .{issue.id});\n        }\n    } else {\n        if (blocked_issues.len == 0) {\n            try output.print(\"No blocked issues.\\n\", .{});\n            return;\n        }\n        \n        try output.printBold(\"Blocked Issues ({d})\\n\", .{blocked_issues.len});\n        try output.print(\"\\n\", .{});\n        \n        for (blocked_issues) |issue| {\n            try output.print(\"{s}  {s}\\n\", .{ issue.id, issue.title });\n            \n            if (args.show_blockers) {\n                const blockers = try dep_store.getBlockers(issue.id);\n                for (blockers) |blocker_id| {\n                    const blocker = try issue_store.get(blocker_id);\n                    if (blocker) |b| {\n                        try output.printDim(\"  -> blocked by {s} [{s}]\\n\", .{ b.id, b.status.toString() });\n                    }\n                }\n            }\n        }\n    }\n}\n\nconst BlockedInfo = struct {\n    issue: Issue,\n    blocked_by: []const []const u8,\n};\n```\n\n## Validation\n1. Test ready excludes blocked issues\n2. Test ready excludes deferred issues\n3. Test ready excludes closed issues\n4. Test ready --limit\n5. Test ready --assignee filter\n6. Test ready --label filter\n7. Test blocked includes only blocked issues\n8. Test blocked shows blocker info\n9. Test --json output for both\n10. `zig build test` passes\n11. Manual test in sandbox/\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-z48 (SQLite connection wrapper)\n- bd-22m (dependency operations)\n- bd-abv (issue CRUD)\n- bd-1ld (CLI argument parser)\n- bd-5hg (output formatting)","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-30T05:15:55.019090756Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:15:55.019090756Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-kl5","title":"Verify cross-platform builds","description":"## Goal\nVerify beads_zig builds and runs correctly on Linux, macOS, and Windows.\n\n## Technical Approach\n1. **Update build.zig for cross-platform**:\n```zig\n// Handle platform-specific SQLite linking\nconst target = b.standardTargetOptions(.{});\n\nif (bundle_sqlite) {\n    // Bundled SQLite works everywhere\n    exe.addCSourceFile(\"sqlite3.c\", &.{});\n} else {\n    // System SQLite\n    if (target.getOs() == .windows) {\n        // Windows: link against sqlite3.dll\n        exe.linkSystemLibrary(\"sqlite3\");\n    } else if (target.getOs() == .macos) {\n        // macOS: use system SQLite\n        exe.linkSystemLibrary(\"sqlite3\");\n    } else {\n        // Linux: link system or bundled\n        exe.linkSystemLibrary(\"sqlite3\");\n    }\n}\n\n// Handle path separators\nconst path_sep = if (builtin.os.tag == .windows) '\\\\' else '/';\n```\n\n2. **Path handling**:\n```zig\n// src/utils/path.zig\npub fn joinPath(allocator: std.mem.Allocator, parts: []const []const u8) ![]u8 {\n    return std.fs.path.join(allocator, parts);\n}\n\npub fn normalizePath(path: []const u8) []const u8 {\n    // Handle Windows backslashes\n    return std.fs.path.normalize(path);\n}\n\npub fn getBeadsDir() []const u8 {\n    return \".beads\";  // Same on all platforms\n}\n```\n\n3. **CI workflow updates** (already in .github/workflows):\n```yaml\njobs:\n  build:\n    strategy:\n      matrix:\n        os: [ubuntu-latest, macos-latest, windows-latest]\n```\n\n4. **Platform-specific tests**:\n- Test file operations with platform paths\n- Test TTY detection\n- Test signal handling\n\n## Validation\n1. `zig build` succeeds on Linux\n2. `zig build` succeeds on macOS  \n3. `zig build` succeeds on Windows\n4. `zig build test` passes on all platforms\n5. CLI commands work correctly on all platforms\n6. Path handling works with both / and \\\n7. CI passes on all matrix combinations\n\n## Dependencies\n- bd-3jg (project directory structure)\n- All core implementations","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-30T05:29:24.362633919Z","created_by":"hotschmoe","updated_at":"2026-01-30T05:29:24.362633919Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-nwm","title":"Implement Comment struct","description":"## Goal\nImplement the Comment struct for issue comments.\n\n## Technical Approach\nCreate `src/models/comment.zig`:\n\n```zig\npub const Comment = struct {\n    id: i64,                      // Auto-increment from SQLite\n    issue_id: []const u8,         // Parent issue ID\n    author: []const u8,           // Who wrote the comment\n    body: []const u8,             // Comment content\n    created_at: i64,              // Unix timestamp\n\n    // JSON serialization\n    pub fn jsonStringify(...)\n    pub fn jsonParse(...)\n\n    // Validation\n    pub fn validate(self: Comment) !void {\n        if (self.body.len == 0) return error.EmptyCommentBody;\n        if (self.author.len == 0) return error.EmptyAuthor;\n        if (self.issue_id.len == 0) return error.EmptyIssueId;\n    }\n};\n```\n\nKey details:\n- id is auto-generated by SQLite, may be 0 for new comments before insert\n- body must not be empty\n- author should be populated from config/environment\n- created_at should be set at creation time if not provided\n\nUpdate `src/models/mod.zig` to export Comment.\n\n## Validation\n1. Test JSON serialization/deserialization\n2. Test validation (empty body, empty author)\n3. Test with various body content (multiline, unicode)\n4. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:01:07.469450543Z","created_by":"hotschmoe","updated_at":"2026-01-30T06:34:36.165537962Z","closed_at":"2026-01-30T06:34:36.165514758Z","close_reason":"Completed successfully","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-qhg","title":"Implement content hash generation","description":"## Goal\nImplement SHA256 content hashing for issue deduplication during sync.\n\n## Technical Approach\nCreate `src/id/hash.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst Issue = @import(\"../models/issue.zig\").Issue;\n\n/// Generate SHA256 content hash for an issue\n/// Hash includes: title, description, design, acceptance_criteria, notes,\n/// status, priority, issue_type, assignee, owner, created_by,\n/// external_ref, source_system, pinned, is_template\n/// Fields are separated by null bytes for stability\npub fn contentHash(issue: Issue) [64]u8 {\n    var hasher = std.crypto.hash.sha2.Sha256.init(.{});\n    \n    // Add each field with null separator\n    hasher.update(issue.title);\n    hasher.update(\"\\x00\");\n    \n    if (issue.description) |d| hasher.update(d);\n    hasher.update(\"\\x00\");\n    \n    if (issue.design) |d| hasher.update(d);\n    hasher.update(\"\\x00\");\n    \n    // ... continue for all fields per SPEC.md\n    \n    // status as string\n    hasher.update(issue.status.toString());\n    hasher.update(\"\\x00\");\n    \n    // priority as string\n    hasher.update(issue.priority.toString());\n    hasher.update(\"\\x00\");\n    \n    // ... etc\n    \n    // pinned/is_template as \"true\"/\"false\"\n    hasher.update(if (issue.pinned) \"true\" else \"false\");\n    hasher.update(\"\\x00\");\n    hasher.update(if (issue.is_template) \"true\" else \"false\");\n    \n    const digest = hasher.finalResult();\n    \n    // Convert to hex string\n    var hex: [64]u8 = undefined;\n    _ = std.fmt.bufPrint(&hex, \"{s}\", .{std.fmt.fmtSliceHexLower(&digest)}) catch unreachable;\n    return hex;\n}\n\n/// Generate content hash as heap-allocated string\npub fn contentHashAlloc(allocator: std.mem.Allocator, issue: Issue) ![]u8 {\n    const hash = contentHash(issue);\n    return allocator.dupe(u8, &hash);\n}\n\ntest \"contentHash deterministic\" {\n    // Same issue produces same hash\n}\n\ntest \"contentHash different for different content\" {\n    // Changing any field changes hash\n}\n```\n\nKey details:\n- Use SHA256 from std.crypto\n- Null byte separators between fields for unambiguous parsing\n- Output as 64-character lowercase hex string\n- Field order must be stable (alphabetical or as listed in SPEC)\n- Optional fields contribute empty string if null\n\nUpdate `src/id/mod.zig` to export hash functions.\n\n## Validation\n1. Test determinism (same input -> same hash)\n2. Test sensitivity (any field change -> different hash)\n3. Test null field handling\n4. Test output format (64 hex chars, lowercase)\n5. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-19r (Issue struct)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:02:54.151160821Z","created_by":"hotschmoe","updated_at":"2026-01-30T07:07:14.313432312Z","closed_at":"2026-01-30T07:07:14.313407856Z","close_reason":"Completed successfully","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-sbg","title":"Implement EventType enum and Event struct","description":"## Goal\nImplement the Event struct and EventType enum for the audit log system.\n\n## Technical Approach\nCreate `src/models/event.zig`:\n\n```zig\npub const EventType = enum {\n    created,\n    updated,\n    status_changed,\n    priority_changed,\n    assignee_changed,\n    commented,\n    closed,\n    reopened,\n    dependency_added,\n    dependency_removed,\n    label_added,\n    label_removed,\n    compacted,\n    deleted,\n    restored,\n\n    pub fn toString(self: EventType) []const u8 {\n        return @tagName(self);\n    }\n\n    pub fn fromString(s: []const u8) ?EventType {\n        return std.meta.stringToEnum(EventType, s);\n    }\n};\n\npub const Event = struct {\n    id: i64,                      // Auto-increment\n    issue_id: []const u8,\n    event_type: EventType,\n    actor: []const u8,            // Who performed the action\n    old_value: ?[]const u8,       // JSON of previous state\n    new_value: ?[]const u8,       // JSON of new state\n    created_at: i64,              // Unix timestamp\n\n    // JSON serialization\n    pub fn jsonStringify(...)\n    pub fn jsonParse(...)\n\n    // Create event for specific changes\n    pub fn statusChange(issue_id: []const u8, actor: []const u8, old: Status, new: Status, timestamp: i64) Event { ... }\n    pub fn priorityChange(issue_id: []const u8, actor: []const u8, old: Priority, new: Priority, timestamp: i64) Event { ... }\n    // ... other factory functions\n};\n```\n\nKey details:\n- EventType is a plain enum (no custom variant needed - audit is internal)\n- old_value/new_value are JSON strings for flexibility\n- Factory functions help create properly formatted events\n- actor is required - should come from config/environment\n\nUpdate `src/models/mod.zig` to export EventType and Event.\n\n## Validation\n1. Test EventType toString/fromString roundtrip\n2. Test Event JSON serialization\n3. Test factory functions produce valid JSON in old_value/new_value\n4. Test with null old_value (for creation events)\n5. `zig build test` passes\n\n## Dependencies\n- bd-3jg (project directory structure)\n- bd-8ev (Status enum - for factory functions)\n- bd-3t8 (Priority struct - for factory functions)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:01:13.427584276Z","created_by":"hotschmoe","updated_at":"2026-01-30T06:39:22.256903210Z","closed_at":"2026-01-30T06:39:22.256879917Z","close_reason":"Completed successfully","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-z48","title":"Implement SQLite connection wrapper","description":"## Goal\nCreate a SQLite connection wrapper with proper configuration for beads_zig.\n\n## Technical Approach\nCreate `src/storage/sqlite.zig`:\n\n```zig\nconst std = @import(\"std\");\nconst c = @cImport({\n    @cInclude(\"sqlite3.h\");\n});\n\npub const SqliteError = error{\n    OpenFailed,\n    PrepareFailed,\n    BindFailed,\n    StepFailed,\n    ExecuteFailed,\n    BusyTimeout,\n    Corrupt,\n};\n\npub const Database = struct {\n    handle: *c.sqlite3,\n    allocator: std.mem.Allocator,\n\n    pub fn open(allocator: std.mem.Allocator, path: []const u8) !Database {\n        var db: ?*c.sqlite3 = null;\n        const path_z = try allocator.dupeZ(u8, path);\n        defer allocator.free(path_z);\n        \n        const rc = c.sqlite3_open(path_z, &db);\n        if (rc != c.SQLITE_OK) {\n            if (db) |d| c.sqlite3_close(d);\n            return error.OpenFailed;\n        }\n        \n        var self = Database{ .handle = db.?, .allocator = allocator };\n        try self.configure();\n        return self;\n    }\n\n    fn configure(self: *Database) !void {\n        // WAL mode for concurrent reads\n        try self.exec(\"PRAGMA journal_mode = WAL\");\n        // NORMAL sync for performance with reasonable safety\n        try self.exec(\"PRAGMA synchronous = NORMAL\");\n        // Enable foreign keys\n        try self.exec(\"PRAGMA foreign_keys = ON\");\n        // 5 second busy timeout (configurable later)\n        try self.exec(\"PRAGMA busy_timeout = 5000\");\n    }\n\n    pub fn close(self: *Database) void {\n        _ = c.sqlite3_close(self.handle);\n    }\n\n    pub fn exec(self: *Database, sql: []const u8) !void {\n        const sql_z = try self.allocator.dupeZ(u8, sql);\n        defer self.allocator.free(sql_z);\n        \n        var err_msg: ?[*:0]u8 = null;\n        const rc = c.sqlite3_exec(self.handle, sql_z, null, null, &err_msg);\n        if (err_msg) |msg| {\n            defer c.sqlite3_free(msg);\n        }\n        if (rc != c.SQLITE_OK) return error.ExecuteFailed;\n    }\n\n    pub fn prepare(self: *Database, sql: []const u8) !Statement {\n        return Statement.init(self, sql);\n    }\n\n    pub fn lastInsertRowId(self: *Database) i64 {\n        return c.sqlite3_last_insert_rowid(self.handle);\n    }\n\n    pub fn changes(self: *Database) i32 {\n        return c.sqlite3_changes(self.handle);\n    }\n};\n\npub const Statement = struct {\n    stmt: *c.sqlite3_stmt,\n    db: *Database,\n\n    pub fn init(db: *Database, sql: []const u8) !Statement {\n        var stmt: ?*c.sqlite3_stmt = null;\n        const rc = c.sqlite3_prepare_v2(db.handle, sql.ptr, @intCast(sql.len), &stmt, null);\n        if (rc != c.SQLITE_OK or stmt == null) return error.PrepareFailed;\n        return Statement{ .stmt = stmt.?, .db = db };\n    }\n\n    pub fn deinit(self: *Statement) void {\n        _ = c.sqlite3_finalize(self.stmt);\n    }\n\n    // Bind functions for various types\n    pub fn bindText(self: *Statement, idx: u32, value: ?[]const u8) !void { ... }\n    pub fn bindInt(self: *Statement, idx: u32, value: i64) !void { ... }\n    pub fn bindNull(self: *Statement, idx: u32) !void { ... }\n\n    // Column getters\n    pub fn columnText(self: *Statement, idx: u32) ?[]const u8 { ... }\n    pub fn columnInt(self: *Statement, idx: u32) i64 { ... }\n    pub fn columnOptionalInt(self: *Statement, idx: u32) ?i64 { ... }\n\n    pub fn step(self: *Statement) !bool {\n        const rc = c.sqlite3_step(self.stmt);\n        return switch (rc) {\n            c.SQLITE_ROW => true,\n            c.SQLITE_DONE => false,\n            c.SQLITE_BUSY => error.BusyTimeout,\n            else => error.StepFailed,\n        };\n    }\n\n    pub fn reset(self: *Statement) !void {\n        _ = c.sqlite3_reset(self.stmt);\n    }\n};\n\n/// Transaction helper\npub fn transaction(db: *Database, comptime f: fn (*Database) anyerror!void) !void {\n    try db.exec(\"BEGIN IMMEDIATE\");\n    f(db) catch |err| {\n        db.exec(\"ROLLBACK\") catch {};\n        return err;\n    };\n    try db.exec(\"COMMIT\");\n}\n```\n\nUpdate `src/storage/mod.zig` to export Database, Statement, transaction.\n\n## Validation\n1. Test open/close database\n2. Test PRAGMA settings are applied\n3. Test exec for simple SQL\n4. Test prepare/bind/step/column workflow\n5. Test transaction commit and rollback\n6. Test busy timeout behavior\n7. `zig build test` passes (using temp database)\n\n## Dependencies\n- bd-3jg (project directory structure)","notes":"SUPERSEDED: Removed SQLite in favor of pure JSONL storage (commit de83573). See docs/architecture.md for Lock+WAL+Compact design.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-30T05:03:52.452251669Z","created_by":"hotschmoe","updated_at":"2026-01-30T19:44:54.544590494Z","closed_at":"2026-01-30T07:19:18.534086149Z","close_reason":"Completed successfully","source_repo":".","compaction_level":0,"original_size":0}
